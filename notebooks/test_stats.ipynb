{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd \n",
    "\n",
    "# tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "t = \"\"\"Two Travellers, walking in the noonday sun, sought the shade of a widespreading tree to rest. As they lay looking up among the pleasant leaves, they saw that it was a Plane Tree.\n",
    "\n",
    "\"How useless is the Plane!\" said one of them. \"It bears no fruit whatever, and only serves to litter the ground with leaves.\"\n",
    "\n",
    "\"Ungrateful creatures!\" said a voice from the Plane Tree. \"You lie here in my cooling shade, and yet you say I am useless! Thus ungratefully, O Jupiter, do men receive their blessings!\"\n",
    "\n",
    "Our best blessings are often the least appreciated.\"\"\"\n",
    "\n",
    "cnt = Counter(t.split())\n",
    "\n",
    "# tfs = tfidf.fit_transform(t.split(\" \"))\n",
    "# str = 'tree cat travellers fruit jupiter'\n",
    "# response = tfidf.transform([t])\n",
    "# feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# for col in response.nonzero()[1]:\n",
    "#     print(feature_names[col], ' - ', response[0, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../example_article.txt', 'r') as f:\n",
    "    word_freq = f.read().split()\n",
    "    word_freq = Counter(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training': 11,\n",
       " 'Generative': 5,\n",
       " 'Adversarial': 1,\n",
       " 'Networks': 1,\n",
       " 'with': 183,\n",
       " 'Limited': 1,\n",
       " 'Data': 3,\n",
       " 'Tero': 2,\n",
       " 'Karras': 5,\n",
       " 'NVIDIA': 10,\n",
       " 'Miika': 1,\n",
       " 'Aittala': 1,\n",
       " 'Janne': 1,\n",
       " 'Hellsten': 1,\n",
       " 'Samuli': 1,\n",
       " 'Laine': 2,\n",
       " 'Jaakko': 1,\n",
       " 'Lehtinen': 1,\n",
       " 'and': 408,\n",
       " 'Aalto': 1,\n",
       " 'University': 2,\n",
       " 'Timo': 1,\n",
       " 'Aila': 1,\n",
       " 'Abstract': 1,\n",
       " 'generative': 21,\n",
       " 'adversarial': 14,\n",
       " 'networks': 6,\n",
       " '(GAN)': 2,\n",
       " 'using': 52,\n",
       " 'too': 6,\n",
       " 'little': 2,\n",
       " 'data': 28,\n",
       " 'typically': 2,\n",
       " 'leads': 5,\n",
       " 'to': 333,\n",
       " 'discriminator': 51,\n",
       " 'overfitting,': 8,\n",
       " 'causing': 1,\n",
       " 'training': 137,\n",
       " 'diverge.': 1,\n",
       " 'We': 129,\n",
       " 'propose': 8,\n",
       " 'an': 56,\n",
       " 'adaptive': 10,\n",
       " 'augmentation': 94,\n",
       " 'mechanism': 2,\n",
       " 'that': 216,\n",
       " 'significantly': 12,\n",
       " 'stabilizes': 2,\n",
       " 'in': 217,\n",
       " 'limited': 16,\n",
       " 'regimes.': 1,\n",
       " 'The': 80,\n",
       " 'approach': 8,\n",
       " 'does': 23,\n",
       " 'not': 80,\n",
       " 'require': 5,\n",
       " 'changes': 2,\n",
       " 'loss': 20,\n",
       " 'functions': 5,\n",
       " 'or': 28,\n",
       " 'network': 10,\n",
       " 'architectures,': 1,\n",
       " 'is': 257,\n",
       " 'applicable': 1,\n",
       " 'both': 12,\n",
       " 'when': 36,\n",
       " 'from': 98,\n",
       " 'scratch': 4,\n",
       " 'fine-tuning': 2,\n",
       " 'existing': 7,\n",
       " 'GAN': 17,\n",
       " 'on': 86,\n",
       " 'another': 2,\n",
       " 'dataset.': 4,\n",
       " 'demonstrate,': 2,\n",
       " 'several': 11,\n",
       " 'datasets,': 3,\n",
       " 'good': 4,\n",
       " 'results': 47,\n",
       " 'are': 85,\n",
       " 'now': 8,\n",
       " 'possible': 10,\n",
       " 'only': 39,\n",
       " 'a': 310,\n",
       " 'few': 5,\n",
       " 'thousand': 2,\n",
       " 'images,': 16,\n",
       " 'often': 5,\n",
       " 'matching': 4,\n",
       " 'StyleGAN2': 26,\n",
       " 'order': 9,\n",
       " 'of': 500,\n",
       " 'magnitude': 5,\n",
       " 'fewer': 4,\n",
       " 'images.': 24,\n",
       " 'expect': 1,\n",
       " 'this': 96,\n",
       " 'open': 1,\n",
       " 'up': 8,\n",
       " 'new': 8,\n",
       " 'application': 2,\n",
       " 'domains': 3,\n",
       " 'for': 203,\n",
       " 'GANs.': 6,\n",
       " 'also': 30,\n",
       " 'find': 8,\n",
       " 'the': 918,\n",
       " 'widely': 3,\n",
       " 'used': 27,\n",
       " 'CIFAR-10': 17,\n",
       " 'is,': 5,\n",
       " 'fact,': 1,\n",
       " 'benchmark,': 2,\n",
       " 'improve': 10,\n",
       " 'record': 2,\n",
       " 'FID': 107,\n",
       " '5.59': 4,\n",
       " '2.42.': 1,\n",
       " '1': 54,\n",
       " 'Introduction': 1,\n",
       " 'increasingly': 2,\n",
       " 'impressive': 1,\n",
       " '[14,': 1,\n",
       " '32,': 1,\n",
       " '31,': 1,\n",
       " '5,': 2,\n",
       " '19,': 1,\n",
       " '20,': 3,\n",
       " '21]': 1,\n",
       " 'fueled': 1,\n",
       " 'by': 131,\n",
       " 'seemingly': 1,\n",
       " 'unlimited': 1,\n",
       " 'supply': 1,\n",
       " 'images': 80,\n",
       " 'available': 8,\n",
       " 'online.': 1,\n",
       " 'Still,': 1,\n",
       " 'it': 57,\n",
       " 'remains': 6,\n",
       " 'challenging': 1,\n",
       " 'collect': 3,\n",
       " 'large': 6,\n",
       " 'enough': 3,\n",
       " 'set': 67,\n",
       " 'specific': 5,\n",
       " 'places': 1,\n",
       " 'constraints': 1,\n",
       " 'subject': 1,\n",
       " 'type,': 1,\n",
       " 'image': 68,\n",
       " 'quality,': 3,\n",
       " 'geographical': 1,\n",
       " 'location,': 1,\n",
       " 'time': 5,\n",
       " 'period,': 1,\n",
       " 'privacy,': 2,\n",
       " 'copyright': 1,\n",
       " 'status,': 1,\n",
       " 'etc.': 1,\n",
       " 'difficulties': 1,\n",
       " 'further': 7,\n",
       " 'exacerbated': 1,\n",
       " 'applications': 2,\n",
       " 'capture': 1,\n",
       " 'new,': 1,\n",
       " 'custom': 2,\n",
       " 'dataset:': 1,\n",
       " 'acquiring,': 1,\n",
       " 'processing,': 1,\n",
       " 'distributing': 1,\n",
       " '∼': 22,\n",
       " '105': 1,\n",
       " '−': 25,\n",
       " '106': 1,\n",
       " 'required': 3,\n",
       " 'train': 4,\n",
       " 'modern': 1,\n",
       " 'high-quality,': 1,\n",
       " 'high-resolution': 2,\n",
       " 'costly': 2,\n",
       " 'undertaking.': 1,\n",
       " 'This': 27,\n",
       " 'curbs': 1,\n",
       " 'increasing': 7,\n",
       " 'use': 32,\n",
       " 'models': 13,\n",
       " 'fields': 2,\n",
       " 'such': 31,\n",
       " 'as': 135,\n",
       " 'medicine': 1,\n",
       " '[47].': 1,\n",
       " 'A': 19,\n",
       " 'significant': 5,\n",
       " 'reduction': 1,\n",
       " 'number': 14,\n",
       " 'therefore': 9,\n",
       " 'has': 29,\n",
       " 'potential': 2,\n",
       " 'considerably': 3,\n",
       " 'help': 2,\n",
       " 'many': 9,\n",
       " 'applications.': 1,\n",
       " 'key': 4,\n",
       " 'problem': 5,\n",
       " 'small': 8,\n",
       " 'datasets': 16,\n",
       " 'overfits': 1,\n",
       " 'examples;': 1,\n",
       " 'its': 27,\n",
       " 'feedback': 1,\n",
       " 'generator': 34,\n",
       " 'becomes': 4,\n",
       " 'meaningless': 1,\n",
       " 'starts': 7,\n",
       " 'diverge': 2,\n",
       " '[2,': 1,\n",
       " '48].': 1,\n",
       " 'In': 95,\n",
       " 'almost': 7,\n",
       " 'all': 47,\n",
       " 'areas': 2,\n",
       " 'deep': 5,\n",
       " 'learning': 22,\n",
       " '[40],': 1,\n",
       " 'dataset': 31,\n",
       " 'standard': 13,\n",
       " 'solution': 4,\n",
       " 'against': 4,\n",
       " 'overfitting.': 4,\n",
       " 'For': 34,\n",
       " 'example,': 16,\n",
       " 'classifier': 2,\n",
       " 'under': 9,\n",
       " 'rotation,': 1,\n",
       " 'noise,': 6,\n",
       " 'etc.,': 1,\n",
       " 'invariance': 1,\n",
       " 'these': 27,\n",
       " 'semantics-preserving': 1,\n",
       " 'distortions': 1,\n",
       " '—': 6,\n",
       " 'highly': 5,\n",
       " 'desirable': 1,\n",
       " 'quality': 18,\n",
       " '[17,': 1,\n",
       " '8,': 2,\n",
       " '9].': 1,\n",
       " 'contrast,': 3,\n",
       " 'trained': 18,\n",
       " 'similar': 10,\n",
       " 'augmentations': 66,\n",
       " 'learns': 3,\n",
       " 'generate': 2,\n",
       " 'augmented': 13,\n",
       " 'distribution': 44,\n",
       " '[50,': 1,\n",
       " '53].': 1,\n",
       " 'general,': 5,\n",
       " '“leaking”': 1,\n",
       " 'generated': 44,\n",
       " 'samples': 5,\n",
       " 'undesirable.': 1,\n",
       " 'noise': 24,\n",
       " 'noisy': 1,\n",
       " 'results,': 3,\n",
       " 'even': 12,\n",
       " 'if': 22,\n",
       " 'there': 8,\n",
       " 'none': 3,\n",
       " 'paper,': 1,\n",
       " 'we': 123,\n",
       " 'demonstrate': 3,\n",
       " 'how': 5,\n",
       " 'wide': 3,\n",
       " 'range': 7,\n",
       " 'prevent': 8,\n",
       " 'while': 10,\n",
       " 'ensuring': 1,\n",
       " 'leak': 13,\n",
       " 'start': 5,\n",
       " 'presenting': 1,\n",
       " 'comprehensive': 1,\n",
       " 'analysis': 4,\n",
       " 'conditions': 10,\n",
       " 'leaking.': 1,\n",
       " 'then': 22,\n",
       " 'design': 2,\n",
       " 'diverse': 8,\n",
       " 'augmentations,': 16,\n",
       " 'control': 4,\n",
       " 'scheme': 2,\n",
       " 'enables': 1,\n",
       " 'same': 20,\n",
       " 'be': 72,\n",
       " 'regardless': 6,\n",
       " 'amount': 6,\n",
       " 'data,': 7,\n",
       " 'properties': 1,\n",
       " 'dataset,': 9,\n",
       " 'exact': 3,\n",
       " 'setup': 4,\n",
       " '(e.g.,': 7,\n",
       " 'transfer': 11,\n",
       " '[33,': 1,\n",
       " '44,': 1,\n",
       " '45,': 2,\n",
       " '34]).': 1,\n",
       " '34th': 1,\n",
       " 'Conference': 1,\n",
       " 'Neural': 2,\n",
       " 'Information': 1,\n",
       " 'Processing': 1,\n",
       " 'Systems': 1,\n",
       " '(NeurIPS': 1,\n",
       " '2020),': 1,\n",
       " 'Vancouver,': 1,\n",
       " 'Canada.': 1,\n",
       " 'arXiv:2006.06676v2': 1,\n",
       " '[cs.CV]': 1,\n",
       " '7': 5,\n",
       " 'Oct': 1,\n",
       " '2020': 1,\n",
       " 't': 16,\n",
       " '=': 153,\n",
       " '0M': 10,\n",
       " '1M': 8,\n",
       " '5M': 9,\n",
       " '10M': 9,\n",
       " '15M': 6,\n",
       " '20M': 6,\n",
       " '25M': 12,\n",
       " 'progress': 6,\n",
       " '(number': 1,\n",
       " 'reals': 1,\n",
       " 'shown': 17,\n",
       " 'D)': 3,\n",
       " '5': 34,\n",
       " '10': 39,\n",
       " '20': 33,\n",
       " '50': 29,\n",
       " '100': 20,\n",
       " 'median/min/max': 5,\n",
       " '(3': 8,\n",
       " 'runs)': 9,\n",
       " '140k': 14,\n",
       " '70k': 6,\n",
       " '50k': 20,\n",
       " '30k': 9,\n",
       " '20k': 13,\n",
       " '10k': 28,\n",
       " '5k': 16,\n",
       " '2M': 4,\n",
       " '4M': 4,\n",
       " '6M': 2,\n",
       " '8M': 2,\n",
       " '12M': 2,\n",
       " '14M': 2,\n",
       " '(reals': 2,\n",
       " '-6': 2,\n",
       " '-4': 2,\n",
       " '-2': 3,\n",
       " '0': 39,\n",
       " '2': 54,\n",
       " '4': 27,\n",
       " '6': 5,\n",
       " 'D(x)': 5,\n",
       " 'Real': 11,\n",
       " 'Generated': 4,\n",
       " 'Validation': 3,\n",
       " 'Best': 3,\n",
       " '(a)': 18,\n",
       " 'Convergence': 4,\n",
       " 'FFHQ': 19,\n",
       " '(256': 4,\n",
       " '×': 16,\n",
       " '256)': 4,\n",
       " '(b)': 16,\n",
       " 'Discriminator': 7,\n",
       " 'outputs,': 3,\n",
       " '(c)': 15,\n",
       " 'Figure': 66,\n",
       " '1:': 4,\n",
       " 'different': 30,\n",
       " 'sizes.': 3,\n",
       " '“140k”': 1,\n",
       " 'means': 4,\n",
       " 'amplified': 1,\n",
       " '2×': 5,\n",
       " 'through': 5,\n",
       " 'x-flips;': 1,\n",
       " 'do': 16,\n",
       " 'amplification': 5,\n",
       " 'any': 24,\n",
       " 'other': 26,\n",
       " 'case.': 4,\n",
       " '(b,c)': 1,\n",
       " 'Evolution': 5,\n",
       " 'outputs': 4,\n",
       " 'during': 3,\n",
       " 'training.': 12,\n",
       " 'Each': 2,\n",
       " 'vertical': 3,\n",
       " 'slice': 2,\n",
       " 'shows': 18,\n",
       " 'histogram': 1,\n",
       " 'D(x),': 1,\n",
       " 'i.e.,': 5,\n",
       " 'raw': 2,\n",
       " 'logits.': 1,\n",
       " 'Furthermore,': 8,\n",
       " 'show': 13,\n",
       " 'popular': 1,\n",
       " 'benchmark': 3,\n",
       " 'suffers': 2,\n",
       " 'achieve': 3,\n",
       " 'Fréchet': 1,\n",
       " 'inception': 3,\n",
       " 'distance': 4,\n",
       " '(FID)': 1,\n",
       " '[18]': 3,\n",
       " '2.42,': 1,\n",
       " 'improving': 2,\n",
       " 'over': 36,\n",
       " 'current': 1,\n",
       " 'state': 4,\n",
       " 'art': 1,\n",
       " '[52].': 1,\n",
       " 'present': 5,\n",
       " 'METFACES,': 4,\n",
       " 'high-quality': 6,\n",
       " 'scenarios.': 2,\n",
       " 'Our': 10,\n",
       " 'implementation': 5,\n",
       " 'at': 37,\n",
       " 'https://github.com/NVlabs/stylegan2-ada': 1,\n",
       " 'Overfitting': 1,\n",
       " 'GANs': 8,\n",
       " 'studying': 1,\n",
       " 'quantity': 1,\n",
       " 'affects': 3,\n",
       " 'artificially': 1,\n",
       " 'subsetting': 1,\n",
       " 'larger': 5,\n",
       " '(FFHQ': 1,\n",
       " 'LSUN': 16,\n",
       " 'CAT)': 1,\n",
       " 'observing': 2,\n",
       " 'resulting': 8,\n",
       " 'dynamics.': 3,\n",
       " 'our': 66,\n",
       " 'baseline,': 2,\n",
       " 'considered': 1,\n",
       " '[21]': 4,\n",
       " 'BigGAN': 13,\n",
       " '[5,': 3,\n",
       " '38].': 1,\n",
       " 'Based': 2,\n",
       " 'initial': 2,\n",
       " 'testing,': 1,\n",
       " 'settled': 1,\n",
       " 'because': 10,\n",
       " 'provided': 2,\n",
       " 'more': 17,\n",
       " 'predictable': 1,\n",
       " 'lower': 3,\n",
       " 'variance': 1,\n",
       " 'between': 17,\n",
       " 'runs': 8,\n",
       " '(see': 2,\n",
       " 'Appendix': 10,\n",
       " 'A).': 1,\n",
       " 'each': 39,\n",
       " 'run,': 2,\n",
       " 'randomize': 2,\n",
       " 'subset': 7,\n",
       " 'samples,': 1,\n",
       " 'initialization.': 2,\n",
       " 'To': 11,\n",
       " 'facilitate': 2,\n",
       " 'extensive': 6,\n",
       " 'sweeps': 6,\n",
       " 'sizes': 5,\n",
       " 'hyperparameters,': 2,\n",
       " 'downscaled': 2,\n",
       " '256': 8,\n",
       " 'version': 7,\n",
       " 'lighter-weight': 1,\n",
       " 'configuration': 7,\n",
       " 'reaches': 2,\n",
       " 'official': 4,\n",
       " 'config': 11,\n",
       " 'F': 8,\n",
       " 'but': 26,\n",
       " '4.6×': 1,\n",
       " 'faster': 1,\n",
       " 'DGX-1.1': 1,\n",
       " 'measure': 8,\n",
       " 'computing': 4,\n",
       " 'recommended': 1,\n",
       " 'Heusel': 2,\n",
       " 'et': 24,\n",
       " 'al.': 24,\n",
       " '[18],': 1,\n",
       " 'actually': 5,\n",
       " '1a': 1,\n",
       " 'baseline': 16,\n",
       " 'subsets': 6,\n",
       " 'FFHQ.': 5,\n",
       " 'way': 10,\n",
       " 'case,': 8,\n",
       " 'eventually': 1,\n",
       " 'stops': 1,\n",
       " 'rise.': 1,\n",
       " 'less': 10,\n",
       " 'earlier': 3,\n",
       " 'happens.': 1,\n",
       " '1b,c': 1,\n",
       " 'output': 12,\n",
       " 'distributions': 21,\n",
       " 'real': 18,\n",
       " 'overlap': 2,\n",
       " 'initially': 2,\n",
       " 'keep': 2,\n",
       " 'drifting': 1,\n",
       " 'apart': 1,\n",
       " 'confident,': 1,\n",
       " 'point': 6,\n",
       " 'where': 22,\n",
       " 'deteriorate': 1,\n",
       " 'consistent': 2,\n",
       " 'sufficient': 4,\n",
       " 'distributions.': 6,\n",
       " 'strong': 5,\n",
       " 'indication': 1,\n",
       " 'evidenced': 2,\n",
       " 'drop': 1,\n",
       " 'accuracy': 1,\n",
       " 'measured': 2,\n",
       " 'separate': 8,\n",
       " 'validation': 9,\n",
       " 'set.': 10,\n",
       " 'tackle': 1,\n",
       " 'employing': 2,\n",
       " 'versatile': 1,\n",
       " 'becoming': 2,\n",
       " 'overly': 1,\n",
       " 'confident.': 1,\n",
       " '2.1': 1,\n",
       " 'Stochastic': 2,\n",
       " 'By': 7,\n",
       " 'definition,': 1,\n",
       " 'applied': 16,\n",
       " 'will': 11,\n",
       " 'get': 2,\n",
       " 'inherited': 1,\n",
       " '[14].': 2,\n",
       " 'Zhao': 6,\n",
       " '[53]': 7,\n",
       " 'recently': 3,\n",
       " 'proposed': 4,\n",
       " 'balanced': 4,\n",
       " 'consistency': 9,\n",
       " 'regularization': 21,\n",
       " '(bCR)': 3,\n",
       " 'supposed': 1,\n",
       " 'Consistency': 2,\n",
       " 'states': 1,\n",
       " 'two': 17,\n",
       " 'sets': 6,\n",
       " 'input': 8,\n",
       " 'image,': 1,\n",
       " 'should': 3,\n",
       " 'yield': 2,\n",
       " '[35,': 1,\n",
       " '27].': 1,\n",
       " 'add': 1,\n",
       " 'terms': 10,\n",
       " 'loss,': 2,\n",
       " 'enforce': 1,\n",
       " 'whereas': 3,\n",
       " 'no': 26,\n",
       " '(Figure': 10,\n",
       " '2a).': 1,\n",
       " 'As': 7,\n",
       " 'such,': 2,\n",
       " 'their': 20,\n",
       " '1We': 1,\n",
       " 'feature': 6,\n",
       " 'maps,': 1,\n",
       " 'minibatch,': 2,\n",
       " 'mixed-precision': 5,\n",
       " 'layers': 10,\n",
       " '≥': 2,\n",
       " '322': 2,\n",
       " ',': 51,\n",
       " 'η': 2,\n",
       " '0.0025,': 1,\n",
       " 'γ': 7,\n",
       " '1,': 15,\n",
       " 'exponential': 3,\n",
       " 'moving': 5,\n",
       " 'average': 10,\n",
       " 'half-life': 1,\n",
       " 'weights.': 2,\n",
       " 'Latents': 4,\n",
       " 'Reals': 2,\n",
       " 'G': 50,\n",
       " 'D': 14,\n",
       " 'Aug': 5,\n",
       " '–': 73,\n",
       " 'f': 16,\n",
       " '(x)': 6,\n",
       " '(x': 3,\n",
       " 'y)': 5,\n",
       " '(–x)': 2,\n",
       " 'bCR': 28,\n",
       " '(previous': 1,\n",
       " 'work)': 1,\n",
       " 'p': 101,\n",
       " 'Ours': 1,\n",
       " '0.1': 2,\n",
       " '0.2': 20,\n",
       " '0.3': 3,\n",
       " '0.5': 7,\n",
       " '0.8': 17,\n",
       " 'Effect': 3,\n",
       " 'probability': 78,\n",
       " '2:': 3,\n",
       " '(a,b)': 2,\n",
       " 'Flowcharts': 1,\n",
       " 'stochastic': 16,\n",
       " 'augmentations.': 6,\n",
       " 'blue': 3,\n",
       " 'elements': 18,\n",
       " 'highlight': 2,\n",
       " 'operations': 1,\n",
       " 'related': 3,\n",
       " 'rest': 2,\n",
       " 'implement': 5,\n",
       " 'orange': 1,\n",
       " 'indicate': 4,\n",
       " 'function': 21,\n",
       " 'green': 1,\n",
       " 'boxes': 1,\n",
       " 'mark': 1,\n",
       " 'being': 2,\n",
       " 'trained.': 1,\n",
       " 'non-saturating': 3,\n",
       " 'logistic': 2,\n",
       " '[14]': 4,\n",
       " 'f(x)': 1,\n",
       " 'log': 1,\n",
       " '(sigmoid(x)).': 1,\n",
       " 'apply': 28,\n",
       " 'every': 12,\n",
       " 'sees,': 1,\n",
       " 'controlled': 2,\n",
       " 'p.': 6,\n",
       " 'effectively': 4,\n",
       " 'strives': 1,\n",
       " 'generalize': 4,\n",
       " 'making': 4,\n",
       " 'blind': 2,\n",
       " 'CR': 2,\n",
       " 'term.': 1,\n",
       " 'However,': 9,\n",
       " 'meeting': 1,\n",
       " 'goal': 4,\n",
       " 'opens': 2,\n",
       " 'door': 1,\n",
       " 'leaking': 4,\n",
       " 'free': 3,\n",
       " 'produce': 7,\n",
       " 'containing': 2,\n",
       " 'them': 7,\n",
       " 'without': 12,\n",
       " 'penalty.': 2,\n",
       " 'Section': 3,\n",
       " '4,': 4,\n",
       " 'experimentally': 1,\n",
       " 'indeed': 3,\n",
       " 'problem,': 2,\n",
       " 'thus': 5,\n",
       " 'effects': 4,\n",
       " 'fundamentally': 1,\n",
       " 'augmentation.': 9,\n",
       " 'discriminator.': 4,\n",
       " 'instead': 7,\n",
       " 'adding': 1,\n",
       " 'terms,': 2,\n",
       " 'evaluate': 1,\n",
       " '2b).': 1,\n",
       " 'call': 3,\n",
       " 'very': 9,\n",
       " 'straightforward.': 1,\n",
       " 'Yet,': 1,\n",
       " 'possibility': 3,\n",
       " 'received': 1,\n",
       " 'attention,': 1,\n",
       " 'possibly': 2,\n",
       " 'first': 12,\n",
       " 'glance': 1,\n",
       " 'obvious': 3,\n",
       " 'works:': 1,\n",
       " 'never': 3,\n",
       " 'sees': 2,\n",
       " 'what': 3,\n",
       " 'really': 1,\n",
       " 'look': 3,\n",
       " 'like,': 1,\n",
       " 'clear': 2,\n",
       " 'can': 56,\n",
       " 'guide': 1,\n",
       " 'properly': 1,\n",
       " '2c).': 2,\n",
       " 'investigate': 1,\n",
       " 'which': 38,\n",
       " 'build': 5,\n",
       " 'full': 4,\n",
       " 'pipeline': 12,\n",
       " 'out': 7,\n",
       " 'transformations.': 3,\n",
       " '2.2': 1,\n",
       " 'Designing': 1,\n",
       " 'corresponds': 9,\n",
       " 'putting': 1,\n",
       " 'distorting,': 1,\n",
       " 'perhaps': 1,\n",
       " 'destructive': 1,\n",
       " 'goggles': 1,\n",
       " 'discriminator,': 3,\n",
       " 'asking': 1,\n",
       " 'cannot': 7,\n",
       " 'distinguished': 1,\n",
       " 'viewed': 4,\n",
       " 'goggles.': 1,\n",
       " 'Bora': 4,\n",
       " '[4]': 2,\n",
       " 'consider': 11,\n",
       " 'corrupted': 1,\n",
       " 'measurements,': 1,\n",
       " 'implicitly': 2,\n",
       " 'undoes': 1,\n",
       " 'corruptions': 4,\n",
       " 'finds': 2,\n",
       " 'correct': 10,\n",
       " 'distribution,': 6,\n",
       " 'long': 13,\n",
       " 'corruption': 2,\n",
       " 'process': 4,\n",
       " 'represented': 3,\n",
       " 'invertible': 14,\n",
       " 'transformation': 20,\n",
       " 'space.': 4,\n",
       " 'operators': 8,\n",
       " 'non-leaking.': 3,\n",
       " 'power': 6,\n",
       " 'transformations': 32,\n",
       " 'they': 15,\n",
       " 'allow': 4,\n",
       " 'conclusions': 2,\n",
       " 'about': 5,\n",
       " 'equality': 1,\n",
       " 'inequality': 1,\n",
       " 'underlying': 2,\n",
       " 'drawn': 1,\n",
       " 'sets.': 1,\n",
       " 'It': 8,\n",
       " 'crucial': 1,\n",
       " 'understand': 2,\n",
       " 'mean': 7,\n",
       " 'performed': 6,\n",
       " 'individual': 8,\n",
       " 'would': 10,\n",
       " 'need': 3,\n",
       " 'undoable.': 1,\n",
       " 'instance,': 2,\n",
       " 'extreme': 2,\n",
       " 'setting': 11,\n",
       " 'zero': 6,\n",
       " '90%': 1,\n",
       " 'sense:': 1,\n",
       " 'easy,': 1,\n",
       " 'human,': 1,\n",
       " 'reason': 4,\n",
       " 'original': 15,\n",
       " 'ignoring': 1,\n",
       " 'black': 3,\n",
       " 'until': 2,\n",
       " '10%': 1,\n",
       " 'remain.': 1,\n",
       " 'On': 2,\n",
       " 'hand,': 2,\n",
       " 'random': 18,\n",
       " 'rotations': 17,\n",
       " 'chosen': 7,\n",
       " 'uniformly': 2,\n",
       " '{0': 1,\n",
       " '◦': 3,\n",
       " '90◦': 8,\n",
       " '180◦': 1,\n",
       " '270◦}': 1,\n",
       " 'invertible:': 1,\n",
       " 'impossible': 1,\n",
       " 'discern': 1,\n",
       " 'differences': 1,\n",
       " 'among': 5,\n",
       " 'orientations': 4,\n",
       " 'after': 8,\n",
       " 'situation': 5,\n",
       " 'rotation': 19,\n",
       " 'executed': 3,\n",
       " '<': 1,\n",
       " 'increases': 2,\n",
       " 'relative': 3,\n",
       " 'occurrence': 1,\n",
       " 'match': 3,\n",
       " 'have': 17,\n",
       " 'orientation.': 2,\n",
       " 'Similarly,': 6,\n",
       " 'designed': 2,\n",
       " 'non-leaking': 10,\n",
       " 'condition': 5,\n",
       " 'skipped': 4,\n",
       " 'non-zero': 3,\n",
       " 'probability.': 3,\n",
       " 'C': 18,\n",
       " 'made': 4,\n",
       " 'hold': 4,\n",
       " 'class': 7,\n",
       " 'including': 3,\n",
       " 'deterministic': 8,\n",
       " 'mappings': 4,\n",
       " 'basis': 3,\n",
       " 'transformations),': 1,\n",
       " 'additive': 10,\n",
       " 'groups': 14,\n",
       " '(e.g,': 1,\n",
       " 'color': 12,\n",
       " 'space': 17,\n",
       " 'rotations,': 4,\n",
       " 'flips': 2,\n",
       " 'scaling),': 1,\n",
       " 'projections': 3,\n",
       " 'cutout': 6,\n",
       " '[11]).': 1,\n",
       " 'composing': 4,\n",
       " 'fixed': 13,\n",
       " 'yields': 3,\n",
       " 'overall': 5,\n",
       " '3': 13,\n",
       " 'validate': 1,\n",
       " 'three': 11,\n",
       " 'practical': 12,\n",
       " 'examples.': 2,\n",
       " 'Isotropic': 3,\n",
       " 'scaling': 18,\n",
       " 'log-normal': 4,\n",
       " 'example': 12,\n",
       " 'inherently': 3,\n",
       " 'safe': 2,\n",
       " 'B': 3,\n",
       " '0.75': 5,\n",
       " '0.80': 3,\n",
       " '0.85': 3,\n",
       " '0.90': 3,\n",
       " '0.95': 3,\n",
       " '1.00': 4,\n",
       " 'E': 4,\n",
       " 'Random': 2,\n",
       " 'Color': 15,\n",
       " '3:': 3,\n",
       " 'Leaking': 2,\n",
       " 'behavior': 3,\n",
       " 'w.r.t.': 1,\n",
       " 'executing': 1,\n",
       " 'dot': 1,\n",
       " 'represents': 2,\n",
       " 'complete': 2,\n",
       " 'Gaussian': 4,\n",
       " 'mixture': 10,\n",
       " 'visualization': 1,\n",
       " 'aid.': 1,\n",
       " 'top': 3,\n",
       " 'row': 2,\n",
       " 'selected': 10,\n",
       " 'runs,': 1,\n",
       " 'indicated': 2,\n",
       " 'uppercase': 1,\n",
       " 'letters': 4,\n",
       " 'plots.': 1,\n",
       " 'value': 12,\n",
       " '3a).': 1,\n",
       " 'aforementioned': 2,\n",
       " 'multiple': 6,\n",
       " 'must': 9,\n",
       " 'least': 4,\n",
       " 'part': 3,\n",
       " '3b).': 1,\n",
       " 'When': 8,\n",
       " 'high,': 1,\n",
       " 'know': 2,\n",
       " 'face': 2,\n",
       " 'ends': 1,\n",
       " 'picking': 2,\n",
       " 'one': 23,\n",
       " 'possibilities': 1,\n",
       " 'random.': 1,\n",
       " 'could': 8,\n",
       " 'expected,': 1,\n",
       " 'occur': 3,\n",
       " 'exclusively': 1,\n",
       " 'limiting': 2,\n",
       " 'case': 16,\n",
       " '1.': 3,\n",
       " 'practice,': 8,\n",
       " 'poorly': 1,\n",
       " 'conditioned': 2,\n",
       " 'nearby': 1,\n",
       " 'values': 15,\n",
       " 'well': 10,\n",
       " 'due': 11,\n",
       " 'finite': 10,\n",
       " 'sampling,': 1,\n",
       " 'representational': 1,\n",
       " 'networks,': 1,\n",
       " 'inductive': 1,\n",
       " 'bias,': 2,\n",
       " 'below': 4,\n",
       " '∼0.85,': 1,\n",
       " 'always': 11,\n",
       " 'oriented': 1,\n",
       " 'correctly.': 2,\n",
       " 'Between': 1,\n",
       " 'regions,': 1,\n",
       " 'sometimes': 2,\n",
       " 'picks': 1,\n",
       " 'wrong': 1,\n",
       " 'orientation': 2,\n",
       " 'initially,': 1,\n",
       " 'partially': 2,\n",
       " 'drifts': 1,\n",
       " 'towards': 5,\n",
       " 'distribution.': 5,\n",
       " 'observations': 2,\n",
       " 'sequence': 4,\n",
       " 'continuous': 15,\n",
       " '3c).': 1,\n",
       " 'experiment': 1,\n",
       " 'suggests': 3,\n",
       " '0.8,': 1,\n",
       " 'leaks': 12,\n",
       " 'unlikely': 3,\n",
       " 'happen': 2,\n",
       " 'practice.': 4,\n",
       " '2.3': 1,\n",
       " 'assumption': 3,\n",
       " 'maximally': 2,\n",
       " 'beneficial,': 2,\n",
       " 'given': 14,\n",
       " 'success': 3,\n",
       " 'RandAugment': 2,\n",
       " '[9]': 2,\n",
       " 'classification': 2,\n",
       " 'tasks.': 1,\n",
       " '18': 5,\n",
       " 'grouped': 2,\n",
       " 'into': 15,\n",
       " 'categories:': 1,\n",
       " 'pixel': 16,\n",
       " 'blitting': 5,\n",
       " '(x-flips,': 1,\n",
       " 'integer': 8,\n",
       " 'translation),': 1,\n",
       " 'general': 7,\n",
       " 'geometric': 16,\n",
       " 'transformations,': 5,\n",
       " 'transforms,': 1,\n",
       " 'image-space': 7,\n",
       " 'filtering,': 2,\n",
       " '[41],': 1,\n",
       " '[11].': 1,\n",
       " 'Details': 1,\n",
       " 'B.': 8,\n",
       " 'Note': 6,\n",
       " 'execute': 2,\n",
       " '2b),': 1,\n",
       " 'requires': 2,\n",
       " 'differentiable.': 1,\n",
       " 'implementing': 1,\n",
       " 'differentiable': 2,\n",
       " 'primitives': 1,\n",
       " 'offered': 1,\n",
       " 'framework.': 1,\n",
       " 'During': 1,\n",
       " 'training,': 3,\n",
       " 'pre-defined': 1,\n",
       " 'order.': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 7),\n",
       " ('a', 3),\n",
       " ('in', 2),\n",
       " ('of', 2),\n",
       " ('to', 2),\n",
       " ('they', 2),\n",
       " ('Plane', 2),\n",
       " ('Tree.', 2),\n",
       " ('said', 2),\n",
       " ('and', 2),\n",
       " ('Two', 1),\n",
       " ('Travellers,', 1),\n",
       " ('walking', 1),\n",
       " ('noonday', 1),\n",
       " ('sun,', 1),\n",
       " ('sought', 1),\n",
       " ('shade', 1),\n",
       " ('widespreading', 1),\n",
       " ('tree', 1),\n",
       " ('rest.', 1),\n",
       " ('As', 1),\n",
       " ('lay', 1),\n",
       " ('looking', 1),\n",
       " ('up', 1),\n",
       " ('among', 1),\n",
       " ('pleasant', 1),\n",
       " ('leaves,', 1),\n",
       " ('saw', 1),\n",
       " ('that', 1),\n",
       " ('it', 1),\n",
       " ('was', 1),\n",
       " ('\"How', 1),\n",
       " ('useless', 1),\n",
       " ('is', 1),\n",
       " ('Plane!\"', 1),\n",
       " ('one', 1),\n",
       " ('them.', 1),\n",
       " ('\"It', 1),\n",
       " ('bears', 1),\n",
       " ('no', 1),\n",
       " ('fruit', 1),\n",
       " ('whatever,', 1),\n",
       " ('only', 1),\n",
       " ('serves', 1),\n",
       " ('litter', 1),\n",
       " ('ground', 1),\n",
       " ('with', 1),\n",
       " ('leaves.\"', 1),\n",
       " ('\"Ungrateful', 1),\n",
       " ('creatures!\"', 1),\n",
       " ('voice', 1),\n",
       " ('from', 1),\n",
       " ('\"You', 1),\n",
       " ('lie', 1),\n",
       " ('here', 1),\n",
       " ('my', 1),\n",
       " ('cooling', 1),\n",
       " ('shade,', 1),\n",
       " ('yet', 1),\n",
       " ('you', 1),\n",
       " ('say', 1),\n",
       " ('I', 1),\n",
       " ('am', 1),\n",
       " ('useless!', 1),\n",
       " ('Thus', 1),\n",
       " ('ungratefully,', 1),\n",
       " ('O', 1),\n",
       " ('Jupiter,', 1),\n",
       " ('do', 1),\n",
       " ('men', 1),\n",
       " ('receive', 1),\n",
       " ('their', 1),\n",
       " ('blessings!\"', 1),\n",
       " ('Our', 1),\n",
       " ('best', 1),\n",
       " ('blessings', 1),\n",
       " ('are', 1),\n",
       " ('often', 1),\n",
       " ('least', 1),\n",
       " ('appreciated.', 1)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dict(cnt).items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_array = np.array(tfidf.get_feature_names_out())\n",
    "tfidf_sorting = np.argsort(response.toarray()).flatten()[::-1]\n",
    "\n",
    "n = 3\n",
    "top_n = feature_array[tfidf_sorting][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 27,  8, 28,  7, 13, 12, 11, 10,  9, 34, 15,  5,  4,  3,  2,  1,\n",
       "       14, 17, 16, 33, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32,\n",
       "        0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fruit', 'travellers', 'jupiter'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m      5\u001b[0m corpus \u001b[39m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mI would like to check this document\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mHow about one more document\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAim is to capture the key words from the corpus\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfrequency of words in a document is called term frequency\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     12\u001b[0m X \u001b[39m=\u001b[39m tfidf\u001b[39m.\u001b[39mfit_transform(corpus)\n\u001b[0;32m---> 13\u001b[0m feature_names \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(tfidf\u001b[39m.\u001b[39;49mget_feature_names())\n\u001b[1;32m     16\u001b[0m new_doc \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mcan key words in this new document be identified?\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m            \u001b[39m'\u001b[39m\u001b[39midf is the inverse document frequency caculcated for each of the words\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m responses \u001b[39m=\u001b[39m tfidf\u001b[39m.\u001b[39mtransform(new_doc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "corpus = [\n",
    "    'I would like to check this document',\n",
    "    'How about one more document',\n",
    "    'Aim is to capture the key words from the corpus',\n",
    "    'frequency of words in a document is called term frequency'\n",
    "]\n",
    "\n",
    "X = tfidf.fit_transform(corpus)\n",
    "feature_names = np.array(tfidf.get_feature_names())\n",
    "\n",
    "\n",
    "new_doc = ['can key words in this new document be identified?',\n",
    "           'idf is the inverse document frequency caculcated for each of the words']\n",
    "responses = tfidf.transform(new_doc)\n",
    "\n",
    "\n",
    "def get_top_tf_idf_words(response, top_n=2):\n",
    "    sorted_nzs = np.argsort(response.data)[:-(top_n+1):-1]\n",
    "    return feature_names[response.indices[sorted_nzs]]\n",
    "  \n",
    "print([get_top_tf_idf_words(response,2) for response in responses])\n",
    "\n",
    "#[array(['key', 'words'], dtype='<U9'),\n",
    "array(['frequency', 'words'], dtype='<U9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vertex_hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
