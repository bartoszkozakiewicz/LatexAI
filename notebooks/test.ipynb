{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Downloading arxiv-1.4.7-py3-none-any.whl (12 kB)\n",
      "Collecting feedparser (from arxiv)\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sgmllib3k (from feedparser->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6067 sha256=443568d42edbeed87a9a6598b5af21a84623f4e7c1fe63684e410422571e61ba\n",
      "  Stored in directory: /home/laszer/.cache/pip/wheels/65/7a/a7/78c287f64e401255dff4c13fdbc672fed5efbfd21c530114e1\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
      "Successfully installed arxiv-1.4.7 feedparser-6.0.10 sgmllib3k-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.tools.arxiv.tool import ArxivQueryRun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ArxivQueryRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published: 2021-03-17\n",
      "Title: Training GANs with Stronger Augmentations via Contrastive Discriminator\n",
      "Authors: Jongheon Jeong, Jinwoo Shin\n",
      "Summary: Recent works in Generative Adversarial Networks (GANs) are actively\n",
      "revisiting various data augmentation techniques as an effective way to prevent\n",
      "discriminator overfitting. It is still unclear, however, that which\n",
      "augmentations could actually improve GANs, and in particular, how to apply a\n",
      "wider range of augmentations in training. In this paper, we propose a novel way\n",
      "to address these questions by incorporating a recent contrastive representation\n",
      "learning scheme into the GAN discriminator, coined ContraD. This \"fusion\"\n",
      "enables the discriminators to work with much stronger augmentations without\n",
      "increasing their training instability, thereby preventing the discriminator\n",
      "overfitting issue in GANs more effectively. Even better, we observe that the\n",
      "contrastive learning itself also benefits from our GAN training, i.e., by\n",
      "maintaining discriminative features between real and fake samples, suggesting a\n",
      "strong coherence between the two worlds: good contrastive representations are\n",
      "also good for GAN discriminators, and vice versa. Our experimental results show\n",
      "that GANs with ContraD consistently improve FID and IS compared to other recent\n",
      "techniques incorporating data augmentations, still maintaining highly\n",
      "discriminative features in the discriminator in terms of the linear evaluation.\n",
      "Finally, as a byproduct, we also show that our GANs trained in an unsupervised\n",
      "manner (without labels) can induce many conditional generative models via a\n",
      "simple latent sampling, leveraging the learned features of ContraD. Code is\n",
      "available at https://github.com/jh-jeong/ContraD.\n",
      "\n",
      "Published: 2019-03-23\n",
      "Title: See Better Before Looking Closer: Weakly Supervised Data Augmentation Network for Fine-Grained Visual Classification\n",
      "Authors: Tao Hu, Honggang Qi, Qingming Huang, Yan Lu\n",
      "Summary: Data augmentation is usually adopted to increase the amount of training data,\n",
      "prevent overfitting and improve the performance of deep models. However, in\n",
      "practice, random data augmentation, such as random image cropping, is\n",
      "low-efficiency and might introduce many uncontrolled background noises. In this\n",
      "paper, we propose Weakly Supervised Data Augmentation Network (WS-DAN) to\n",
      "explore the potential of data augmentation. Specifically, for each training\n",
      "image, we first generate attention maps to represent the object's\n",
      "discriminative parts by weakly supervised learning. Next, we augment the image\n",
      "guided by these attention maps, including attention cropping and attention\n",
      "dropping. The proposed WS-DAN improves the classification accuracy in two\n",
      "folds. In the first stage, images can be seen better since more discriminative\n",
      "parts' features will be extracted. In the second stage, attention regions\n",
      "provide accurate location of object, which ensures our model to look at the\n",
      "object closer and further improve the performance. Comprehensive experiments in\n",
      "common fine-grained visual classification datasets show that our WS-DAN\n",
      "surpasses the state-of-the-art methods, which demonstrates its effectiveness.\n",
      "\n",
      "Published: 2023-01-24\n",
      "Title: Data Augmentation Alone Can Improve Adversarial Training\n",
      "Authors: Lin Li, Michael Spratling\n",
      "Summary: Adversarial training suffers from the issue of robust overfitting, which\n",
      "seriously impairs its generalization performance. Data augmentation, which is\n",
      "effective at preventing overfitting in standard training, has been observed by\n",
      "many previous works to be ineffective in mitigating overfitting in adversarial\n",
      "training. This work proves that, contrary to previous findings, data\n",
      "augmentation alone can significantly boost accuracy and robustness in\n",
      "adversarial training. We find that the hardness and the diversity of data\n",
      "augmentation are important factors in combating robust overfitting. In general,\n",
      "diversity can improve both accuracy and robustness, while hardness can boost\n",
      "robustness at the cost of accuracy within a certa\n"
     ]
    }
   ],
   "source": [
    "s = 'In this paper, we demonstrate how to use a wide range of augmentations to prevent the discriminator from overfitting, while ensuring that none of the augmentations leak to the generated images.'\n",
    "print(a(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_langchain",
   "language": "python",
   "name": "llms_langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
