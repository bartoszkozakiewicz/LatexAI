Training Generative Adversarial Networks with
Limited Data
Tero Karras
NVIDIA
Miika Aittala
NVIDIA
Janne Hellsten
NVIDIA
Samuli Laine
NVIDIA
Jaakko Lehtinen
NVIDIA and Aalto University
Timo Aila
NVIDIA
Abstract
Training generative adversarial networks (GAN) using too little data typically leads
to discriminator overfitting, causing training to diverge. We propose an adaptive
discriminator augmentation mechanism that significantly stabilizes training in
limited data regimes. The approach does not require changes to loss functions
or network architectures, and is applicable both when training from scratch and
when fine-tuning an existing GAN on another dataset. We demonstrate, on several
datasets, that good results are now possible using only a few thousand training
images, often matching StyleGAN2 results with an order of magnitude fewer
images. We expect this to open up new application domains for GANs. We also
find that the widely used CIFAR-10 is, in fact, a limited data benchmark, and
improve the record FID from 5.59 to 2.42.
1 Introduction
The increasingly impressive results of generative adversarial networks (GAN) [14, 32, 31, 5, 19,
20, 21] are fueled by the seemingly unlimited supply of images available online. Still, it remains
challenging to collect a large enough set of images for a specific application that places constraints
on subject type, image quality, geographical location, time period, privacy, copyright status, etc.
The difficulties are further exacerbated in applications that require the capture of a new, custom
dataset: acquiring, processing, and distributing the ∼ 105 − 106
images required to train a modern
high-quality, high-resolution GAN is a costly undertaking. This curbs the increasing use of generative
models in fields such as medicine [47]. A significant reduction in the number of images required
therefore has the potential to considerably help many applications.
The key problem with small datasets is that the discriminator overfits to the training examples; its
feedback to the generator becomes meaningless and training starts to diverge [2, 48]. In almost all
areas of deep learning [40], dataset augmentation is the standard solution against overfitting. For
example, training an image classifier under rotation, noise, etc., leads to increasing invariance to these
semantics-preserving distortions — a highly desirable quality in a classifier [17, 8, 9]. In contrast,
a GAN trained under similar dataset augmentations learns to generate the augmented distribution
[50, 53]. In general, such “leaking” of augmentations to the generated samples is highly undesirable.
For example, a noise augmentation leads to noisy results, even if there is none in the dataset.
In this paper, we demonstrate how to use a wide range of augmentations to prevent the discriminator
from overfitting, while ensuring that none of the augmentations leak to the generated images. We
start by presenting a comprehensive analysis of the conditions that prevent the augmentations from
leaking. We then design a diverse set of augmentations, and an adaptive control scheme that enables
the same approach to be used regardless of the amount of training data, properties of the dataset, or
the exact training setup (e.g., training from scratch or transfer learning [33, 44, 45, 34]).
34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
arXiv:2006.06676v2 [cs.CV] 7 Oct 2020
t = 0M 1M 5M 10M 15M 20M 25M
Training progress (number of reals shown to D)
5
10
20
50
100
FID median/min/max (3 runs)
FID
140k
70k
50k
30k
20k
10k
5k
t = 0M 2M 4M 6M 8M 10M 12M 14M
Training progress (reals shown to D)
-6
-4
-2
0
2
4
6
D(x)
Real Generated Validation Best FID
t = 0M 2M 4M 6M 8M 10M 12M 14M
Training progress (reals shown to D)
-6
-4
-2
0
2
4
6
D(x)
Real Generated Validation Best FID
(a) Convergence of FFHQ (256 × 256) (b) Discriminator outputs, 50k (c) Discriminator outputs, 20k
Figure 1: (a) Convergence with different training set sizes. “140k” means that we amplified the 70k
dataset by 2× through x-flips; we do not use data amplification in any other case. (b,c) Evolution of
discriminator outputs during training. Each vertical slice shows a histogram of D(x), i.e., raw logits.
We demonstrate, on several datasets, that good results are now possible using only a few thousand
images, often matching StyleGAN2 results with an order of magnitude fewer images. Furthermore,
we show that the popular CIFAR-10 benchmark suffers from limited data and achieve a new record
Fréchet inception distance (FID) [18] of 2.42, significantly improving over the current state of the art
of 5.59 [52]. We also present METFACES, a high-quality benchmark dataset for limited data scenarios.
Our implementation and models are available at https://github.com/NVlabs/stylegan2-ada
2 Overfitting in GANs
We start by studying how the quantity of available training data affects GAN training. We approach
this by artificially subsetting larger datasets (FFHQ and LSUN CAT) and observing the resulting
dynamics. For our baseline, we considered StyleGAN2 [21] and BigGAN [5, 38]. Based on initial
testing, we settled on StyleGAN2 because it provided more predictable results with significantly
lower variance between training runs (see Appendix A). For each run, we randomize the subset of
training data, order of training samples, and network initialization. To facilitate extensive sweeps
over dataset sizes and hyperparameters, we use a downscaled 256 × 256 version of FFHQ and a
lighter-weight configuration that reaches the same quality as the official StyleGAN2 config F for
this dataset, but runs 4.6× faster on NVIDIA DGX-1.1 We measure quality by computing FID
between 50k generated images and all available training images, as recommended by Heusel et
al. [18], regardless of the subset actually used for training.
Figure 1a shows our baseline results for different subsets of FFHQ. Training starts the same way in
each case, but eventually the progress stops and FID starts to rise. The less training data there is, the
earlier this happens. Figure 1b,c shows the discriminator output distributions for real and generated
images during training. The distributions overlap initially but keep drifting apart as the discriminator
becomes more and more confident, and the point where FID starts to deteriorate is consistent with the
loss of sufficient overlap between distributions. This is a strong indication of overfitting, evidenced
further by the drop in accuracy measured for a separate validation set. We propose a way to tackle
this problem by employing versatile augmentations that prevent the discriminator from becoming
overly confident.
2.1 Stochastic discriminator augmentation
By definition, any augmentation that is applied to the training dataset will get inherited to the
generated images [14]. Zhao et al. [53] recently proposed balanced consistency regularization (bCR)
as a solution that is not supposed to leak augmentations to the generated images. Consistency
regularization states that two sets of augmentations, applied to the same input image, should yield the
same output [35, 27]. Zhao et al. add consistency regularization terms for the discriminator loss, and
enforce discriminator consistency for both real and generated images, whereas no augmentations or
consistency loss terms are applied when training the generator (Figure 2a). As such, their approach
1We use 2× fewer feature maps, 2× larger minibatch, mixed-precision training for layers at ≥ 322
,
η = 0.0025, γ = 1, and exponential moving average half-life of 20k images for generator weights.
2
Latents Reals Latents
G G
D D
Aug Aug
G loss D loss
– f (x) – f (x) (x – y) – f (–x)
2 (x – y)
2
(a) bCR (previous work)
Latents
G
D
G loss
– f (x)
Aug
Reals
D loss
– f (x)
D
Latents
G
– f (–x)
Aug Aug
p
(b) Ours
p = 0 p = 0.1 p = 0.2 p = 0.3 p = 0.5 p = 0.8
(c) Effect of augmentation probability p
Figure 2: (a,b) Flowcharts for balanced consistency regularization (bCR) [53] and our stochastic
discriminator augmentations. The blue elements highlight operations related to augmentations,
while the rest implement standard GAN training with generator G and discriminator D [14]. The
orange elements indicate the loss function and the green boxes mark the network being trained. We
use the non-saturating logistic loss [14] f(x) = log (sigmoid(x)). (c) We apply a diverse set of
augmentations to every image that the discriminator sees, controlled by an augmentation probability p.
effectively strives to generalize the discriminator by making it blind to the augmentations used in
the CR term. However, meeting this goal opens the door for leaking augmentations, because the
generator will be free to produce images containing them without any penalty. In Section 4, we show
experimentally that bCR indeed suffers from this problem, and thus its effects are fundamentally
similar to dataset augmentation.
Our solution is similar to bCR in that we also apply a set of augmentations to all images shown to the
discriminator. However, instead of adding separate CR loss terms, we evaluate the discriminator only
using augmented images, and do this also when training the generator (Figure 2b). This approach that
we call stochastic discriminator augmentation is therefore very straightforward. Yet, this possibility
has received little attention, possibly because at first glance it is not obvious if it even works: if the
discriminator never sees what the training images really look like, it is not clear if it can guide the
generator properly (Figure 2c). We will therefore first investigate the conditions under which this
approach will not leak an augmentation to the generated images, and then build a full pipeline out of
such transformations.
2.2 Designing augmentations that do not leak
Discriminator augmentation corresponds to putting distorting, perhaps even destructive goggles on
the discriminator, and asking the generator to produce samples that cannot be distinguished from the
training set when viewed through the goggles. Bora et al. [4] consider a similar problem in training
GANs under corrupted measurements, and show that the training implicitly undoes the corruptions
and finds the correct distribution, as long as the corruption process is represented by an invertible
transformation of probability distributions over the data space. We call such augmentation operators
non-leaking.
The power of these invertible transformations is that they allow conclusions about the equality or
inequality of the underlying sets to be drawn by observing only the augmented sets. It is crucial to
understand that this does not mean that augmentations performed on individual images would need to
be undoable. For instance, an augmentation as extreme as setting the input image to zero 90% of the
time is invertible in the probability distribution sense: it would be easy, even for a human, to reason
about the original distribution by ignoring black images until only 10% of the images remain. On the
other hand, random rotations chosen uniformly from {0
◦
, 90◦
, 180◦
, 270◦} are not invertible: it is
impossible to discern differences among the orientations after the augmentation.
The situation changes if this rotation is only executed at a probability p < 1: this increases the
relative occurrence of 0
◦
, and now the augmented distributions can match only if the generated
images have correct orientation. Similarly, many other stochastic augmentations can be designed to
be non-leaking on the condition that they are skipped with a non-zero probability. Appendix C shows
that this can be made to hold for a large class of widely used augmentations, including deterministic
mappings (e.g., basis transformations), additive noise, transformation groups (e.g, image or color
space rotations, flips and scaling), and projections (e.g., cutout [11]). Furthermore, composing
non-leaking augmentations in a fixed order yields an overall non-leaking augmentation.
In Figure 3 we validate our analysis by three practical examples. Isotropic scaling with log-normal
distribution is an example of an inherently safe augmentation that does not leak regardless of the
3
A B
p = 0.75 0.80 0.85 0.90 0.95
5
10
20
50
1.00
FID
A B
(a) Isotropic image scaling
C D E
p = 0.75 0.80 0.85 0.90 0.95
5
10
20
50
1.00
FID
C
D
E
(b) Random 90◦
rotations
F G
p = 0.75 0.80 0.85 0.90 0.95
5
10
20
50
1.00
FID
F
G
(c) Color transformations
Figure 3: Leaking behavior of three example augmentations, shown as FID w.r.t. the probability of
executing the augmentation. Each dot represents a complete training run, and the blue Gaussian
mixture is a visualization aid. The top row shows generated example images from selected training
runs, indicated by uppercase letters in the plots.
value of p (Figure 3a). However, the aforementioned rotation by a random multiple of 90◦ must be
skipped at least part of the time (Figure 3b). When p is too high, the generator cannot know which
way the generated images should face and ends up picking one of the possibilities at random. As
could be expected, the problem does not occur exclusively in the limiting case of p = 1. In practice,
the training setup is poorly conditioned for nearby values as well due to finite sampling, finite
representational power of the networks, inductive bias, and training dynamics. When p remains below
∼0.85, the generated images are always oriented correctly. Between these regions, the generator
sometimes picks a wrong orientation initially, and then partially drifts towards the correct distribution.
The same observations hold for a sequence of continuous color augmentations (Figure 3c). This
experiment suggests that as long as p remains below 0.8, leaks are unlikely to happen in practice.
2.3 Our augmentation pipeline
We start from the assumption that a maximally diverse set of augmentations is beneficial, given the
success of RandAugment [9] in image classification tasks. We consider a pipeline of 18 transformations that are grouped into 6 categories: pixel blitting (x-flips, 90◦
rotations, integer translation), more
general geometric transformations, color transforms, image-space filtering, additive noise [41], and
cutout [11]. Details of the individual augmentations are given in Appendix B. Note that we execute
augmentations also when training the generator (Figure 2b), which requires the augmentations to be
differentiable. We achieve this by implementing them using standard differentiable primitives offered
by the deep learning framework.
During training, we process each image shown to the discriminator using a pre-defined set of
transformations in a fixed order. The strength of augmentations is controlled by the scalar p ∈ [0, 1],
so that each transformation is applied with probability p or skipped with probability 1 − p. We
always use the same value of p for all transformations. The randomization is done separately for each
augmentation and for each image in a minibatch. Given that there are many augmentations in the
pipeline, even fairly small values of p make it very unlikely that the discriminator sees a clean image
(Figure 2c). Nonetheless, the generator is guided to produce only clean images as long as p remains
below the practical safety limit.
In Figure 4 we study the effectiveness of stochastic discriminator augmentation by performing
exhaustive sweeps over p for different augmentation categories and dataset sizes. We observe that
it can improve the results significantly in many cases. However, the optimal augmentation strength
depends heavily on the amount of training data, and not all augmentation categories are equally
useful in practice. With a 2k training set, the vast majority of the benefit came from pixel blitting
and geometric transforms. Color transforms were modestly beneficial, while image-space filtering,
noise, and cutout were not particularly useful. In this case, the best results were obtained using strong
augmentations. The curves also indicate some of the augmentations becoming leaky when p → 1.
With a 10k training set, the higher values of p were less helpful, and with 140k the situation was
markedly different: all augmentations were harmful. Based on these results, we choose to use only
4
p = 0.0 0.2 0.4 0.6 0.8 1.0
2
5
10
20
50
100
FID
Blit
Geom
Color
Filter
Noise
Cutout
p = 0.0 0.2 0.4 0.6 0.8 1.0
2
5
10
20
50
100
FID
Blit
Geom
Color
Filter
Noise
Cutout
p = 0.0 0.2 0.4 0.6 0.8 1.0
2
5
10
20
50
100
FID
Blit
Geom
Color
Filter
Noise
Cutout
t = 0M 1M 5M 10M 15M 20M 25M
10
20
50
100
200
FID
p = 0.0
p = 0.2
p = 0.4
p = 0.8
(a) FFHQ-2k (b) FFHQ-10k (c) FFHQ-140k (d) Convergence, 10k, Geom
Figure 4: (a-c) Impact of p for different augmentation categories and dataset sizes. The dashed gray
line indicates baseline FID without augmentations. (d) Convergence curves for selected values of p
using geometric augmentations with 10k training images.
pixel blitting, geometric, and color transforms for the rest of our tests. Figure 4d shows that while
stronger augmentations reduce overfitting, they also slow down the convergence.
In practice, the sensitivity to dataset size mandates a costly grid search, and even so, relying on any
fixed p may not be the best choice. Next, we address these concerns by making the process adaptive.
3 Adaptive discriminator augmentation
Ideally, we would like to avoid manual tuning of the augmentation strength and instead control it
dynamically based on the degree of overfitting. Figure 1 suggests a few possible approaches for this.
The standard way of quantifying overfitting is to use a separate validation set and observe its behavior
relative to the training set. From the figure we see that when overfitting kicks in, the validation set
starts behaving increasingly like the generated images. This is a quantifiable effect, albeit with the
drawback of requiring a separate validation set when training data may already be in short supply.
We can also see that with the non-saturating loss [14] used by StyleGAN2, the discriminator outputs
for real and generated images diverge symmetrically around zero as the situation gets worse. This
divergence can be quantified without a separate validation set.
Let us denote the discriminator outputs by Dtrain, Dvalidation, and Dgenerated for the training set, validation set, and generated images, respectively, and their mean over N consecutive minibatches by
E[·]. In practice we use N = 4, which corresponds to 4 × 64 = 256 images. We can now turn our
observations about Figure 1 into two plausible overfitting heuristics:
rv =
E[Dtrain] − E[Dvalidation]
E[Dtrain] − E[Dgenerated]
rt = E[sign(Dtrain)] (1)
For both heuristics, r = 0 means no overfitting and r = 1 indicates complete overfitting, and our
goal is to adjust the augmentation probability p so that the chosen heuristic matches a suitable target
value. The first heuristic, rv, expresses the output for a validation set relative to the training set and
generated images. Since it assumes the existence of a separate validation set, we include it mainly
as a comparison method. The second heuristic, rt, estimates the portion of the training set that gets
positive discriminator outputs. We have found this to be far less sensitive to the chosen target value
and other hyperparameters than the obvious alternative of looking at E[Dtrain] directly.
We control the augmentation strength p as follows. We initialize p to zero and adjust its value once
every four minibatches2 based on the chosen overfitting heuristic. If the heuristic indicates too
much/little overfitting, we counter by incrementing/decrementing p by a fixed amount. We set the
adjustment size so that p can rise from 0 to 1 sufficiently quickly, e.g., in 500k images. After every
step we clamp p from below to 0. We call this variant adaptive discriminator augmentation (ADA).
In Figure 5a,b we measure how the target value affects the quality obtainable using these heuristics.
We observe that rv and rt are both effective in preventing overfitting, and that they both improve the
results over the best fixed p found using grid search. We choose to use the more realistic rt heuristic
in all subsequent tests, with 0.6 as the target value. Figure 5c shows the resulting p over time. With a
2k training set, augmentations were applied almost always towards the end. This exceeds the practical
2This choice follows from StyleGAN2 training loop layout. The results are not sensitive to this parameter.
5
0.2 0.3 0.4 0.5 0.6 0.7 0.8
5
10
20
FID
p = 0.4
p = 0.2
p = 0.2
2k 10k 50k
0.3 0.4 0.5 0.6 0.7 0.8 0.9
5
10
20
FID
p = 0.4
p = 0.2
p = 0.2
p = 0.0
2k 10k 50k 140k
t = 0M 1M 5M 10M 15M 20M 25M
0.2
0.4
0.6
0.8
p
2k 10k 50k 140k
t = 0M 1M 5M 10M 15M 20M 25M
0.2
0.4
0.6
0.8
r
2k 10k 50k 140k
(a) rv target sweep (b) rt target sweep (c) Evolution of p over training (d) Evolution of rt
Figure 5: Behavior of our adaptive augmentation strength heuristics in FFHQ. (a,b) FID for different
training set sizes as a function of the target value for rv and rt. The dashed horizontal lines indicate
the best fixed augmentation probability p found using grid search, and the dashed vertical line marks
the target value we will use in subsequent tests. (c) Evolution of p over the course of training using
heuristic rt. (d) Evolution of rt values over training. Dashes correspond to the fixed p values in (b).
t = 0M 1M 5M 10M 15M 20M 25M
5
10
20
50
100
FID median/min/max (3 runs)FID
5k
10k
20k
50k
140k
t = 0M 5M 10M 15M 20M 25M
-3
-2
-1
0
1
2
3
D(x)
Real Generated Validation Best FID
No augment With ADA
1M 5M 25M
(a) With adaptive augmentation (b) Discriminator outputs, 20k (c) Discriminator gradients, 10k
Figure 6: (a) Training curves for FFHQ with different training set sizes using adaptive augmentation.
(b) The supports of real and generated images continue to overlap. (c) Example magnitudes of the
gradients the generator receives from the discriminator as the training progresses.
safety limit after which some augmentations become leaky, indicating that the augmentations were
not powerful enough. Indeed, FID started deteriorating after p ≈ 0.5 in this extreme case. Figure 5d
shows the evolution of rt with adaptive vs fixed p, showing that a fixed p tends to be too strong in the
beginning and too weak towards the end.
Figure 6 repeats the setup from Figure 1 using ADA. Convergence is now achieved regardless of the
training set size and overfitting no longer occurs. Without augmentations, the gradients the generator
receives from the discriminator become very simplistic over time— the discriminator starts to pay
attention to only a handful of features, and the generator is free to create otherwise non-sensical
images. With ADA, the gradient field stays much more detailed which prevents such deterioration. In
an interesting parallel, it has been shown that loss functions can be made significantly more robust in
regression settings by using similar image augmentation ensembles [23].
4 Evaluation
We start by testing our method against a number of alternatives in FFHQ and LSUN CAT, first in
a setting where a GAN is trained from scratch, then by applying transfer learning on a pre-trained
GAN. We conclude with results for several smaller datasets.
4.1 Training from scratch
Figure 7 shows our results in FFHQ and LSUN CAT across training set sizes, demonstrating that our
adaptive discriminator augmentation (ADA) improves FIDs substantially in limited data scenarios.
We also show results for balanced consistency regularization (bCR) [53], which has not been studied
in the context of limited data before. We find that bCR can be highly effective when the lack of data
is not too severe, but also that its set of augmentations leaks to the generated images. In this example,
we used only xy-translations by integer offsets for bCR, and Figure 7d shows that the generated
images get jittered as a result. This means that bCR is essentially a dataset augmentation and needs
to be limited to symmetries that actually benefit the training data, e.g., x-flip is often acceptable but
6
1k 2k 5k 10k 20k 50k 140k
5
10
20
50
FID
Baseline
ADA (Ours)
bCR
ADA+bCR
1k 2k 5k 10k 20k 50k 200k
10
20
50
100
FID
Baseline
ADA (Ours)
bCR
ADA+bCR
Dataset Baseline ADA + bCR FFHQ
1k 100.16 21.29 22.61
5k 49.68 10.96 10.58
10k 30.74 8.13 7.53
30k 12.31 5.46 4.57
70k 5.28 4.30 3.91
140k 3.71 3.81 3.62
LSUN CAT
1k 186.91 43.25 38.82
5k 96.44 16.95 16.80
10k 50.66 13.13 12.90
30k 15.90 10.50 9.68
100k 8.56 9.26 8.73
200k 7.98 9.22 9.03
ADA Real
bCR Real
(a) FFHQ (256 × 256) (b) LSUN CAT (256 × 256) (c) Median FID (d) Mean image
Figure 7: (a-c) FID as a function of training set size, reported as median/min/max over 3 training runs.
(d) Average of 10k random images generated using the networks trained with 5k subset of FFHQ.
ADA matches the average of real data, whereas the xy-translation augmentation in bCR [53] has
leaked to the generated images, significantly blurring the average image.
FFHQ (256 × 256) 2k 10k 140k
Baseline 78.80 ±2.31 30.73 ±0.48 3.66 ±0.10
PA-GAN [48] 56.49 ±7.28 27.71 ±2.77 3.78 ±0.06
WGAN-GP [15] 79.19 ±6.30 35.68 ±1.27 6.54 ±0.37
zCR [53] 71.61 ±9.64 23.02 ±2.09 3.45 ±0.19
Auxiliary rotation [6] 66.64 ±3.64 25.37 ±1.45 4.16 ±0.05
Spectral norm [31] 88.71 ±3.18 38.58 ±3.14 4.60 ±0.19
Shallow mapping 71.35 ±7.20 27.71 ±1.96 3.59 ±0.22
Adaptive dropout 67.23 ±4.76 23.33 ±0.98 4.16 ±0.05
ADA (Ours) 16.49 ±0.65 8.29 ±0.31 3.88 ±0.13
Baseline
0.25 0.5 0.75 1 1.5 2
2
5
10
20
50
100
FID
2k 10k 50k 140k
ADA
0.25 0.5 0.75 1 1.5 2
2
5
10
20
50
100
FID
2k 10k 50k 140k
(a) Comparison methods (b) Discriminator capacity sweeps
Figure 8: (a) We report the mean and standard deviation for each comparison method, calculated over
3 training runs. (b) FID as a function of discriminator capacity, reported as median/min/max over
3 training runs. We scale the number of feature maps uniformly across all layers by a given factor
(x-axis). The baseline configuration (no scaling) is indicated by the dashed vertical line.
y-flip only rarely. Meanwhile, with ADA the augmentations do not leak, and thus the same diverse set
of augmentations can be safely used in all datasets. We also find that the benefits for ADA and bCR
are largely additive. We combine ADA and bCR so that ADA is first applied to the input image (real
or generated), and bCR then creates another version of this image using its own set of augmentations.
Qualitative results are shown in Appendix A.
In Figure 8a we further compare our adaptive augmentation against a wider set of alternatives:
PA-GAN [48], WGAN-GP [15], zCR [53], auxiliary rotations [6], and spectral normalization [31].
We also try modifying our baseline to use a shallower mapping network, which can be trained with
less data, borrowing intuition from DeLiGAN [16]. Finally, we try replacing our augmentations with
multiplicative dropout [42], whose per-layer strength is driven by our adaptation algorithm. We spent
considerable effort tuning the parameters of all these methods, see Appendix D. We can see that ADA
gave significantly better results than the alternatives. While PA-GAN is somewhat similar to our
method, its checksum task was not strong enough to prevent overfitting in our tests. Figure 8b shows
that reducing the discriminator capacity is generally harmful and does not prevent overfitting.
4.2 Transfer learning
Transfer learning reduces the training data requirements by starting from a model trained using
some other dataset, instead of a random initialization. Several authors have explored this in the
context of GANs [44, 45, 34], and Mo et al. [33] recently showed strong results by freezing the
highest-resolution layers of the discriminator during transfer (Freeze-D).
We explore several transfer learning setups in Figure 9, using the best Freeze-D configuration found
for each case with grid search. Transfer learning gives significantly better results than from-scratch
training, and its success seems to depend primarily on the diversity of the source dataset, instead of
the similarity between subjects. For example, FFHQ (human faces) can be trained equally well from
7
t = 0M 1M 2M 3M 4M 5M
5
10
20
50
FID
FFHQ-1k
+ Freeze-D
FFHQ-5k
+ Freeze-D
FFHQ-20k
+ Freeze-D
t = 0M 1M 2M 3M 4M 5M
5
10
20
50
FID
FFHQ-1k
+ Freeze-D
FFHQ-5k
+ Freeze-D
FFHQ-20k
+ Freeze-D
1k 2k 5k 10k 20k
2
5
10
20
50
FID
Baseline
+ Transfer
+ Freeze-D
ADA (Ours)
+ Transfer
+ Freeze-D
1k 2k 5k 10k 20k
2
5
10
20
FID
LSUN Cat from CelebA-HQ
LSUN Cat from FFHQ
LSUN Cat from LSUN Dog
FFHQ from CelebA-HQ
FFHQ from LSUN Dog
(a) Without ADA (b) With ADA (c) Dataset sizes (d) Datasets
Figure 9: Transfer learning FFHQ starting from a pre-trained CELEBA-HQ model, both 256 × 256.
(a) Training convergence for our baseline method and Freeze-D [33]. (b) The same configurations
with ADA. (c) FIDs as a function of dataset size. (d) Effect of source and target datasets.
METFACES (new dataset) BRECAHAD AFHQ CAT, DOG, WILD (5122
) CIFAR-10
1336 img, 10242
, transfer learning from FFHQ 1944 img, 5122
5153 img 4739 img 4738 img 50k, 10 cls, 322
Figure 10: Example generated images for several datasets with limited amount of training data, trained
using ADA. We use transfer learning with METFACES and train other datasets from scratch. See
Appendix A for uncurated results and real images, and Appendix D for our training configurations.
CELEBA-HQ (human faces, low diversity) or LSUN DOG (more diverse). LSUN CAT, however,
can only be trained from LSUN DOG, which has comparable diversity, but not from the less diverse
datasets. With small target dataset sizes, our baseline achieves reasonable FID quickly, but the
progress soon reverts as training continues. ADA is again able to prevent the divergence almost
completely. Freeze-D provides a small but reliable improvement when used together with ADA but is
not able to prevent the divergence on its own.
4.3 Small datasets
We tried our method with several datasets that consist of a limited number of training images
(Figure 10). METFACES is our new dataset of 1336 high-quality faces extracted from the collection of
Metropolitan Museum of Art (https://metmuseum.github.io/). BRECAHAD [1] consists of only
162 breast cancer histopathology images (1360 × 1024); we reorganized these into 1944 partially
overlapping crops of 5122
. Animal faces (AFHQ) [7] includes ∼5k closeups per category for dogs,
cats, and wild life; we treated these as three separate datasets and trained a separate network for each
of them. CIFAR-10 includes 50k tiny images in 10 categories [25].
Figure 11 reveals that FID is not an ideal metric for small datasets, because it becomes dominated
by the inherent bias when the number of real images is insufficient. We find that kernel inception
distance (KID) [3]— that is unbiased by design — is more descriptive in practice and see that ADA
provides a dramatic improvement over baseline StyleGAN2. This is especially true when training
from scratch, but transfer learning also benefits from ADA. In the widely used CIFAR-10 benchmark,
we improve the SOTA FID from 5.59 to 2.42 and inception score (IS) [37] from 9.58 to 10.24 in the
class-conditional setting (Figure 11b). This large improvement portrays CIFAR-10 as a limited data
benchmark. We also note that CIFAR-specific architecture tuning had a significant effect.
8
Dataset Method
Scratch Transfer + Freeze-D
FID KID KID KID
×103 ×103 ×103
METFACES
Baseline 57.26 35.66 3.16 2.05
ADA 18.22 2.41 0.81 1.33
BRECAHAD Baseline 97.72 89.76 18.07 6.94
ADA 15.71 2.88 3.36 1.91
AFHQ CAT
Baseline 5.13 1.54 1.09 1.00
ADA 3.55 0.66 0.44 0.35
AFHQ DOG
Baseline 19.37 9.62 4.63 2.80
ADA 7.40 1.16 1.40 1.12
AFHQ WILD
Baseline 3.48 0.77 0.31 0.12
ADA 3.05 0.45 0.15 0.14
Method Unconditional Conditional
FID ↓ IS ↑ FID ↓ IS ↑
ProGAN [19] 15.52 8.56 ±0.06 – –
AutoGAN [13] 12.42 8.55 ±0.10 – –
BigGAN [5] – – 14.73 9.22
+ Tuning [22] – – 8.47 9.07 ±0.13
MultiHinge [22] – – 6.40 9.58 ±0.09
FQ-GAN [52] – – 5.59 ±0.12 8.48
Baseline 8.32 ±0.09 9.21 ±0.09 6.96 ±0.41 9.53 ±0.06
+ ADA (Ours) 5.33 ±0.35 10.02 ±0.07 3.49 ±0.17 10.24 ±0.07
+ Tuning (Ours) 2.92 ±0.05 9.83 ±0.04 2.42 ±0.04 10.14 ±0.09
(a) Small datasets (b) CIFAR-10
Figure 11: (a) Several small datasets trained with StyleGAN2 baseline (config F) and ADA, from
scratch and using transfer learning. We used FFHQ-140K with matching resolution as a starting
point for all transfers. We report the best KID, and compute FID using the same snapshot. (c) Mean
and standard deviation for CIFAR-10, computed from the best scores of 5 training runs. For the
comparison methods we report the average scores when available, and the single best score otherwise.
The best IS and FID were searched separately [22], and often came from different snapshots. We
computed the FID for Progressive GAN [19] using the publicly available pre-trained network.
5 Conclusions
We have shown that our adaptive discriminator augmentation reliably stabilizes training and vastly
improves the result quality when training data is in short supply. Of course, augmentation is not a
substitute for real data— one should always try to collect a large, high-quality set of training data
first, and only then fill the gaps using augmentation. As future work, it would be worthwhile to search
for the most effective set of augmentations, and to see if recently published techniques, such as the
U-net discriminator [38] or multi-modal generator [39], could also help with limited data.
Enabling ADA has a negligible effect on the energy consumption of training a single model. As such,
using it does not increase the cost of training models for practical use or developing methods that
require large-scale exploration. For reference, Appendix E provides a breakdown of all computation
that we performed related to this paper; the project consumed a total of 325 MWh of electricity, or
135 single-GPU years, the majority of which can be attributed to extensive comparisons and sweeps.
Interestingly, the core idea of discriminator augmentations was independently discovered by three
other research groups in parallel work: Z. Zhao et al. [54], Tran et al. [43], and S. Zhao et al. [51].
We recommend these papers as they all offer a different set of intuition, experiments, and theoretical justifications. While two of these papers [54, 51] propose essentially the same augmentation
mechanism as we do, they study the absence of leak artifacts only empirically. The third paper
[43] presents a theoretical justification based on invertibility, but arrives at a different argument
that leads to a more complex network architecture, along with significant restrictions on the set of
possible augmentations. None of these works consider the possibility of tuning augmentation strength
adaptively. Our experiments in Section 3 show that the optimal augmentation strength not only varies
between datasets of different content and size, but also over the course of training — even an optimal
set of fixed augmentation parameters is likely to leave performance on the table.
A direct comparison of results between the parallel works is difficult because the only dataset used
in all papers is CIFAR-10. Regrettably, the other three papers compute FID using 10k generated
images and 10k validation images (FID-10k), while we use follow the original recommendation of
Heusel et al. [18] and use 50k generated images and all training images. Their FID-10k numbers are
thus not comparable to the FIDs in Figure 11b. For this reason we also computed FID-10k for our
method, obtaining 7.01 ± 0.06 for unconditional and 6.54 ± 0.06 for conditional. These compare
favorably to parallel work’s unconditional 9.89 [51] or 10.89 [43], and conditional 8.30 [54] or 8.49
[51]. It seems likely that some combination of the ideas from all four papers could further improve
our results. For example, more diverse set of augmentations or contrastive regularization [54] might
be worth testing.
Acknowledgements We thank David Luebke for helpful comments; Tero Kuosmanen and Sabu
Nadarajan for their support with compute infrastructure; and Edgar Schönfeld for guidance on setting
up unconditional BigGAN.
9
Broader impact
Data-driven generative modeling means learning a computational recipe for generating complicated
data based purely on examples. This is a foundational problem in machine learning. In addition
to their fundamental nature, generative models have several uses within applied machine learning
research as priors, regularizers, and so on. In those roles, they advance the capabilities of computer
vision and graphics algorithms for analyzing and synthesizing realistic imagery.
The methods presented in this work enable high-quality generative image models to be trained using
significantly less data than required by existing approaches. It thereby primarily contributes to the
deep technical question of how much data is enough for generative models to succeed in picking up
the necessary commonalities and relationships in the data.
From an applied point of view, this work contributes to efficiency; it does not introduce fundamental
new capabilities. Therefore, it seems likely that the advances here will not substantially affect the
overall themes— surveillance, authenticity, privacy, etc.— in the active discussion on the broader
impacts of computer vision and graphics.
Specifically, generative models’ implications on image and video authenticity is a topic of active
discussion. Most attention revolves around conditional models that allow semantic control and
sometimes manipulation of existing images. Our algorithm does not offer direct controls for highlevel attributes (e.g., identity, pose, expression of people) in the generated images, nor does it enable
direct modification of existing images. However, over time and through the work of other researchers,
our advances will likely lead to improvements in these types of models as well.
The contributions in this work make it easier to train high-quality generative models with custom sets
of images. By this, we eliminate, or at least significantly lower, the barrier for applying GAN-type
models in many applied fields of research. We hope and believe that this will accelerate progress in
several such fields. For instance, modeling the space of possible appearance of biological specimens
(tissues, tumors, etc.) is a growing field of research that appears to chronically suffer from limited
high-quality data. Overall, generative models hold promise for increased understanding of the
complex and hard-to-pinpoint relationships in many real-world phenomena; our work hopefully
increases the breadth of phenomena that can be studied.
References
[1] A. Aksac, D. J. Demetrick, T. Ozyer, and R. Alhajj. BreCaHAD: A dataset for breast cancer histopathological annotation and diagnosis. BMC Research Notes, 12, 2019.
[2] M. Arjovsky and L. Bottou. Towards principled methods for training generative adversarial networks. In
Proc. ICLR, 2017.
[3] M. Binkowski, D. J. Sutherland, M. Arbel, and A. Gretton. Demystifying MMD GANs. In ´ Proc. ICLR,
2018.
[4] A. Bora, E. Price, and A. Dimakis. AmbientGAN: Generative models from lossy measurements. In Proc.
ICLR, 2018.
[5] A. Brock, J. Donahue, and K. Simonyan. Large scale GAN training for high fidelity natural image synthesis.
In Proc. ICLR, 2019.
[6] T. Chen, X. Zhai, M. Ritter, M. Lucic, and N. Houlsby. Self-supervised GANs via auxiliary rotation loss.
In Proc. CVPR, 2019.
[7] Y. Choi, Y. Uh, J. Yoo, and J.-W. Ha. StarGAN v2: Diverse image synthesis for multiple domains. In Proc.
CVPR, 2020.
[8] E. D. Cubuk, B. Zoph, D. Mané, V. Vasudevan, and Q. V. Le. AutoAugment: Learning augmentation
policies from data. In Proc. CVPR, 2019.
[9] E. D. Cubuk, B. Zoph, J. Shlens, and Q. V. Le. RandAugment: Practical automated data augmentation
with a reduced search space. CoRR, abs/1909.13719, 2019.
[10] I. Daubechies. Ten lectures on wavelets, volume 61. Siam, 1992.
[11] T. De Vries and G. Taylor. Improved regularization of convolutional neural networks with cutout. CoRR,
abs/1708.04552, 2017.
[12] R. Ge, X. Feng, H. Pyla, K. Cameron, and W. Feng. Power measurement tutorial for the Green500 list.
https://www.top500.org/green500/resources/tutorials/, Accessed March 1, 2020.
[13] X. Gong, S. Chang, Y. Jiang, and Z. Wang. AutoGAN: Neural architecture search for generative adversarial
networks. In Proc. ICCV, 2019.
10
[14] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio.
Generative adversarial networks. In Proc. NIPS, 2014.
[15] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville. Improved training of Wasserstein
GANs. In Proc. NIPS, pages 5769–5779, 2017.
[16] S. Gurumurthy, R. K. Sarvadevabhatla, and V. B. Radhakrishnan. DeLiGAN: Generative adversarial
networks for diverse and limited data. In Proc. CVPR, 2017.
[17] T. He, Z. Zhang, H. Zhang, Z. Zhang, J. Xie, and M. Li. Bag of tricks for image classification with
convolutional neural networks. In Proc. CVPR, 2019.
[18] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter. GANs trained by a two time-scale
update rule converge to a local Nash equilibrium. In Proc. NIPS, 2017.
[19] T. Karras, T. Aila, S. Laine, and J. Lehtinen. Progressive growing of GANs for improved quality, stability,
and variation. In Proc. ICLR, 2018.
[20] T. Karras, S. Laine, and T. Aila. A style-based generator architecture for generative adversarial networks.
In Proc. CVPR, 2018.
[21] T. Karras, S. Laine, M. Aittala, J. Hellsten, J. Lehtinen, and T. Aila. Analyzing and improving the image
quality of StyleGAN. In Proc. CVPR, 2020.
[22] I. Kavalerov, W. Czaja, and R. Chellappa. cGANs with multi-hinge loss. CoRR, abs/1912.04216, 2019.
[23] M. Kettunen, E. Härkönen, and J. Lehtinen. E-LPIPS: robust perceptual image similarity via random
transformation ensembles. CoRR, abs/1906.03973, 2019.
[24] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In Proc. ICLR, 2015.
[25] A. Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of
Toronto, 2009.
[26] T. Kynkäänniemi, T. Karras, S. Laine, J. Lehtinen, and T. Aila. Improved precision and recall metric for
assessing generative models. In Proc. NeurIPS, 2019.
[27] S. Laine and T. Aila. Temporal ensembling for semi-supervised learning. In Proc. ICLR, 2017.
[28] X. Mao, Q. Li, H. Xie, R. Y. K. Lau, and Z. Wang. Least squares generative adversarial networks. In Proc.
ICCV, 2017.
[29] M. Marchesi. Megapixel size image creation using generative adversarial networks. CoRR, abs/1706.00082,
2017.
[30] L. Mescheder, A. Geiger, and S. Nowozin. Which training methods for GANs do actually converge? In
Proc. ICML, 2018.
[31] T. Miyato, T. Kataoka, M. Koyama, and Y. Yoshida. Spectral normalization for generative adversarial
networks. In Proc. ICLR, 2018.
[32] T. Miyato and M. Koyama. cGANs with projection discriminator. In Proc. ICLR, 2018.
[33] S. Mo, M. Cho, and J. Shin. Freeze the discriminator: a simple baseline for fine-tuning GANs. CoRR,
abs/2002.10964, 2020.
[34] A. Noguchi and T. Harada. Image generation from small datasets via batch statistics adaptation. In Proc.
ICCV, 2019.
[35] M. Sajjadi, M. Javanmardi, and T. Tasdizen. Regularization with stochastic transformations and perturbations for deep semi-supervised learning. In Proc. NIPS, 2016.
[36] M. S. M. Sajjadi, O. Bachem, M. Lucic, O. Bousquet, and S. Gelly. Assessing generative models via
precision and recall. In Proc. NIPS, 2018.
[37] T. Salimans, I. J. Goodfellow, W. Zaremba, V. Cheung, A. Radford, and X. Chen. Improved techniques for
training GANs. In Proc. NIPS, 2016.
[38] E. Schönfeld, B. Schiele, and A. Khoreva. A U-net based discriminator for generative adversarial networks.
CoRR, abs/2002.12655, 2020.
[39] O. Sendik, D. Lischinski, and D. Cohen-Or. Unsupervised multi-modal styled content generation. CoRR,
abs/2001.03640, 2020.
[40] C. Shorten and T. M. Khoshgoftaar. A survey on image data augmentation for deep learning. Journal of
Big Data, 6, 2019.
[41] C. Sønderby, J. Caballero, L. Theis, W. Shi, and F. Huszár. Amortised MAP inference for image superresolution. In Proc. ICLR, 2017.
[42] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: A simple way to
prevent neural networks from overfitting. Journal of Machine Learning Research, 15:1929–1958, 2014.
[43] N.-T. Tran, V.-H. Tran, N.-B. Nguyen, T.-K. Nguyen, and N.-M. Cheung. On data augmentation for GAN
training. CoRR, abs/2006.05338, 2020.
[44] Y. Wang, A. Gonzalez-Garcia, D. Berga, L. Herranz, F. S. Khan, and J. van de Weijer. MineGAN: Effective
knowledge transfer from GANs to target domains with few images. In Proc. CVPR, 2020.
[45] Y. Wang, C. Wu, L. Herranz, J. van de Weijer, A. Gonzalez-Garcia, and B. Raducanu. Transferring GANs:
Generating images from limited data. In Proc. ECCV, 2018.
[46] J. Wishart and M. S. Bartlett. The distribution of second order moment statistics in a normal system.
Mathematical Proceedings of the Cambridge Philosophical Society, 28(4):455–459, 1932.
11
[47] X. Yi, E. Walia, and P. S. Babyn. Generative adversarial network in medical imaging: A review. Medical
Image Analysis, 58, 2019.
[48] D. Zhang and A. Khoreva. PA-GAN: Improving GAN training by progressive augmentation. In Proc.
NeurIPS, 2019.
[49] H. Zhang, I. Goodfellow, D. Metaxas, and A. Odena. Self-attention generative adversarial networks. In
Proc. ICML, 2019.
[50] H. Zhang, Z. Zhang, A. Odena, and H. Lee. Consistency regularization for generative adversarial networks.
In Proc. ICLR, 2019.
[51] S. Zhao, Z. Liu, J. Lin, J.-Y. Zhu, and S. Han. Differentiable augmentation for data-efficient GAN training.
CoRR, abs/2006.10738, 2020.
[52] Y. Zhao, C. Li, P. Yu, J. Gao, and C. Chen. Feature quantization improves GAN training. CoRR,
abs/2004.02088, 2020.
[53] Z. Zhao, S. Singh, H. Lee, Z. Zhang, A. Odena, and H. Zhang. Improved consistency regularization for
GANs. CoRR, abs/2002.04724, 2020.
[54] Z. Zhao, Z. Zhang, T. Chen, S. Singh, and H. Zhang. Image augmentations for GAN training. CoRR,
abs/2006.02595, 2020.
A Additional results
In Figures 12, 13, 14, 15, and 16, we show generated images for METFACES, BRECAHAD, and
AFHQ CAT, DOG, WILD, respectively, along with real images from the respective training sets
(Section 4.3 and Figure 11a). The images were selected at random; we did not perform any cherrypicking besides choosing one global random seed. We can see that ADA yields excellent results in all
cases, and with slight truncation [29, 20], virtually all of the images look convincing. Without ADA,
the convergence is hampered by discriminator overfitting, leading to inferior image quality for the
original StyleGAN2, especially in METFACES, AFHQ DOG, and BRECAHAD.
Figure 17 shows examples of the generated CIFAR-10 images in both unconditional and classconditional setting (See Appendix D.1 for details on the conditional setup). Figure 18 shows
qualitative results for different methods using subsets of FFHQ at 256×256 resolution. Methods
that do not employ augmentation (BigGAN, StyleGAN2, and our baseline) degrade noticeably as
the size of the training set decreases, generally yielding poor image quality and diversity with fewer
than 30k training images. With ADA, the degradation is much more graceful, and the results remain
reasonable even with a 5k training set.
Figure 19 compares our results with unconditional BigGAN [5, 38] and StyleGAN2 config F [21].
BigGAN was very unstable in our experiments: while some of the results were quite good, approximately 50% of the training runs failed to converge. StyleGAN2, on the other hand, behaved
predictably, with different training runs resulting in nearly identical FID. We note that FID has a
general tendency to increase as the training set gets smaller— not only because of the lower image
quality, but also due to inherent bias in FID itself [3]. In our experiments, we minimize the impact
of this bias by always computing FID between 50k generated images and all available real images,
regardless of which subset was used for training. To estimate the magnitude of bias in FID, we
simulate a hypothetical generator that replicates the training set as-is, and compute the average FID
over 100 random trials with different subsets of training data; the standard deviation was ≤2% in all
cases. We can see that the bias remains negligible with ≥20k training images but starts to dominate
with ≤2k. Interestingly, ADA reaches the same FID as the best-case generator with FFHQ-1k,
indicating that FID is no longer able to differentiate between the two in this case.
Figure 20 shows additional examples of bCR leaking to generated images and compares bCR with
dataset augmentation. In particular, rotations in range [−45◦
, +45◦
] (denoted ±45◦
) serve as a very
clear example that attempting to make the discriminator blind to certain transformations opens up the
possibility for the generator to produce similarly transformed images with no penalty. In applications
where such leaks are acceptable, one can employ either bCR or dataset augmentation — we find that
it is difficult to predict which method is better. For example, with translation augmentations bCR
was significantly better than dataset augmentation, whereas x-flip was much more effective when
implemented as a dataset augmentation.
Finally, Figure 21 shows an extended version of Figure 4, illustrating the effect of different augmentation categories with increasing augmentation probability p. Blit + Geom + Color yielded the best
results with a 2k training set and remained competitive with larger training sets as well.
12
ADA (Ours), truncated (ψ = 0.7) Real images from the training set
ADA (Ours), untruncated Original StyleGAN2 config F, untruncated
FID 15.34 – KID 0.81×103
– Recall 0.261 FID 19.47 – KID 3.16×103
– Recall 0.350
Figure 12: Uncurated 1024×1024 results generated for METFACES (1336 images) with and without
ADA, along with real images from the training set. Both generators were trained using transfer
learning, starting from the pre-trained StyleGAN2 for FFHQ. We recommend zooming in.
13
ADA (Ours), truncated (ψ = 0.7) Real images from the training set
ADA (Ours), untruncated Original StyleGAN2 config F, untruncated
FID 15.71 – KID 2.88×103
– Recall 0.340 FID 97.72 – KID 89.76×103
– Recall 0.027
Figure 13: Uncurated 512×512 results generated for BRECAHAD [1] (1944 images) with and
without ADA, along with real images from the training set. Both generators were trained from scratch.
We recommend zooming in to inspect the image quality in detail.
14
ADA (Ours), truncated (ψ = 0.7) Real images from the training set
ADA (Ours), untruncated Original StyleGAN2 config F, untruncated
FID 3.55 – KID 0.66×103
– Recall 0.430 FID 5.13 – KID 1.54×103
– Recall 0.215
Figure 14: Uncurated 512×512 results generated for AFHQ CAT [7] (5153 images) with and without
ADA, along with real images from the training set. Both generators were trained from scratch. We
recommend zooming in to inspect the image quality in detail.
15
ADA (Ours), truncated (ψ = 0.7) Real images from the training set
ADA (Ours), untruncated Original StyleGAN2 config F, untruncated
FID 7.40 – KID 1.16×103
– Recall 0.454 FID 19.37 – KID 9.62×103
– Recall 0.196
Figure 15: Uncurated 512×512 results generated for AFHQ DOG [7] (4739 images) with and without
ADA, along with real images from the training set. Both generators were trained from scratch. We
recommend zooming in to inspect the image quality in detail.
16
ADA (Ours), truncated (ψ = 0.7) Real images from the training set
ADA (Ours), untruncated Original StyleGAN2 config F, untruncated
FID 3.05 – KID 0.45×103
– Recall 0.147 FID 3.48 – KID 0.77×103
– Recall 0.143
Figure 16: Uncurated 512×512 results generated for AFHQ WILD [7] (4738 images) with and
without ADA, along with real images from the training set. Both generators were trained from scratch.
We recommend zooming in to inspect the image quality in detail.
17
Generator with best FID Real images Generator with best IS
Unconditional
FID 2.85 – IS 9.74 IS 11.24 FID 5.70 – IS 10.08
Plane Car Bird Cat Deer Dog Frog Horse Ship Truck
FID 2.38 – IS 10.00 IS 11.24 FID 3.62 – IS 10.33
Figure 17: Generated and real images for CIFAR-10 in the unconditional setting (top) and each class
in the conditional setting (bottom). We show the results for the best generators trained in the context
of Figure 11b, selected according to either FID or IS. The numbers refer to the single best model and
are therefore slightly better than the averages quoted in the result table. It can be seen that the model
with the lowest FID produces images with a wider variation in coloring and poses compared to the
model with highest IS. This is in line with the common approximation (e.g., [5]) that FID roughly
corresponds to Recall and IS to Precision, two independent aspects of result quality [36, 26].
18
2k training set 5k training set 30k training set 140k training set
BigGAN
FID 60.47 FID 32.34 FID 15.84 FID 11.08
StyleGAN2
FID 66.77 – Recall 0.002 FID 39.42 – Recall 0.030 FID 8.80 – Recall 0.283 FID 3.81 – Recall 0.452
Our baseline
FID 76.61 – Recall 0.000 FID 43.72 – Recall 0.010 FID 11.40 – Recall 0.258 FID 3.54 – Recall 0.452
ADA (Ours)
FID 15.76 – Recall 0.135 FID 10.78 – Recall 0.185 FID 5.40 – Recall 0.354 FID 3.79 – Recall 0.440
ADA + bCR
FID 17.05 – Recall 0.076 FID 10.21 – Recall 0.155 FID 4.55 – Recall 0.327 FID 3.55 – Recall 0.412
Figure 18: Images generated for different subsets of FFHQ at 256×256 resolution using the training
setups from Figures 7 and 19. We show the best snapshot of the best training run for each case,
selected according to FID, so the numbers are slightly better than the medians reported in Figure 7c. In
addition to FID, we also report the Recall metric [26] as a more direct way to estimate image diversity.
The bolded numbers indicate the lowest FID and highest Recall for each training set size. “BigGAN”
corresponds to the unconditional variant of BigGAN [5] proposed by Schönfeld et al. [38], and
“StyleGAN2” corresponds to config F of the official TensorFlow implementation by Karras et al. [21].
19
1k 2k 5k 10k 20k 30k 50k 70k 140k
2
5
10
20
50
100
200
FID
BigGAN (5 runs)
StyleGAN2 (3 runs)
Our baseline (3 runs)
+ ADA (3 runs)
Approximate
bias in FID
1k 2k 5k 10k 20k 30k 50k 100k 200k
2
5
10
20
50
100
200
FID
BigGAN (5 runs)
StyleGAN2 (3 runs)
Our baseline (3 runs)
+ ADA (3 runs)
Approximate
bias in FID
(a) Different subsets of FFHQ at 256×256 (b) Different subsets of LSUN CAT at 256×256
Figure 19: Comparison of our results with unconditional BigGAN [5, 38] and StyleGAN2 config F [21]. We report the median/min/max FID as a function of training set size, calculated over
multiple independent training runs. The dashed red line illustrates the expected bias of the FID metric,
computed using a hypothetical generator that outputs random images from the training set as-is.
Integer translation
±0px ±4px ±8px ±16px ±16px samples
Arbitrary rotation
±0
◦ ±10◦ ±20◦ ±45◦ ±45◦
samples
1k 2k 5k 10k 30k 70k
2
5
10
20
50
FID
Baseline
Data trans.
Data x-flip
bCR trans.
bCR trans. + bCR x-flip
bCR trans. + data x-flip
1k 2k 5k 10k 30k 70k
2
5
10
20
50
FID
Baseline
+ data x-flip
ADA
+ data x-flip
(a) Mean images for bCR with FFHQ-5k (b) bCR vs. dataset augment (c) Effect of dataset x-flips
Figure 20: (a) Examples of bCR leaking to generated images. (b) Comparison between dataset
augmentation and bCR using ±8px translations and x-flips. (c) In general, dataset x-flips can provide
a significant boost to FID in cases where they are appropriate. For baseline, the effect is almost equal
to doubling the size of training set, as evidenced by the consistent 2× horizontal offset between the
blue curves. With ADA the effect is somewhat weaker.
2k training set 10k training set 50k training set 140k training set
Individual
p = 0.0 0.2 0.4 0.6 0.8 1.0
5
10
20
50
100
FID
Blit
Geom
Color
Filter
Noise
Cutout
p = 0.0 0.2 0.4 0.6 0.8 1.0
5
10
20
50
100
FID
Blit
Geom
Color
Filter
Noise
Cutout
p = 0.0 0.2 0.4 0.6 0.8 1.0
5
10
20
50
100
FID
Blit
Geom
Color
Filter
Noise
Cutout
p = 0.0 0.2 0.4 0.6 0.8 1.0
5
10
20
50
100
FID
Blit
Geom
Color
Filter
Noise
Cutout
Cumulative
p = 0.0 0.2 0.4 0.6 0.8 1.0
5
10
20
50
100
FID
Blit
+ Geom
+ Color
+ Filter
+ Noise
+ Cutout
p = 0.0 0.2 0.4 0.6 0.8 1.0
5
10
20
50
100
FID
Blit
+ Geom
+ Color
+ Filter
+ Noise
+ Cutout
p = 0.0 0.2 0.4 0.6 0.8 1.0
5
10
20
50
100
FID
Blit
+ Geom
+ Color
+ Filter
+ Noise
+ Cutout
p = 0.0 0.2 0.4 0.6 0.8 1.0
5
10
20
50
100
FID
Blit
+ Geom
+ Color
+ Filter
+ Noise
+ Cutout
Figure 21: Extended version of Figure 4, illustrating the individual and cumulative effect of different
augmentation categories with increasing augmentation probability p.
20
B Our augmentation pipeline
We designed our augmentation pipeline based on three goals. First, the entire pipeline must be strictly
non-leaking (Appendix C). Second, we aim for a maximally diverse set of augmentations, inspired by
the success of RandAugment [9]. Third, we strive for the highest possible image quality to reduce
unintended artifacts such as aliasing. In total, our pipeline consists of 18 transformations: geometric
(7), color (5), filtering (4), and corruption (2). We implement it entirely on the GPU in a differentiable
fashion, with full support for batching. All parameters are sampled independently for each image.
B.1 Geometric and color transformations
Figure 22 shows pseudocode for our geometric and color transformations, along with example images.
In general, geometric transformations tend to lose high-frequency details of the input image due to
uneven resampling, which may reduce the capability of the discriminator to detect pixel-level errors
in the generated images. We alleviate this by introducing a dedicated sub-category, pixel blitting,
that only copies existing pixels as-is, without blending between neighboring pixels. Furthermore,
we avoid gradual image degradation from multiple consecutive transformations by collapsing all
geometric transformations into a single combined operation.
The parameters for pixel blitting are selected on lines 5–15, consisting of x-flips (line 7), 90◦
rotations
(line 10), and integer translations (line 13). The transformations are accumulated into a homogeneous
3 × 3 matrix G, defined so that input pixel (xi
, yi) is placed at [xo, yo, 1]T = G · [xi
, yi
, 1]T
in the
output. The origin is located at the center of the image and neighboring pixels are spaced at unit
intervals. We apply each transformation with probability p by sampling its parameters from uniform
distribution, either discrete U{·} or continuous U(·), and updating G using elementary transforms:
SCALE2D(sx, sy) = "
sx 0 0
0 sy 0
0 0 1#
, ROTATE2D(θ) = "
cos θ − sin θ 0
sin θ cos θ 0
0 0 1#
, TRANSLATE2D(tx, ty) = "
1 0 tx
0 1 ty
0 0 1 #
(2)
General geometric transformations are handled in a similar way on lines 16–32, consisting of isotropic
scaling (line 17), arbitrary rotation (lines 21 and 27), anisotropic scaling (line 24), and fractional
translation (line 30). Since both of the scaling transformations are multiplicative in nature, we sample
their parameter, s, from a log-normal distribution so that ln s ∼ N
0,(0.2 · ln 2)2

. In practice, this
can be done by first sampling t ∼ N (0, 1) and then calculating s = exp2
(0.2t). We allow anisotropic
scaling to operate in other directions besides the coordinate axes by breaking the rotation into two
independent parts, one applied before the scaling (line 21) and one after it (line 27). We apply the
rotations slightly less frequently than other transformations, so that the probability of applying at
least one rotation is equal to p. Note that we also have two translations in our pipeline (lines 13 and
30), one applied at the beginning and one at the end. To increase the diversity of our augmentations,
we use U(·) for the former and N (·) for the latter.
Once the parameters are settled, the combined geometric transformation is executed on lines 33–47.
We avoid undesirable effects at image borders by first padding the image with reflection. The amount
of padding is calculated dynamically based on G so that none of the output pixels are affected by
regions outside the image (line 35). We then upsample the image to a higher resolution (line 40) and
transform it using bilinear interpolation (line 45). Operating at a higher resolution is necessary to
reduce aliasing when the image is minified, e.g., as a result of isotropic scaling— interpolating at
the original resolution would fail to correctly filter out frequencies above Nyquist in this case, no
matter which interpolation filter was used. The choice of the upsampling filter requires some care,
however, because we must ensure that an identity transform does not modify the image in any way
(e.g., when p = 0). In other words, we need to use a lowpass filter H(z) with cutoff fc =
π
2
that
satisfies DOWNSAMPLE2D
UPSAMPLE2D
Y, H(z
−1
)

, H(z)

= Y . Luckily, existing literature
on wavelets [10] offers a wide selection of such filters; we choose 12-tap symlets (SYM6) to strike a
balance between resampling quality and computational cost.
Finally, color transformations are applied to the resulting image on lines 48–70. The overall operation is similar to geometric transformations: we collect the parameters of each individual transformation into a homogeneous 4 × 4 matrix C that we then apply to each pixel by computing
[ro, go, bo, 1]T = C · [ri
, gi
, bi
, 1]T
. The transformations include adjusting brightness (line 50), contrast (line 53), and saturation (line 63), as well as flipping the luma axis while keeping the chroma
unchanged (line 57) and rotating the hue axis by an arbitrary amount (line 60).
1: input: original image X, augmentation probability p
2: output: augmented image Y
3: (w, h) ← SIZE(X)
4: Y ← CONVERT(X, FLOAT) . Yx,y ∈ [−1, +1]3
5: . Select parameters for pixel blitting
6: G ← I3 . Homogeneous 2D transformation matrix
7: apply x-flip with probability p
8: sample i ∼ U{0, 1}
9: G ← SCALE2D(1 − 2i, 1) · G
10: apply 90◦
rotations with probability p
11: sample i ∼ U{0, 3}
12: G ← ROTATE2D
− π
2
· i

· G
13: apply integer translation with probability p
14: sample tx, ty ∼ U(−0.125, +0.125)
15: G ← TRANSLATE2D
round(txw), round(tyh)

· G
16: . Select parameters for general geometric transformations
17: apply isotropic scaling with probability p
18: sample s ∼ Lognormal
0, (0.2 · ln 2)2

19: G ← SCALE2D(s, s) · G
20: prot ← 1 −
√
1 − p . P (pre ∪ post) = p
21: apply pre-rotation with probability prot
22: sample θ ∼ U(−π, +π)
23: G ← ROTATE2D(−θ) · G . Before anisotropic scaling
24: apply anisotropic scaling with probability p
25: sample s ∼ Lognormal
0, (0.2 · ln 2)2

26: G ← SCALE2D
s, 1
s

· G
27: apply post-rotation with probability prot
28: sample θ ∼ U(−π, +π)
29: G ← ROTATE2D(−θ) · G . After anisotropic scaling
30: apply fractional translation with probability p
31: sample tx, ty ∼ N
0, (0.125)2

32: G ← TRANSLATE2D(txw, tyh) · G
33: . Pad image and adjust origin
34: H(z) ← WAVELET(SYM6) . Orthogonal lowpass filter
35: (mlo , mhi ) ← CALCULATEPADDING
G, w, h, H(z)

36: Y ← PAD(Y, mlo , mhi , REFLECT)
37: T ← TRANSLATE2D
1
2 w− 1
2 +mlo,x,
1
2
h− 1
2 +mlo,y
38: G ← T · G · T
−1 . Place origin at image center
39: . Execute geometric transformations
40: Y
0 ← UPSAMPLE2X2

Y, H(z
−1
)

41: S ← SCALE2D(2, 2)
42: G ← S · G · S
−1 . Account for the upsampling
43: for each pixel (xo, yo) ∈ Y
0
do
44: [xi, yi, zi]
T ← G−1
· [xo, yo, 1]T
45: Yxo,yo ← BILINEARLOOKUP(Y
0
, xi, yi)
46: Y ← DOWNSAMPLE2X2

Y, H(z)

47: Y ← CROP(Y, mlo , mhi ) . Undo the padding
48: . Select parameters for color transformations
49: C ← I4 . Homogeneous 3D transformation matrix
50: apply brightness with probability p
51: sample b ∼ N
0, (0.2)2

52: C ← TRANSLATE3D(b, b, b) · C
53: apply contrast with probability p
54: sample c ∼ Lognormal
0, (0.5 · ln 2)2

55: C ← SCALE3D(c, c, c) · C
56: v ← [1, 1, 1, 0] /
√
3 . Luma axis
57: apply luma flip with probability p
58: sample i ∼ U{0, 1}
59: C ←

I4 − 2v
T v · i

· C . Householder reflection
60: apply hue rotation with probability p
61: sample θ ∼ U(−π, +π)
62: C ← ROTATE3D(v, θ) · C . Rotate around v
63: apply saturation with probability p
64: sample s ∼ Lognormal
0, (1 · ln 2)2

65: C ←

v
T v +

I4 − v
T v

· s

· C
66: . Execute color transformations
67: for each pixel (x, y) ∈ Y do
68: (ri, gi, bi) ← Yx,y
69: [ro, go, bo, ao]
T ← C · [ri, gi, bi, 1]T
70: Yx,y ← (ro, go, bo)
71: return Y
Percentile: 5th 35th 65th 95th
Pixel blitting
x-flip
90◦
rotations
Integer
translation
General geometric transformations
Isotropic
scaling
Arbitrary
rotation
Anisotropic
scaling
Fractional
translation
Color transformations
Brightness
Contrast
Luma
flip
Hue
rotation
Saturation
Figure 22: Pseudocode and example images for geometric and color transformations (Appendix B.1).
We illustrate the effect of each individual transformation (apply) using four sets of parameter values,
representing the 5th, 35th, 65th, and 95th percentiles of their corresponding distribution
1: input: original image X, augmentation probability p
2: output: augmented image Y
3: (w, h) ← SIZE(X)
4: Y ← CONVERT(X, FLOAT) . Yx,y ∈ [−1, +1]3
5: . Select parameters for image-space filtering
6: b ←
h
0,
π
8

,
 π
8
,
π
4

,
 π
4
,
π
2

,
 π
2
, π
i
. Freq. bands
7: g ← [1, 1, 1, 1] . Global gain vector (identity)
8: λ ← [10, 1, 1, 1] / 13 . Expected power spectrum (1/f)
9: for i = 1, 2, 3, 4 do
10: apply amplification for bi with probability p
11: t ← [1, 1, 1, 1] . Temporary gain vector
12: sample ti ∼ Lognormal
0, (1 · ln 2)2

13: t ← t
qP
j λj t
2
j
. Normalize power
14: g ← g  t . Accumulate into global gain
15: . Execute image-space filtering
16: H(z) ← WAVELET(SYM2) . Orthogonal 4-tap filter bank
17: H0
(z) ← 0 . Combined amplification filter
18: for i = 1, 2, 3, 4 do
19: H0
(z) ← H0
(z) + BANDPASS
H(z), bi

· gi
20: (mlo , mhi ) ← CALCULATEPADDING
H0
(z)

21: Y ← PAD(Y, mlo , mhi , REFLECT)
22: Y ← SEPARABLECONV2D
Y, H0
(z)

23: Y ← CROP(Y, mlo , mhi )
24: . Additive RGB noise
25: apply noise with probability p
26: sample σ ∼ Halfnormal
(0.1)2

27: for each pixel (x, y) ∈ Y do
28: sample nr, ng, nb ∼ N(0, σ
2
)
29: Yx,y ← Yx,y + [nr, ng, nb]
30: . Cutout
31: apply cutout with probability p
32: sample cx, cy ∼ U(0, 1)
33: rlo ← roundh
cx − 1
4

· w,
cy − 1
4

· h
i
34: rhi ← roundh
cx + 1
4

· w,
cy + 1
4

· h
i
35: Y ← Y 

1 − RECTANGULARMASK(rlo , rhi )

36: return Y
Percentile: 5th 35th 65th 95th
Image-space filtering
Frequency
band b1

0,
π
8

Frequency
band b2
 π
8
,
π
4

Frequency
band b3
 π
4
,
π
2

Frequency
band b4
 π
2
, π
Image-space corruptions
Additive
RGB noise
Cutout
Figure 23: Pseudocode and example images for image-space filtering and corruptions (Appendix B.2).
x  y denotes element-wise multiplication.
B.2 Image-space filtering and corruptions
Figure 23 shows pseudocode for our image-space filtering and corruptions. The parameters for imagespace filtering are selected on lines 5–14. The idea is to divide the frequency content of the image into
4 non-overlapping bands and amplify/weaken each band in turn via a sequence of 4 transformations,
so that each transformation is applied independently with probability p (lines 9–10). Frequency
bands b2, b3, and b4 correspond to the three highest octaves, respectively, while the remaining low
frequencies are attributed to b1 (line 6). We track the overall gain of each band using vector g (line 7)
that we update after each transformation (line 14). We sample the amplification factor for a given
band from log-normal distribution (line 12), similar to geometric scaling, and normalize the overall
gain so that the total energy is retained on expectation. For the normalization, we assume that the
frequency content obeys 1/f power spectrum typically seen in natural images (line 8). While this
assumption is not strictly true in our case, especially when some of the previous frequency bands
have already been amplified, it is sufficient to keep the output pixel values within reasonable bounds.
The filtering is executed on lines 15–23. We first construct a combined amplification filter H0
(z)
(lines 17–19) and then perform separable convolution for the image using reflection padding (lines 21–
23). We use a zero-phase filter bank derived from 4-tap symlets (SYM2) [10]. Denoting the wavelet
scaling filter by H(z), the corresponding bandpass filters are obtained as follows (line 19):
BANDPASS
H(z), b1

= H(z)H(z
−1
)H(z
2
)H(z
−2
)H(z
4
)H(z
−4
)/8 (3)
BANDPASS
H(z), b2

= H(z)H(z
−1
)H(z
2
)H(z
−2
)H(−z
4
)H(−z
−4
)/8 (4)
BANDPASS
H(z), b3

= H(z)H(z
−1
)H(−z
2
)H(−z
−2
)/4 (5)
BANDPASS
H(z), b4

= H(−z)H(−z
−
Finally, we apply additive RGB noise on lines 24–29 and cutout on lines 30–35. We vary the
strength of the noise by sampling its standard deviation from half-normal distribution, i.e., N (·)
restricted to non-negative values (line 26). For cutout, we match the original implementation of
DeVries and Taylor [11] by setting pixels to zero within a rectangular area of size  w
2
,
h
2

, with the
center point selected from uniform distribution over the entire image.
C Non-leaking augmentations
The goal of GAN training is to find a generator function G whose output probability distribution x
(under suitable stochastic input) matches a given target distribution y.
When augmenting both the dataset and the generator output, the key safety principle is that if x and
y do not match, then their augmented versions must not match either. If the augmentation pipeline
violates this principle, the generator is free to learn some different output distribution than the dataset,
as these look identical after the augmentations – we say that the augmentations leak. Conversely, if
the principle holds, then the only option for the generator is to learn the correct distribution: no other
choice results in a post-augmentation match.
In this section, we study the conditions on the augmentation pipeline under which this holds and
demonstrate the safety and caveats of various common augmentations and their compositions.
Notation Throughout this section, we denote probability distributions (and their generalizations)
with lowercase bold-face letters (e.g., x), operators acting on them by calligraphic letters (T ), and
variates sampled from probability distributions by upper-case letters (X).
C.1 Augmentation operator
A very general model for augmentations is as follows. Assume a fixed but arbitrarily complicated nonlinear and stochastic augmentation pipeline. To any image X, it assigns a distribution of augmented
images, such as demonstrated in Figure 2c. This idea is captured by an augmentation operator T
that maps probability distributions to probability distributions (or, informally, datasets to augmented
datasets). A distribution with the lone image X is the Dirac point mass δX, which is mapped to some
distribution T δX of augmented images.3
In general, applying T to an arbitrary distribution x yields
the linear superposition T x of such augmented distributions.
It is important to understand that T is different from a function f(X; φ) that actually applies the
augmentation on any individual image X sampled from x (parametrized by some φ, e.g., angle in case
of a rotation augmentation). It captures the aggregate effect of applying this function on all images
in the distribution and subsumes the randomization of the function parameters. T is always linear
and deterministic, regardless of non-linearity of the function f and stochasticity of its parameters
φ. We will later discuss invertibility of T . Here it is also critical to note that its invertibility is not
equivalent with the invertibility of the function f it is based on; for an example, refer to the discussion
in Section 2.2.
Specifically, T is a (Markov) transition operator. Intuitively, it is an (uncountably) infinitedimensional generalization of a Markov transition matrix (i.e. a stochastic matrix), with nonnegative
entries that sum to 1 along columns. In this analogy, probability distributions upon which T operates
are vectors, with nonnegative entries summing to 1. More generally, the distributions have a vector
space structure and they can be arbitrarily linearly combined (in which case they may lose their
validity as probability distributions and are viewed as arbitrary signed measures). Similarly, we can
do algebra with the with the operators by linearly combining and composing them like matrices.
Concepts such as null space and invertibility carry over to this setting, with suitable technical care. In
the following, we will be somewhat informal with the measure theoretical and functional analytic
details of the problem, and draw upon this analogy as appropriate.4
3These distributions are probability measures over a non-discrete high dimensional space: for example, in
our experiments with 256 × 256 RGB images, this space is R
256∗256∗3 = R
196608
.
4The addition and scalar multiplication of measures is taken to mean that for any set S to which x and y
assign a measure, [αx + βy](S) = αx(S) + βy(S). When the measures are represented by density functions,
this simplifies to the usual pointwise linear combination of the functions. We always mean addition and scalar
2
C.2 Invertibility implies non-leaking augmentations
Within this framework, our question can be stated as follows. Given a target distribution y and an
augmentation operator T , we train for a generated distribution x such that the augmented distributions
match, namely
T x = T y. (7)
The desired outcome is that this equation is satisfied only by the correct target distribution, namely
x = y. We say that T leaks if there exist distributions x 6= y that satisfy the above equation, and the
goal is to find conditions that guarantee the absence of leaks.
There are obviously no such leaks in classical non-augmented training, where T is the identity I,
whence T x = T y ⇒ Ix = Iy ⇒ x = y. For arbitrary augmentations, the desired outcome x = y
does always satisfy Eq. 7; however, if also other choices of x satisfy it, then it cannot be guaranteed
that the training lands on the desired solution. A trivial example is an augmentation that maps every
image to black (in other words, T z = δ0 for any z). Then, T x = T y does not imply that x = y, as
indeed any choice of x produces the same set of black images that satisfies Eq. 7. In this case, it is
vanishingly unlikely that the training finds the solution x = y.
More generally, assume that T has a non-trivial null space, namely there exists a signed measure
n 6= 0 such that T n = 0, that is, n is in the null space of T . Equivalently, T is not invertible, because
n cannot be recovered from T n. Then, x = y + αn for any α ∈ R satisfies Eq. 7. Therefore noninvertibility of T implies that measures in its null space may freely leak into the learned distribution
(as long as the sum remains a valid probability distribution that assigns non-negative mass to all sets).
Conversely, assume that some x 6= y satisfies Eq. 7. Then T (x − y) = T y − T y = 0, so x − y is
in null space of T and therefore T is not invertible.
Therefore, leaking augmentations imply non-invertibility of the augmentation operator, which conversely implies the central principle: if the augmentation operator T is invertible, it does not
leak. Such a non-leaking operator further satisfies the requirements of Lemma 5.1. of Bora et al. [4],
where the invertibility is shown to imply that a GAN learns the correct distribution.
The invertibility has an intuitive interpretation: the training process can implicitly “undo” the
augmentations, as long as probability mass is merely shifted around and not squashed flat.
C.3 Compositions and mixtures
We only access the operator T indirectly: it is implemented as a procedure, rather than a matrix-like
entity whose null space we could study directly (even if we know that such a thing exists in principle).
Showing invertibility for an arbitrary procedure is likely to be impossible. Rather, we adopt a
constructive approach, and build our augmentation pipeline from combinations of simple known-safe
augmentations, in a way that can be shown to not leak. This calls for two components: a set of
combination rules that preserve the non-leaking guarantee, and a set of elementary augmentations
that have this property. In this subsection we address the former.
By elementary linear algebra: assume T and U are invertible. Then the composition T U is invertible, as is any finite chain of such compositions. Hence, sequential composition of non-leaking
augmentations is non-leaking. We build our pipeline on this observation.
The other obvious combination of augmentations is obtained by probabilistic mixtures: given
invertible augmentations T and U, perform T with probability α and U with probability 1 − α.
The operator corresponding to this augmentation is the “pointwise” convex blend αT + (1 − α)U.
More generally, one can mix e.g. a continuous family of augmentations Tφ with weights given by
a non-negative unit-sum function α(φ), as R
α(φ)Tφ dφ. Unfortunately, stochastically choosing
among a set of augmentations is not guaranteed to preserve the non-leaking property, and must
be analyzed case by case (which is the content of the next subsection). To see this, consider an
multiplication of probability distributions in this sense (as opposed to e.g. addition of random variables), unless
otherwise noted.
Technically, one can consider the vector space of finite signed measures on R
N , which is a Banach space
under the Total Variation norm. Markov operators form a convex subset of linear operators acting on this space,
and general linear combinations thereof form a subspace (and a subalgebra). The exact mathematical conditions
under which some of the following findings apply may be intricate but have limited practical significance given
the approximate nature of GAN training.
25
extremely simple discrete probability space with only two elements. The augmentation operator
T =

0 1
1 0 
flips the elements. Mixed with probability α =
1
2 with the identity augmentation I
(which keeps the distribution unchanged), we obtain the augmentation 1
2
T +
1
2
I =
1
2

1 1
1 1 
which
is a singular matrix and therefore not invertible. Intuitively, this operator smears any probability
distribution into a degenerate equidistribution, from which the original can no longer be recovered.
Similar considerations carry over to arbitrarily complicated linear operators.
C.4 Non-leaking elementary augmentations
In the following, we construct several examples of relatively large classes of elementary augmentations
that do not leak and can therefore be used to form a chain of augmentations. Importantly, most of
these classes are not inherently safe, as they are stochastic mixtures of even simpler augmentations,
as discussed above. However, in many cases we can show that the degenerate situation only arises
with specific choices of mixture distribution, which we can then avoid.
Specifically, for every type of augmentation, we identify a configuration where applying it with
probability strictly less than 1 results in an invertible transformation. From the standpoint of this
analysis, we interpret this stochastic skipping as modifying the augmentation operator itself, in a
way that boosts the probability of leaving the input unchanged and reduces the probability of other
outcomes.
C.4.1 Deterministic mappings
The simplest form of augmentation is a deterministic mapping, where the operator Tf assigns to
every image X a unique image f(X). In the most general setting f is any measurable function and
Tfx is the corresponding pushforward measure. When f is a diffeomorphism, Tf acts by the usual
change of variables formula with a density correction by a Jacobian determinant. These mappings are
invertible as long as f itself is invertible. Conversely, if f is not invertible, then neither is Tf .
Here it may be instructive to highlight the difference between f and Tf . The former transforms the
underlying space on which the probability distributions live – for example, if we are dealing with
images of just two pixels (with continuous and unconstrained values), f is a nonlinear “warp” of the
two-dimensional plane. In contrast, Tf operates on distributions defined on this space – think of a
continuous 2-dimensional function (density) on the aforementioned plane. The action of Tf is to
move the density around according to f, while compensating for thinning and concentration of the
mass due to stretching. As long as f maps every distinct point to a distinct point, this warp can be
reversed.
An important special case is that where f is a linear transformation of the space. Then the invertibility
of Tf becomes a simpler question of the invertibility of a finite-dimensional matrix that represents f.
Note that when an invertible deterministic transformation is skipped probabilistically, the determinism is lost, and very specific choices of transformation could result in non-invertibility (see e.g.
the example of flipping above). We only use deterministic mappings as building blocks of other
augmentations, and never apply them in isolation with stochastic skipping.
C.4.2 Transformation group augmentations
Many commonly used augmentations are built from transformations that act as a group under
sequential composition. Examples of this are flips, translations, rotations, scalings, shears, and many
color and intensity transformations. We show that a stochastic mixture of transformations within
a finitely generated abelian group is non-leaking as long as the mixture weights are chosen from a
non-degenerate distribution.
As an example, the four deterministic augmentations {R0, R90, R180, R270} that rotate the images
to every one of the 90-degree increment orientations constitute a group. This is seen by checking
that the set satisfies the axiomatic definition of a group. Specifically, the set is closed, as composing
two of elements always results in an element of the same set, e.g. R270R180 = R90. It is also
obviously associative, and has an identity element R0 = I. Finally, every element has an inverse, e.g.
R
−1
90 = R270. We can now simply speak of powers of the single generator element, whereby the four
group elements are written as {R0
90, R1
90, R2
90, R3
90} and further (as well as negative) powers “wrap
over” to the same elements. This group is isomorphic to Z4, the additive group of integers modulo 4.

A group of rotations is compact due to the wrap-over effect. An example of a non-compact group is
that of translations (with non-periodic boundary conditions): compositions of translations are still
translations, but one cannot wrap over. Furthermore, more than one generator element can be present
(e.g. y-translation in addition to x-translation), but we require that these commute, i.e. the order of
applying the transformations must not matter (in which case the group is called abelian).
Similar considerations extend to continuous Lie groups, e.g. that of rotations by any angle; here the
generating element is replaced by an infinitesimal generator from the corresponding Lie algebra,
and the discrete powers by the continuous exponential mapping. For example, continuous rotation
transformations are isomorphic to the group SO(2), or U(1).
In the following subsections show that for finitely generated abelian groups whose identity element matches the identity augmentation, stochastic mixtures of augmentations within the
group are invertible, as long as the appropriate Fourier transform of the probability distribution over the elements has no zeros.
Discrete compact one-parameter groups We demonstrate the key points in detail with the simple
but relevant case of a discrete compact one-parameter group and generalize later. Let G be a
deterministic augmentation that generates the finite cyclic group {Gi}
N−1
i=0 of order N (e.g. the four
90-degree rotations above), such that the element G
0
is the identity mapping that leaves its input
unchanged.
Consider a stochastic augmentation T that randomly applies an element of the group, with the
probability of choosing each element given by the probability vector p ∈ R
N (where p is nonnegative
and sums to 1):
T =
N
X−1
i=0
piG
i
(8)
To show the conditions for invertibility of T , we build an operator U that explicitly inverts T , namely
UT = I = G
0
. Whenever this is possible, T is invertible and non-leaking. We build U from the
same group elements with a different weighting5 vector q ∈ R
N :
U =
N
X−1
j=0
qjG
j
(9)
We now seek a vector q for which UT = I, that is, for which U is the desired inverse. Now,
UT =
 N
X−1
i=0
piG
i
! 

N
X−1
j=0
qjG
j

 (10)
=
N
X−1
i,j=0
piqjG
i+j
(11)
The powers of the group operation, as well as the indices of the weight vectors, are taken as modulo
N due to the cyclic wrap-over of the group element. Collecting the terms that correspond to each G
k
in this range and changing the indexing accordingly, we arrive at:
=
N
X−1
k=0 "N
X−1
l=0
plqk−l
#
G
k
(12)
=
N
X−1
k=0
[p ⊗ q]kG
k
(13)
5Unlike with p, there is no requirement for q to represent a nonnegative probability density that sums to 1, as
we are establishing the general invertibility of T without regard to its probabilistic interpretation. Note that U is
never actually constructed or evaluated when applying our method in practice, and does not need to represent
an operation that can be algorithmically implemented; our interest is merely to identify the conditions for its
existence.
27
where we observe that the multiplier in front of each G
k
is given by the cyclic convolution of the
elements of the vectors p and q. This can be written as a pointwise product in terms of the Discrete
Fourier Transform F, denoting the DFT’s of p and q by a hat:
=
N
X−1
k=0
[F
−1
(ˆp  qˆ)]kG
k
(14)
To recover the sought after inverse, assuming every element of pˆ is nonzero, we set qˆi =
1
pˆi
for all i:
=
N
X−1
k=0
[F
−1
(ˆp  pˆ
−1
)]kG
k
(15)
=
N
X−1
k=0
[F
−11]kG
k
(16)
= G
0
(17)
= I (18)
Here, we take advantage of the fact that the inverse DFT of a constant vector of ones is the vector
[1, 0, ..., 0].
In summary, the product of U and T effectively computes a convolution between their respective
group element weights. This convolution assigns all of the weight to the identity element precisely
when one has qˆi =
1
pˆi
, for all i, whereby U is the inverse of T . This inverse only exists when the
Fourier transform pˆi of the augmentation probability weights has no zeros.
The intuition is that the mixture of group transformations “smears” probability mass among the
different transformed versions of the distribution. Analogously to classical deconvolution, this
smearing can be undone (“deconvolved”) as long as the convolution does not destroy any frequencies
by scaling them to zero.
Some noteworthy consequences of this are:
• Assume p is a constant vector 1
N
1, that is, the augmentation applies the group elements with
uniform probability. In this case pˆ = δ0 and convolution with any zero-mean weight vector
is zero. This case is almost certain to cause leaks of the group elements themselves. To see
this directly, the mixed augmentation operator is now T := 1
N
PN−1
j=0 G
j
. Consider the true
distribution of training samples y, and a version y
0 = G
ky into which some element of the
transformation group has leaked. Now,
T y
0 = T (G
ky) = 1
N
N
X−1
j=0
G
jG
ky =
1
N
N
X−1
j=0
G
j+ky =
1
N
N
X−1
j=0
G
jy = T y (19)
(recalling the modulo arithmetic in the group powers). By Eq. 7, this is a leak, and the
training may equally well learn the distribution G
ky rather than y. By the same reasoning,
any mixture of transformed elements may be learned (possibly even a different one for each
image).
• Similarly, if p is periodic (with period that is some integer factor of N, other than N itself),
the Fourier transform is a sparse sequence of spikes separated by zeros. Another viewpoint
to this is that the group has a subgroup, whose elements are chosen uniformly. Similar to
above, this is almost certain to cause leaks with elements of that subgroup.
• With more sporadic zero patterns, the leaks can be seen as “conditional”: while the augmentation operator has a null space, it is not generally possible to write an equivalent of Eq. 19
without setting conditions on the distribution y itself. In these cases, leaks only occur for
specific kinds of distributions, e.g., when a sufficient amount of group symmetry is already
present in the distribution itself.
For example, consider a dataset where all four 90 degree orientations of any image are
equally likely, and an augmentation that performs either a 0 or 90 degree rotation at equal
probability. This corresponds to the probability vector p = [0.5, 0.5, 0, 0] over the four
28
elements of the 90-degree rotation group. This distribution has a single zero in its Fourier
transform. The associated leak might manifest as the generator only learning to produce
images in orientations 0 and 180 degrees, and relying on the augmentation to fill the gaps.
Such a leak could not happen in e.g. a dataset depicting upright faces, and the failure of
invertibility would be harmless in this case. However, this may no longer hold when the
augmentation is a part of a composed pipeline, as other augmentations may have introduced
partial invariances that were not present in the original data.
In our augmentations involving compact groups (rotations and flips), we always choose the elements
with a uniform probability, but importantly, only perform the augmentation with some probability
less than one. This combination can be viewed as increasing the probability of choosing the group
identity element. The probability vector p is then constant, except for having a higher value at p0; the
Fourier transform of such a vector has no zeros.
Non-compact discrete one-parameter groups The above reasoning can be extended to groups
which are not compact, in particular translations by integer offsets (without periodic boundaries).
In the discrete case, such a group is necessarily isomorphic to the additive group Z of all integers, and
no modulo integer arithmetic is performed. The mixture density is then a two-sided sequence {pi}
with i ∈ Z, and the appropriate Fourier transform maps this to a periodic function. By an analogous
reasoning with the previous subsection, the invertibility holds as long as this spectrum has no zeros.
Continuous one-parameter groups With suitable technical care, these arguments can be extended
to continuous groups with elements Gφ indexed by a continuous parameter φ. In the compact case
(e.g. continuous rotation), the group elements wrap over at some period L, such that Gφ+L = Gφ.
In the non-compact case (e.g. translation (addition) and scaling (multiplication) by real-valued
amounts) no such wrap-over occurs. The compact and non-compact groups are isomorphic to U(1),
and the additive group R, respectively. Stochastic mixtures of these group elements are expressed by
probability density functions p(φ), with φ ∈ [0, L) if the group is compact, and φ ∈ R otherwise.
The Fourier transforms are replaced by the appropriate generalizations, and the invertibility holds
when the spectrum has no zeros.
Here it is important to use the correct parametrization of the group. Note that one could in principle
parametrize e.g. rotations in arbitrary ways, and it may seem ambiguous as to what parametrization
to use, which would appear to render concepts like uniform distribution meaningless. The issue
arises when replacing the sums in the earlier formulas with integrals, whereby one needs to choose
a measure of integration. These findings apply specifically to the natural Haar measure and the
associated parametrization – essentially, the measure that accumulates at constant rate when taking
small steps in the group by applying the infinitesimal generator. For rotation groups, the usual “area”
measure over the angular parametrization coincides with the Haar measure, and therefore e.g. uniform
distribution is taken to mean that all angles are chosen equally likely. For translation, the natural
Euclidian distance is the correct parametrization. For other groups, such as scaling, the choice is a
bit more nuanced: when composing scaling operations, the scale factor combines by multiplication
instead of addition, so the natural parametrization is the logarithm of the scale factor.
For continuous compact groups (rotation), we use the same scheme as in the discrete case: uniform
probability mixed with identity at a probability greater than zero.
For continuous non-compact groups, the Fourier transform of the normal distribution has no zeros
and results in an invertible augmentation when used to choose among the group elements. Other
distributions with this property are at least the α-stable and more generally the infinitely divisible
family of distributions. When the parametrization is logarithmic, we may instead use exponentiated
values from these distributions (e.g. the log-normal distribution). Finally, stochastically mixing
zero-mean normal distributed variables with identity does not introduce zeros to the FT, as it merely
lifts the already positive values of the spectrum.
Multi-parameter abelian groups Finally, these findings generalize to groups that are products of a
finite number of single-parameter groups, provided that the elements of the different groups commute
29
among each other (in other words, finitely generated abelian groups). An example of this is the group
of 2-dimensional translations obtained by considering x- and y-translations simultaneously.6
The Fourier transforms are replaced with suitable multi-dimensional generalizations, and the probability distributions and their Fourier transforms obtain multidimensional domains accordingly.
Discussion Invertibility is a sufficient condition to ensure the absence of leaks. However, it may
not always be necessary: in the case of non-compact groups, a hypothesis could be made that even a
technically non-invertible operator does not leak. For example, a shift augmentation with uniform
distributed offset on a continuous interval is not invertible, as the Fourier transform of its density is a
sinc function with periodic zeros (except at 0). This only allows for leaks of zero-mean functions
whose FT is supported on this evenly spaced set of frequencies – in other words, infinitely periodic
functions. Even though such functions are in the null space of the augmentation operator, they
cannot be added to any density in an infinite domain without violating non-negativity, and so we
may hypothesize that no leak can in fact occur. In practice, however, the near-zero spectrum values
might allow for a periodic leak modulated by a wide window function to occur for very specific (and
possibly contrived) data distributions.
In contrast, straightforward examples and practical demonstrations of leaks are easily found for
compact groups, e.g. with uniform or periodic rotations.
C.4.3 Noise and image filter augmentations
We refer to Theorem 5.3. of Bora et al. [4], where it is shown that in a setting effectively identical to
ours, addition of noise that is independent of the image is an invertible operation as long as the
Fourier spectrum of the noise distribution does not contain zeros. The reason is that addition of
mutually independent random variables results in a convolution of their probability distributions.
Similar to groups, this is a multiplication in the Fourier domain, and the zeros correspond to
irrevocable loss of information, making the inversion impossible. The inverse can be realized by
“deconvolution”, or division in the Fourier domain.
A potential source of confusion is that the Fourier transform is commonly used to describe spatial
correlations of noise in signal processing. We refer to a different concept, namely the Fourier
transform of the probability density of the noise, often called the characteristic function in probability
literature (although correlated noise is also subsumed by this analysis).
Gaussian product noise In our setting, we also randomize the magnitude parameter of the noise,
in effect stochastically mixing between different noise distributions. The above analysis subsumes
this case, as the mixture is also a random noise, with a density that is a weighted blend between the
densities of the base noises. However, the noise is no longer independent across points, so its joint
distribution is no longer separable to a product of marginals, and one must consider the joint Fourier
transform in full dimension.
Specifically, we draw the per-pixel noise from a normal distribution and modulate this entire noise
field by a multiplication with a single (half-)normal random number. The resulting distribution has
an everywhere nonzero Fourier transform and hence is invertible. To see this, first consider two
standard normal distributed random scalars X and Y , and their product Z = XY (taken in the
sense of multiplying the random variables, not the densities). Then Z is distributed according to
the density pZ(Z) = K0(|Z|)
π
, where K0 is a modified Bessel function, and has the characteristic
function (Fourier transform) pˆZ(ω) = √
1
ω2+1 , which is everywhere positive [46].
Then, considering our situation with a product of a normal distributed scalar X and an independent
normal distributed vector Y ∈ R
N , the N entries of the product Z = XY become mutually
dependent. The marginal distribution of each entry is nevertheless exactly the above product
distribution pZ. By Fourier slice theorem, all one-dimensional slices through the main axes of the
characteristic function of Z must then coincide with the characteristic function pˆZ of this marginal
6However, for example the non-abelian group of 3-dimensional rotations, SO(3), is not obtained as a product
of the single-parameter “Euler angle” rotations along three axes, and therefore is not covered by the present
formulation of our theory. The reason is that the three different rotations do not commute. One may of course
still freely compose the three single-parameter rotation augmentations in sequence, but note that the combined
effect can only induce a subset of possible probability distributions on SO(3).
30
distribution. Finally, because the joint distribution is radially symmetric, so is the characteristic
function, and this must apply to all slices through the origin, yielding the everywhere positive Fourier
transform pˆZ(ω) = √
1
|ω|
2+1
. When stochastically mixed with identity (as is our random skipping
procedure), the Fourier Transform values are merely lifted towards 1 and no new zero-crossings are
introduced.
Additive noise in transformed bases Similar notes apply to additive noise in a different basis: one
can consider the noise augmentation as being flanked by an invertible deterministic (possibly also
nonlinear) basis transformation and its inverse. It then suffices to show that the additive noise has a
non-zero spectrum in isolation. In particular, multiplicative noise with a non-negative distribution
can be viewed as additive noise in logarithmic space and is invertible if the logarithmic version of the
noise distribution has no zeros in its Fourier transform. The image-space filters are a combination
of a linear basis transformation to the wavelet basis, and additive Gaussian noise under a non-linear
logarithmic transformation.
C.4.4 Random projection augmentations
The cutout augmentation (as well as e.g. the pixel and patch blocking in AmbientGAN [4]) can be
interpreted as projecting a random subset of the dimensions to zero.
Let P1,P2, ...,PN be a set of deterministic projection augmentation operators with the defining
property that P
2
j = Pj . For example, each one of these operators can set a different fixed rectangular
region to zero. Clearly the individual projections have a null space (unless they are the identity
projection) and they are not invertible in isolation.
Consider a stochastic augmentation that randomly applies one of these projections, or the identity.
Let p0, p1, ..., pN denote the discrete probabilities of choosing the identity operator I for p0, and
Pk for the remaining pk. Define the mixture of the projections as:
T = p0I +
X
N
j=1
pjPj (20)
Again, T is a mixture of operators, however unlike in earlier examples, some (but not all) of the
operators are non-invertible. Under what conditions on the probability distribution p is T invertible?
Assume that T is not invertible, i.e. there exists a probability distribution x 6= 0 such that T x = 0.
Then
0 = T x = p0x +
X
N
j=1
pjPjx (21)
and rearranging,
X
N
j=1
pjPjx = −p0x (22)
Under reasonable technical assumptions (e.g. discreteness of the pixel intensity values, such as
justified in Theorem 5.4. of Bora et al. [4]), we can consider the inner product of both sides of this
equation with x:
X
N
j=1
pj hx,Pjxi = −p0hx, xi (23)
The right side of this equation is strictly negative if the probability p0 of identity is greater than
zero, as x 6= 0. The left side is a non-negative sum of non-negative terms, as the inner product
of a vector with its projection is non-negative. Therefore, the assumption leads to a contradiction
unless p0 = 0; conversely, random projection augmentation does not leak if there is a non-zero
probability that it produces the identity.
31
C.5 Practical considerations
C.5.1 Conditioning
In practical numerical computation, an operator that is technically invertible may nevertheless be so
close to a non-invertible configuration that inversion fails in practice. Assuming a finite state space,
this notion is captured by the condition number, which is infinite when the matrix is singular, and
large when it is singular for all practical purposes. The same consideration applies to infinite state
spaces, but the appropriate technical notion of conditioning is less clear.
The practical value of the analysis in this section is in identifying the conditions where exact noninvertibility happens, so that appropriate safety margin can be kept. We achieve this by regulating the
probability p of performing a given augmentation, and keeping it at a safe distance from p = 1 which
for many of the augmentations corresponds to a non-invertible condition (e.g. uniform distribution
over compact group elements).
For example, consider applying transformations from a finite group with a uniform probability
distribution, where the augmentation is applied with probability p. In a finite state space, a matrix
corresponding to this augmentation has 1 − p for its smallest singular value, and 1 for the largest,
resulting in condition number 1/(1 − p) which approaches infinity as p approaches one.
C.5.2 Pixel-level effects and boundaries
When dealing with images represented on finite pixel grids, naive practical implementations of some
of the group transformations do not strictly speaking form groups. For example, a composition of
two continuous rotations of an image with angles φ and θ does not generally reproduce the same
image as a single rotation by angle φ + θ, if the transformed image is resampled to the rectangular
pixel grid twice. Furthermore, parts of the image may fall outside the boundaries of the grid, whereby
their values are lost and cannot be restored even if a reverse transformation is made afterwards,
unless special care is taken. These effects may become significant when multiple transformations are
composed.
In our implementation, we mitigate these issues as much as possible by accumulating the chain of
transformations into a matrix and a vector representing the total affine transformation implemented
by all the grouped augmentations, and only then applying it on the image. This is possible because
all the augmentations we use are affine transformations in the image (or color) space. Furthermore,
prior to applying the geometric transformations, the images are reflection padded and scaled to
double resolution (and conversely, cropped and downscaled afterwards). Effectively the image is
then treated as an infinite tiling of suitably reflected finer-resolution copies of itself, and a practical
target-resolution crop is only sampled at augmentation time.
D Implementation details
We implemented our techniques on top of the StyleGAN2 official TensorFlow implementation7
. We
kept most of the details unchanged, including network architectures [21], weight demodulation [21],
path length regularization [21], lazy regularization [21], style mixing regularization [20], bilinear
filtering in all up/downsampling layers [20], equalized learning rate for all trainable parameters [19],
minibatch standard deviation layer at the end of the discriminator [19], exponential moving average
of generator weights [19], non-saturating logistic loss [14] with R1 regularization [30], and Adam
optimizer [24] with β1 = 0, β2 = 0.99, and  = 10−8
.
We ran our experiments on a computing cluster with a few dozen NVIDIA DGX-1s, each containing
8 Tesla V100 GPUs, using TensorFlow 1.14.0, PyTorch 1.1.0 (for comparison methods), CUDA 10.0,
and cuDNN 7.6.3. We used the official pre-trained Inception network8
to compute FID, KID, and
Inception score.
32
Parameter StyleGAN2
config F
Our
baseline
BreCaHAD,
AFHQ MetFaces CIFAR-10 + Tuning
Resolution 1024×1024 256×256 512×512 1024×1024 32×32 32×32
Number of GPUs 8 8 8 8 2 2
Training length 25M 25M 25M 25M 100M 100M
Minibatch size 32 64 64 32 64 64
Minibatch stddev 4 8 8 4 32 32
Dataset x-flips X/ – – X X – –
Feature maps 1×
1
2× 1× 1× 512 512
Learning rate η×103
2 2.5 2.5 2 2.5 2.5
R1 regularization γ 10 1 0.5 2 0.01 0.01
G moving average 10k 20k 20k 10k 500k 500k
Mixed-precision – X X X X X
Mapping net depth 8 8 8 8 8 2
Style mixing reg. X X X X X –
Path length reg. X X X X X –
Resnet D X X X X X –
Figure 24: Hyperparameters used in each experiment.
D.1 Hyperparameters and training configurations
Figure 24 shows the hyperparameters that we used in our experiments, as well as the original
StyleGAN2 config F [21]. We performed all training runs using 8 GPUs and continued the training
until the discriminator had seen a total of 25M real images, except for CIFAR-10, where we used
2 GPUs and 100M images. We used minibatch size of 64 when possible, but reverted to 32 for
METFACES in order to avoid running out of GPU memory. Similar to StyleGAN2, we evaluated the
minibatch standard deviation layer independently over the images processed by each GPU.
Dataset augmentation We did not use dataset augmentation in any of our experiments with
FFHQ, LSUN CAT, or CIFAR-10, except for the FFHQ-140k case and in Figure 20. In particular,
we feel that leaky augmentations are inappropriate for CIFAR-10 given its status as a standard
benchmark dataset, where dataset/leaky augmentations would unfairly inflate the results. METFACES,
BRECAHAD, and AFHQ DOG are horizontally symmetric in nature, so we chose to enable dataset
x-flips for these datasets to maximize result quality.
Network capacity We follow the original StyleGAN2 configuration for high-resolution datasets
(≥ 5122
): a layer operating on N = w × h pixels uses min
2
16/
√
N, 512
feature maps. With
CIFAR-10 we use 512 feature maps for all layers. In the 256 × 256 configuration used with FFHQ
and LSUN CAT, we facilitate extensive sweeps over dataset sizes by decreasing the number of
feature maps to min
2
15/
√
N, 512
.
Learning rate and weight averaging We selected the optimal learning rates using grid search and
found that it is generally beneficial to use the highest learning rate that does not result in training
instability. We also found that larger minibatch size allows for a slightly higher learning rate. For the
moving average of generator weights [19], the natural choice is to parameterize the decay rate with
respect to minibatches— not individual images— so that increasing the minibatch size results in a
longer decay. Furthermore, we observed that a very long moving average consistently gave the best
results on CIFAR-10. To reduce startup bias, we linearly ramp up the length parameter from 0 to
500k over the first 10M images.
R1 regularization Karras et al. [21] postulated that the best choice for the R1 regularization weight
γ is highly dependent on the dataset. We thus performed extensive grid search for each column
7
https://github.com/NVlabs/stylegan2
8
http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz

in Figure 24, considering γ ∈ {0.001, 0.002, 0.005, . . . , 20, 50, 100}. Although the optimal γ does
vary wildly, from 0.01 to 10, it seems to scale almost linearly with the resolution of the dataset. In
practice, we have found that a good initial guess is given by γ0 = 0.0002 · N/M, where N = w × h
is the number of pixels and M is the minibatch size. Nevertheless, the optimal value of γ tends to
vary depending on the dataset, so we recommend experimenting with different values in the range
γ ∈ [γ0/5, γ0 · 5].
Mixed-precision training We utilize the high-performance Tensor Cores available in Volta-class
GPUs by employing mixed-precision FP16/FP32 training in all of our experiments (with two exceptions, discussed in Appendix D.2). We store the trainable parameters with full FP32 precision
for the purposes of optimization but cast them to FP16 before evaluating G and D. The main
challenge with mixed-precision training is that the numerical range of FP16 is limited to ∼ ±2
16, as
opposed to ∼ ±2
128 for FP32. Thus, any unexpected spikes in signal magnitude— no matter how
transient— will immediately collapse the training dynamics. We found that the risk of such spikes
can be reduced drastically using three tricks: first, by limiting the use of FP16 to only the 4 highest
resolutions, i.e., layers for which Nlayer ≥ Ndataset/(2 × 2)4
; second, by pre-normalizing the style
vector s and each row of the weight tensor w before applying weight modulation and demodulation9
;
and third, by clamping the output of every convolutional layer to ±2
8
, i.e., an order of magnitude
wider range than is needed in practice. We observed about 60% end-to-end speedup from using FP16
and verified that the results were virtually identical to FP32 on our baseline configuration.
CIFAR-10 We enable class-conditional image generation on CIFAR-10 by extending the original
StyleGAN2 architecture as follows. For the generator, we embed the class identifier into a 512-
dimensional vector that we concatenate with the original latent code after normalizing each, i.e.,
z
0 = concat
norm(z), norm(embed(c))
, where c is the class identifier. For the discriminator, we
follow the approach of Miyato and Koyama [32] by evaluating the final discriminator output as
D(x) = norm
embed(c)

· D0
(x)
T
, where D0
(x) corresponds to the feature vector produced by the
last layer of D. To compute FID, we generate 50k images using randomly selected class labels and
compare their statistics against the 50k images from the training set. For IS, we compute the mean
over 10 independent trials using 5k generated images per trial. As illustrated in Figures 11b and 24,
we found that we can improve the FID considerably by disabling style mixing regularization [20],
path length regularization [21], and residual connections in D [21]. Note that all of these features are
highly beneficial on higher-resolution datasets such as FFHQ. We find it somewhat alarming that
they have precisely the opposite effect on CIFAR-10 — this suggests that some previous conclusions
reached in the literature using CIFAR-10 may fail to generalize to other datasets.
D.2 Comparison methods
We implemented the comparison methods shown in Figures 8a on top of our baseline configuration, identifying the best-performing hyperparameters for each method via extensive grid search.
Furthermore, we inspected the resulting network weights and training dynamics in detail to verify
correct behavior, e.g., that with the discriminator indeed learns to correctly handle the auxiliary tasks
with PA-GAN and auxiliary rotations. We found zCR and WGAN-GP to be inherently incompatible
with our mixed-precision training setup due to their large variation in gradient magnitudes. We
thus reverted to full-precision FP32 for these methods. Similarly, we found lazy regularization
to be incompatible with bCR, zCR, WGAN-GP, and auxiliary rotations. Thus, we included their
corresponding loss terms directly into our main training loss, evaluated on every minibatch.
bCR We implement balanced consistency regularization proposed by Zhao et al. [53] by introducing
two new loss terms as shown in Figure 2a. We set λreal = λfake = 10 and use integer translations on
the range of [−8, +8] pixels. In Figure 20, we also perform experiments with x-flips and arbitrary
rotations.
zCR In addition to bCR, Zhao et al. [53] also propose latent consistency regularization (zCR) to
improve the diversity of the generated images. We implement zCR by perturbing each component of
the latent z by σnoise = 0.1 and encouraging the generator to maximize the L2 difference between the
9Note that our pre-normalization only affects the intermediate results; it has no effect on the final output of
the convolution layer due to the subsequent post-normalization performed by weight demodulation.

generated images, measured as an average over the pixels, with weight λgen = 0.02. Similarly, we
encourage the discriminator to minimize the L2 difference in D(x) with weight λdis = 0.2.
PA-GAN Zhang and Khoreva [48] propose to reduce overfitting by requiring the discriminator
to learn an auxiliary checksum task. This is done by providing a random bit string as additional
input to D, requiring that the sign of the output is flipped based on the parity of bits that were set,
and dynamically increasing the number of bits when overfitting is detected. We select the number
of bits using our rt heuristic with target 0.95. Given the value of p produced by the heuristic, we
calculate the number of bits as k = dp · 16e. Similar to Zhang and Khoreva, we fade in the effect
of newly added bits smoothly over the course of training. In practice, we use a fixed string of
16 bits, where the first k − 1 bits are sampled from Bernoulli(0.5), the k
th bit is sampled from
Bernoulli
min(p · 16 − k + 1, 0.5)
, and the remaining 16 − k bits are set to zero.
WGAN-GP For WGAN-GP, proposed by Gulrajani et al. [15], we reuse the existing implementation included in the StyleGAN2 codebase with λ = 10. We found WGAN-GP to be quite unstable
in our baseline configuration, which necessitated us to disable mixed-precision training and lazy
regularization, as well as to settle for a considerably lower learning rate η = 0.0010.
Auxiliary rotations Chen et al. [6] propose to improve GAN training by introducing an auxiliary
rotation loss for G and D. In addition the main training objective, the discriminator is shown real
images augmented with 90◦
rotations and asked to detect their correct orientation. Similarly, the
generator is encouraged to produce images whose orientation is easy for the discriminator to detect
correctly. We implement this method by introducing two new loss terms that are evaluated on a 4×
larger minibatch, consisting of rotated versions of the images shown to the discriminator as a part of
the main loss. We extend the last layer of D to output 5 scalar values instead of one and interpret the
last 4 components as raw logits for softmax cross-entropy loss. We weight the additional loss terms
using α = 10 for G, and β = 5 for D.
Spectral normalization Miyato et al. [31] propose to regularize the discriminator by explicitly
enforcing an upper bound for its Lipschitz constant, and several follow-up works [49, 5, 53, 38] have
found it to be beneficial. Given that spectral normalization is effectively a no-op when applied to
the StyleGAN2 generator [21], we apply it only to the discriminator. We ported the original Chainer
implementation10 to TensorFlow, and applied it to the main convolution layers of D. We found it
beneficial to not use spectral normalization with the FromRGB layer, residual skip connections, or the
last fully-connected layer.
Freeze-D Mo et al. [33] propose to freeze the first k layers of the discriminator to improve results
with transfer learning. We tested several different choices for k; the best results were given by k = 10
in Figure 9 and by k = 13 in Figure 11b. In practice, this corresponds to freezing all layers operating
at the 3 or 4 highest resolutions, respectively.
BigGAN BigGAN results in Figures 19 and 18 were run on a modified version of the original
BigGAN PyTorch implementation11. The implementation was adapted for unconditional operation
following Schönfeld et al. [38] by matching their hyperparameters, replacing class-conditional
BatchNorm with self-modulation, where the BatchNorm parameters are conditioned only on the
latent vector z, and not using class projection in the discriminator.
Mapping network depth For the “Shallow mapping” case in Figure 8a, we reduced the depth of
the mapping network from 8 to 2. Reducing the depth further than 2 yielded consistently inferior
results, confirming the usefulness of the mapping network. In general, we found depth 2 to yield
slightly better results than depth 8, making it a good default choice for future work.
Adaptive dropout Dropout [42] is a well-known technique for combating overfitting in practically
all areas of machine learning. In Figure 8a, we employ multiplicative Gaussian dropout for all layers
of the discriminator, similar to the approach employed by Karras et al. [19] in the context of LSGAN
10https://github.com/pfnet-research/sngan_projection
11https://github.com/ajbrock/BigGAN-PyTorch
3
loss [28]. We adjust the standard deviation dynamically using our rt heuristic with target 0.6, so that
the resulting p is used directly as the value for σ.
D.3 MetFaces dataset
We have collected a new dataset, MetFaces, by extracting images of human faces from the Metropolitan Museum of Art online collection. Dataset images were searched using terms such as ‘paintings’,
‘watercolor’ and ‘oil on canvas’, and downloaded via the https://metmuseum.github.io/ API. This
resulted in a set of source images that depicted paintings, drawings, and statues. Various automated
heuristics, such as face detection and image quality metrics, were used to narrow down the set
of images to contain only human faces. A manual selection pass over the remaining images was
performed to weed out poor quality images not caught by automated filtering. Finally, faces were
cropped and aligned to produce 1,336 high quality images at 10242
resolution.
The whole dataset, including the unprocessed images, is available at
https://github.com/NVlabs/metfaces-dataset
E Energy consumption
Computation is a core resource in any machine learning project: its availability and cost, as well as
the associated energy consumption, are key factors in both choosing research directions and practical
adoption. We provide a detailed breakdown for our entire project in Table 25 in terms of both GPU
time and electricity consumption. We report expended computational effort as single-GPU years
(Volta class GPU). We used a varying number of NVIDIA DGX-1s for different stages of the project,
and converted each run to single-GPU equivalents by simply scaling by the number of GPUs used.
We followed the Green500 power measurements guidelines [12] similarly to Karras et al. [21]. The
entire project consumed approximately 300 megawatt hours (MWh) of electricity. Almost half of
the total energy was spent on exploration and shaping the ideas before the actual paper production
started. Subsequently the majority of computation was targeted towards the extensive sweeps shown
in various figures. Given that ADA does not significantly affect the cost of training a single model,
e.g., training StyleGAN2 [21] with 1024 × 1024 FFHQ still takes approximately 0.7 MWh.
36
Item Number of GPU years Electricity
training runs (Volta) (MWh)
Early exploration 253 22.65 52.05
Paper exploration 1116 36.54 87.39
Setting up the baselines 251 12.19 30.70
Paper figures 960 50.53 108.02
Fig.1 Baseline convergence 21 1.01 2.27
Fig.3 Leaking behavior 78 3.62 7.93
Fig.4 Augmentation categories 90 4.45 9.40
Fig.5 ADA heuristics 61 3.16 6.87
Fig.6 ADA convergence 15 0.78 1.70
Fig.7 Training set sweeps 174 10.82 22.70
Fig.8a Comparison methods 69 4.18 8.64
Fig.8b Discriminator capacity 144 7.70 15.93
Fig.9 Transfer learning 40 0.71 1.67
Fig.11a Small datasets 30 1.71 4.15
Fig.11b CIFAR-10 30 0.93 2.71
Fig.19 BigGAN comparison 54 3.34 7.12
Fig.20 bCR leaks 40 2.19 4.57
Fig.21 Cumulative augmentations 114 5.93 12.36
Results intentionally left out 177 5.51 11.78
Wasted due to technical issues 255 3.86 8.39
Code release 375 12.49 26.71
Total 3387 143.76 325.06
Figure 25: Computational effort expenditure and electricity consumption data for this project. The unit
for computation is GPU-years on a single NVIDIA V100 GPU — it would have taken approximately
135 years to execute this project using a single GPU. See the text for additional details about the
computation and energy consumption estimates. Early exploration includes all training runs that
affected our decision to start this project. Paper exploration includes all training runs that were done
specifically for this project, but were not intended to be used in the paper as-is. Setting up the baselines
includes all hyperparameter tuning for the baselines. Figures provides a per-figure breakdown, and
underlines that just reproducing all the figures would require over 50 years of computation on a single
GPU. Results intentionally left out includes additional results that were initially planned, but then left
out to improve focus and clarity. Wasted due to technical issues includes computation wasted due
to code bugs and infrastructure issues. Code release covers testing and benchmarking related to the
public release.
37



Main menu

WikipediaThe Free Encyclopedia
Search Wikipedia
Search
Create account
Log in

Personal tools
Contents hide
(Top)
Etymology
History
Toggle History subsection
Geography
Toggle Geography subsection
Government and politics
Toggle Government and politics subsection
Economy
Toggle Economy subsection
Demographics
Toggle Demographics subsection
Culture
Toggle Culture subsection
See also
Notes
References
Toggle References subsection
External links
Poland

Article
Talk
Read
View source
View history

Tools
Coordinates: 52°N 20°E
Page semi-protected
From Wikipedia, the free encyclopedia
"Polska" and "Rzeczpospolita Polska" redirect here. For the dance, see Polska (dance). For other uses, see Poland (disambiguation) and Rzeczpospolita (disambiguation).
Republic of Poland
Rzeczpospolita Polska (Polish)
Flag of Poland
Flag
Coat of arms of Poland
Coat of arms
Anthem: Mazurek Dąbrowskiego
"Poland Is Not Yet Lost"
0:43
EU-Poland (orthographic projection).svg
Show globe
Show map of Europe
Show all
Location of Poland (dark green)
– in Europe (green & dark grey)
– in the European Union (green)  –  [Legend]

Capital
and largest city
Warsaw
52°13′N 21°02′E
Official language	Polish[1]
Ethnic groups (2011)[2]	
98% Poles
2% other/unanswered
Religion (2011)[3]	
88.7% Christianity
87.6% Catholicism
1.1% other Christian
2.4% no religion
0.2% other
8.7% unanswered
Demonym(s)	
PolishPole
Government	Unitary parliamentary republic
• President
Andrzej Duda
• Prime Minister
Mateusz Morawiecki
Legislature	Parliament
• Upper house
Senate
• Lower house
Sejm
Formation
• Baptism of Poland
14 April 966
• Kingdom of Poland
18 April 1025
• Polish–Lithuanian Commonwealth
1 July 1569
• Partitions of Poland
24 October 1795
• Second Republic
11 November 1918
• Government-in-exile
17 September 1939
• People's Republic
19 February 1947
• Third Republic
31 December 1989[4]
Area
• Total
312,696 km2 (120,733 sq mi)[5] (69th)
• Water (%)
1.48 (2015)[6]
Population
• 2022 census
Neutral decrease 38,036,118[7] (38th)
• Density
122/km2 (316.0/sq mi) (98th)
GDP (PPP)	2023 estimate
• Total
Increase $1.705 trillion[8] (21st)
• Per capita
Increase $45,343[8] (41st)
GDP (nominal)	2023 estimate
• Total
Increase $748.8 billion[8] (22nd)
• Per capita
Increase $19,912[8] (50th)
Gini (2020)	Positive decrease 27.2[9]
low
HDI (2021)	Increase 0.876[10]
very high · 34th
Currency	Złoty (PLN)
Time zone	UTC+1 (CET)
• Summer (DST)
UTC+2 (CEST)
Date format	dd.mm.yyyy (CE)
Driving side	right
Calling code	+48
ISO 3166 code	PL
Internet TLD	.pl
Poland,[a] officially the Republic of Poland,[b] is a country in Central Europe. It is divided into 16 administrative provinces called voivodeships, covering an area of 312,696 km2 (120,733 sq mi). Poland has a population of 38 million and is the fifth-most populous member state of the European Union. Warsaw is the nation's capital and largest metropolis. Other major cities include Kraków, Wrocław, Łódź, Poznań, Gdańsk, and Szczecin.

Poland has a temperate transitional climate and its territory traverses the Central European Plain, extending from Baltic Sea in the north to Sudeten and Carpathian Mountains in the south. The longest Polish river is the Vistula, and Poland's highest point is Mount Rysy, situated in the Tatra mountain range of the Carpathians. The country is bordered by Lithuania and Russia to the northeast,[c] Belarus and Ukraine to the east, Slovakia and the Czech Republic to the south, and Germany to the west. It also shares maritime boundaries with Denmark and Sweden.

The history of human activity on Polish soil dates to c. 10,000 BC. Culturally diverse throughout late antiquity, the region became inhabited by tribal Polans who gave Poland its name in the early medieval period. The establishment of statehood in 966 coincided with a pagan ruler of the Polans converting to Christianity under the auspices of the Roman Church. The Kingdom of Poland emerged in 1025 and in 1569 cemented its longstanding association with Lithuania, thus forming the Polish–Lithuanian Commonwealth. It was one of the great powers of Europe at the time, with a uniquely liberal political system that adopted Europe's first modern constitution in 1791.

With the passing of a prosperous Polish Golden Age, the country was partitioned by neighbouring states at the end of the 18th century and regained its independence in 1918 as the Second Polish Republic. In September 1939, the invasion of Poland by Germany and the Soviet Union marked the beginning of World War II, which resulted in the Holocaust and millions of Polish casualties. As a member of the Communist Bloc in the global Cold War, the Polish People's Republic was a founding signatory of the Warsaw Pact. Through the emergence and contributions of the Solidarity movement, the communist government was dissolved and Poland re-established itself as a democratic state in 1989.

Poland is a parliamentary republic, with its bicameral legislature comprising the Sejm and the Senate. It is a developed market and a high income economy. Considered a middle power, Poland has the sixth largest economy in the European Union by GDP (nominal) and the fifth largest by GDP (PPP). It provides a very high standard of living, safety and economic freedom, as well as free university education and a universal health care system. The country has 17 UNESCO World Heritage Sites, 15 of which are cultural. Poland is a founding member state of the United Nations, as well as a member of the World Trade Organization, NATO, and the European Union (including the Schengen Area).

Etymology
Main article: Names of Poland
The native Polish name for Poland is Polska.[11] The name is derived from the Polans, a West Slavic tribe who inhabited the Warta River basin of present-day Greater Poland region (6th–8th century CE).[12] The tribe's name stems from the Proto-Slavic noun pole meaning field, which in-itself originates from the Proto-Indo-European word *pleh₂- indicating flatland.[13] The etymology alludes to the topography of the region and the flat landscape of Greater Poland.[14][15] The English name Poland was formed in the 1560s, from German Pole(n) and the suffix -land, denoting a people or nation.[16][17] Prior to its adoption, the Latin form Polonia was widely used throughout medieval Europe.[18]

The country's alternative archaic name is Lechia and its root syllable remains in official use in several languages, notably Hungarian, Lithuanian, and Persian.[19] The exonym possibly derives from either Lech, a legendary ruler of the Lechites, or from the Lendians, a West Slavic tribe that dwelt on the south-easternmost edge of Lesser Poland.[20][21] The origin of the tribe's name lies in the Old Polish word lęda (plain).[22] Initially, both names Lechia and Polonia were used interchangeably when referring to Poland by chroniclers during the Middle Ages.[23]

History
Main article: History of Poland
Prehistory and protohistory
Main articles: Bronze- and Iron-Age Poland, Poland in Antiquity, Early Slavs, West Slavs, Lechites, and Poland in the Early Middle Ages

A reconstruction of a Bronze Age, Lusatian culture settlement in Biskupin, 8th century BC
The first Stone Age archaic humans and Homo erectus species settled what was to become Poland approximately 500,000 years ago, though the ensuing hostile climate prevented early humans from founding more permanent encampments.[24] The arrival of Homo sapiens and anatomically modern humans coincided with the climatic discontinuity at the end of the Last Glacial Period (10,000 BC), when Poland became habitable.[25] Neolithic excavations indicated broad-ranging development in that era; the earliest evidence of European cheesemaking (5500 BC) was discovered in Polish Kuyavia,[26] and the Bronocice pot is incised with the earliest known depiction of what may be a wheeled vehicle (3400 BC).[27]

The period spanning the Bronze Age and the Early Iron Age (1300 BC–500 BC) was marked by an increase in population density, establishment of palisaded settlements (gords) and the expansion of Lusatian culture.[28][29] A significant archaeological find from the protohistory of Poland is a fortified settlement at Biskupin, attributed to the Lusatian culture of the Late Bronze Age (mid-8th century BC).[30]

Throughout antiquity (400 BC–500 AD), many distinct ancient populations inhabited the territory of present-day Poland, notably Celtic, Scythian, Germanic, Sarmatian, Baltic and Slavic tribes.[31] Furthermore, archaeological findings confirmed the presence of Roman Legions sent to protect the amber trade.[32] The Polish tribes emerged following the second wave of the Migration Period around the 6th century AD;[18] they were Slavic and possibly may have included assimilated remnants of peoples that earlier dwelled in the area.[33][34] Beginning in the early 10th century, the Polans would come to dominate other Lechitic tribes in the region, initially forming a tribal federation and later a centralised monarchial state.[35]

Kingdom of Poland
Main articles: History of Poland during the Piast dynasty, History of Poland during the Jagiellonian dynasty, Christianization of Poland, and Kingdom of Poland

Poland under the rule of Mieszko I, whose acceptance of Christianity under the auspices of the Roman Church and the Baptism of Poland marked the beginning of statehood in 966.
Poland began to form into a recognisable unitary and territorial entity around the middle of the 10th century under the Piast dynasty.[36] In 966, ruler of the Polans Mieszko I accepted Christianity under the auspices of the Roman Church with the Baptism of Poland.[37] An incipit titled Dagome iudex first defined Poland's geographical boundaries with its capital and bishopric at Gniezno, and affirmed that its monarchy was under the protection of the Apostolic See.[38] The country's early origins were described by Gallus Anonymus in Gesta principum Polonorum, the oldest Polish chronicle.[39] An important national event of the period was the martyrdom of Saint Adalbert, who was killed by Prussian pagans in 997 and whose remains were reputedly bought back for their weight in gold by Mieszko's successor, Bolesław I the Brave.[38]

In 1000, at the Congress of Gniezno, Bolesław obtained the right of investiture from Otto III, Holy Roman Emperor, who assented to the creation of additional bishoprics.[38] Three new dioceses were subsequently established in Kraków, Kołobrzeg, and Wrocław.[40] Also, Otto bestowed upon Bolesław royal regalia and a replica of the Holy Lance, which were later used at his coronation as the first King of Poland in c. 1025, when Bolesław received permission for his coronation from Pope John XIX.[41][42] Bolesław also expanded the realm considerably by seizing parts of German Lusatia, Czech Moravia, Upper Hungary and southwestern regions of the Kievan Rus'.[43]


Casimir III the Great is the only Polish king to receive the title of Great. He built extensively during his reign, and reformed the Polish army along with the country's legal code, 1333–70.
The transition from paganism in Poland was not instantaneous and resulted in the pagan reaction of the 1030s.[44] In 1031, Mieszko II Lambert lost the title of king and fled amidst the violence.[45] The unrest led to the transfer of the capital to Kraków in 1038 by Casimir I the Restorer.[46] In 1076, Bolesław II re-instituted the office of king, but was banished in 1079 for murdering his opponent, Bishop Stanislaus.[47] In 1138, the country fragmented into five principalities when Bolesław III Wrymouth divided his lands among his sons.[20] These comprised Lesser Poland, Greater Poland, Silesia, Masovia and Sandomierz, with intermittent hold over Pomerania.[48] In 1226, Konrad I of Masovia invited the Teutonic Knights to aid in combating the Baltic Prussians; a decision that led to centuries of warfare with the Knights.[49]

In the mid-13th century, Henry I the Bearded and Henry II the Pious aimed to unite the fragmented dukedoms, but the Mongol invasions and the death of Henry II in battle hindered the unification.[50][51] As a result of the devastation which followed, depopulation and the demand for craft labour spurred a migration of German and Flemish settlers into Poland, which was encouraged by the Polish dukes.[52] In 1264, the Statute of Kalisz introduced unprecedented autonomy for the Polish Jews, who came to Poland fleeing persecution elsewhere in Europe.[53] In 1320, Władysław I the Short became the first king of a reunified Poland since Przemysł II in 1296,[54] and the first to be crowned at Wawel Cathedral in Kraków.[55]

Beginning in 1333, the reign of Casimir III the Great was marked by developments in castle infrastructure, army, judiciary and diplomacy.[56][57] Under his authority, Poland transformed into a major European power; he instituted Polish rule over Ruthenia in 1340 and imposed quarantine that prevented the spread of Black Death.[58][59] In 1364, Casimir inaugurated the University of Kraków, one of the oldest institutions of higher learning in Europe.[60] Upon his death in 1370, the Piast dynasty came to an end.[61] He was succeeded by his closest male relative, Louis of Anjou, who ruled Poland, Hungary and Croatia in a personal union.[62] Louis' younger daughter Jadwiga became Poland's first female monarch in 1384.[62]


The Battle of Grunwald was fought against the German Order of Teutonic Knights, and resulted in a decisive victory for the Kingdom of Poland, 15 July 1410.
In 1386, Jadwiga of Poland entered a marriage of convenience with Władysław II Jagiełło, the Grand Duke of Lithuania, thus forming the Jagiellonian dynasty and the Polish–Lithuanian union which spanned the late Middle Ages and early Modern Era.[63] The partnership between Poles and Lithuanians brought the vast multi-ethnic Lithuanian territories into Poland's sphere of influence and proved beneficial for its inhabitants, who coexisted in one of the largest European political entities of the time.[64]

In the Baltic Sea region, the struggle of Poland and Lithuania with the Teutonic Knights continued and culminated at the Battle of Grunwald in 1410, where a combined Polish-Lithuanian army inflicted a decisive victory against them.[65] In 1466, after the Thirteen Years' War, king Casimir IV Jagiellon gave royal consent to the Peace of Thorn, which created the future Duchy of Prussia under Polish suzerainty and forced the Prussian rulers to pay tributes.[20] The Jagiellonian dynasty also established dynastic control over the kingdoms of Bohemia (1471 onwards) and Hungary.[66] In the south, Poland confronted the Ottoman Empire and the Crimean Tatars, and in the east helped Lithuania to combat Russia.[20]

Poland was developing as a feudal state, with a predominantly agricultural economy and an increasingly powerful landed nobility that confined the population to private manorial farmsteads, or folwarks.[67] In 1493, John I Albert sanctioned the creation of a bicameral parliament composed of a lower house, the Sejm, and an upper house, the Senate.[68] The Nihil novi act adopted by the Polish General Sejm in 1505, transferred most of the legislative power from the monarch to the parliament, an event which marked the beginning of the period known as Golden Liberty, when the state was ruled by the seemingly free and equal Polish nobles.[69]


Wawel Castle in Kraków, seat of Polish kings from 1038 until the capital was moved to Warsaw in 1596.
The 16th century saw Protestant Reformation movements making deep inroads into Polish Christianity, which resulted in the establishment of policies promoting religious tolerance, unique in Europe at that time.[70] This tolerance allowed the country to avoid the religious turmoil and wars of religion that beset Europe.[70] In Poland, Nontrinitarian Christianity became the doctrine of the so-called Polish Brethren, who separated from their Calvinist denomination and became the co-founders of global Unitarianism.[71]

The European Renaissance evoked under Sigismund I the Old and Sigismund II Augustus a sense of urgency in the need to promote a cultural awakening.[20] During the Polish Golden Age, the nation's economy and culture flourished.[20] The Italian-born Bona Sforza, daughter of the Duke of Milan and queen consort to Sigismund I, made considerable contributions to architecture, cuisine, language and court customs at Wawel Castle.[20]

Polish–Lithuanian Commonwealth
Main articles: History of Poland in the Early Modern era (1569–1795), Crown of the Kingdom of Poland, and Polish–Lithuanian Commonwealth

The Polish-Lithuanian Commonwealth at its greatest extent in 1619
The Union of Lublin of 1569 established the Polish–Lithuanian Commonwealth, a unified federal state with an elective monarchy, but largely governed by the nobility.[72] The latter coincided with a period of prosperity; the Polish-dominated union thereafter becoming a leading power and a major cultural entity, exercising political control over parts of Central, Eastern, Southeastern and Northern Europe. The Polish–Lithuanian Commonwealth occupied approximately 1 million km2 (390,000 sq mi) at its peak and was the largest state in Europe.[73][74] Simultaneously, Poland imposed Polonisation policies in newly acquired territories which were met with resistance from ethnic and religious minorities.[72]

In 1573, Henry de Valois of France, the first elected king, approbated the Henrician Articles which obliged future monarchs to respect the rights of nobles.[75] His successor, Stephen Báthory, led a successful campaign in the Livonian War, granting Poland more lands across the eastern shores of the Baltic Sea.[76] State affairs were then headed by Jan Zamoyski, the Crown Chancellor.[77] In 1592, Sigismund III of Poland succeeded his father, John Vasa, in Sweden.[78] The Polish-Swedish union endured until 1599, when he was deposed by the Swedes.[79]


King John III Sobieski defeated the Ottoman Turks at the Battle of Vienna on 12 September 1683.
In 1609, Sigismund invaded Russia which was engulfed in a civil war,[20] and a year later the Polish winged hussar units under Stanisław Żółkiewski occupied Moscow for two years after defeating the Russians at Klushino.[20] Sigismund also countered the Ottoman Empire in the southeast; at Khotyn in 1621 Jan Karol Chodkiewicz achieved a decisive victory against the Turks, which ushered the downfall of Sultan Osman II.[80][81]

Sigismund's long reign in Poland coincided with the Silver Age.[82] The liberal Władysław IV effectively defended Poland's territorial possessions but after his death the vast Commonwealth began declining from internal disorder and constant warfare.[83][84] In 1648, the Polish hegemony over Ukraine sparked the Khmelnytsky Uprising,[85] followed by the decimating Swedish Deluge during the Second Northern War,[86] and Prussia's independence in 1657.[86] In 1683, John III Sobieski re-established military prowess when he halted the advance of an Ottoman Army into Europe at the Battle of Vienna.[87] The successive Saxon era, under Augustus II and Augustus III, saw the rise of neighbouring countries in the aftermath of the Great Northern War (1700) and the War of the Polish Succession (1733).[88]

Partitions
Main articles: History of Poland (1795–1918) and Partitions of Poland

Stanisław II Augustus, the last King of Poland, reigned from 1764 until his abdication on 25 November 1795.
The royal election of 1764 resulted in the elevation of Stanisław II Augustus Poniatowski to the monarchy.[89] His candidacy was extensively funded by his sponsor and former lover, Empress Catherine II of Russia.[90] The new king maneuvered between his desire to implement necessary modernising reforms, and the necessity to remain at peace with surrounding states.[91] His ideals led to the formation of the 1768 Bar Confederation, a rebellion directed against the Poniatowski and all external influence, which ineptly aimed to preserve Poland's sovereignty and privileges held by the nobility.[92] The failed attempts at government restructuring as well as the domestic turmoil provoked its neighbours to intervene.[93]

In 1772, the First Partition of the Commonwealth by Prussia, Russia and Austria took place; an act which the Partition Sejm, under considerable duress, eventually ratified as a fait accompli.[94] Disregarding the territorial losses, in 1773 a plan of critical reforms was established, in which the Commission of National Education, the first government education authority in Europe, was inaugurated.[95] Corporal punishment of schoolchildren was officially prohibited in 1783. Poniatowski was the head figure of the Enlightenment, encouraged the development of industries, and embraced republican neoclassicism.[96] For his contributions to the arts and sciences he was awarded a Fellowship of the Royal Society.[97]

In 1791, Great Sejm parliament adopted the 3 May Constitution, the first set of supreme national laws, and introduced a constitutional monarchy.[98] The Targowica Confederation, an organisation of nobles and deputies opposing the act, appealed to Catherine and caused the 1792 Polish–Russian War.[99] Fearing the reemergence of Polish hegemony, Russia and Prussia arranged and in 1793 executed, the Second Partition, which left the country deprived of territory and incapable of independent existence. On 24 October 1795, the Commonwealth was partitioned for the third time and ceased to exist as a territorial entity.[100][101] Stanisław Augustus, the last King of Poland, abdicated the throne on 25 November 1795.[102]

Era of insurrections
Main articles: Austrian Partition, Prussian Partition, and Russian Partition

The partitions of Poland, carried out by the Kingdom of Prussia (blue), the Russian Empire (brown), and the Austrian Habsburg Monarchy (green) in 1772, 1793 and 1795.
The Polish people rose several times against the partitioners and occupying armies. An unsuccessful attempt at defending Poland's sovereignty took place in the 1794 Kościuszko Uprising, where a popular and distinguished general Tadeusz Kościuszko, who had several years earlier served under George Washington in the American Revolutionary War, led Polish insurgents.[103] Despite the victory at the Battle of Racławice, his ultimate defeat ended Poland's independent existence for 123 years.[104]

In 1806, an insurrection organised by Jan Henryk Dąbrowski liberated western Poland ahead of Napoleon's advance into Prussia during the War of the Fourth Coalition. In accordance with the 1807 Treaty of Tilsit, Napoleon proclaimed the Duchy of Warsaw, a client state ruled by his ally Frederick Augustus I of Saxony. The Poles actively aided French troops in the Napoleonic Wars, particularly those under Józef Poniatowski who became Marshal of France shortly before his death at Leipzig in 1813.[105] In the aftermath of Napoleon's exile, the Duchy of Warsaw was abolished at the Congress of Vienna in 1815 and its territory was divided into Russian Congress Kingdom of Poland, the Prussian Grand Duchy of Posen, and Austrian Galicia with the Free City of Kraków.[106]


Tadeusz Kościuszko was a veteran and hero of both the Polish and American wars of independence.[103]
In 1830, non-commissioned officers at Warsaw's Officer Cadet School rebelled in what was the November Uprising.[107] After its collapse, Congress Poland lost its constitutional autonomy, army and legislative assembly.[108] During the European Spring of Nations, Poles took up arms in the Greater Poland Uprising of 1848 to resist Germanisation, but its failure saw duchy's status reduced to a mere province; and subsequent integration into the German Empire in 1871.[109] In Russia, the fall of the January Uprising (1863–1864) prompted severe political, social and cultural reprisals, followed by deportations and pogroms of the Polish-Jewish population. Towards the end of the 19th century, Congress Poland became heavily industrialised; its primary exports being coal, zinc, iron and textiles.[110][111]

Second Polish Republic
Main articles: History of Poland (1918–1939), Battle of Warsaw (1920), and Second Polish Republic

Chief of State Marshal Józef Piłsudski was a hero of the Polish independence campaign and the nation's premiere statesman from 1918 until his death on 12 May 1935.
In the aftermath of World War I, the Allies agreed on the reconstitution of Poland, confirmed through the Treaty of Versailles of June 1919.[112] A total of 2 million Polish troops fought with the armies of the three occupying powers, and over 450,000 died.[113] Following the armistice with Germany in November 1918, Poland regained its independence as the Second Polish Republic.[114]

The Second Polish Republic reaffirmed its sovereignty after a series of military conflicts, most notably the Polish–Soviet War, when Poland inflicted a crushing defeat on the Red Army at the Battle of Warsaw.[115]

The inter-war period heralded a new era of Polish politics. Whilst Polish political activists had faced heavy censorship in the decades up until World War I, a new political tradition was established in the country. Many exiled Polish activists, such as Ignacy Jan Paderewski, who would later become prime minister, returned home. A significant number of them then went on to take key positions in the newly formed political and governmental structures. Tragedy struck in 1922 when Gabriel Narutowicz, inaugural holder of the presidency, was assassinated at the Zachęta Gallery in Warsaw by a painter and right-wing nationalist Eligiusz Niewiadomski.[116]

In 1926, the May Coup, led by the hero of the Polish independence campaign Marshal Józef Piłsudski, turned rule of the Second Polish Republic over to the nonpartisan Sanacja (Healing) movement to prevent radical political organizations on both the left and the right from destabilizing the country.[117] By the late 1930s, due to increased threats posed by political extremism inside the country, the Polish government became increasingly heavy-handed, banning a number of radical organisations, including communist and ultra-nationalist political parties, which threatened the stability of the country.[118]

World War II
Main articles: History of Poland (1939–1945), Invasion of Poland, Polish contribution to World War II, and War crimes in occupied Poland during World War II

Polish Army 7TP tanks on military manoeuvres shortly before the invasion of Poland in 1939
World War II began with the Nazi German invasion of Poland on 1 September 1939, followed by the Soviet invasion of Poland on 17 September. On 28 September 1939, Warsaw fell. As agreed in the Molotov–Ribbentrop Pact, Poland was split into two zones, one occupied by Nazi Germany, the other by the Soviet Union. In 1939–1941, the Soviets deported hundreds of thousands of Poles. The Soviet NKVD executed thousands of Polish prisoners of war (among other incidents in the Katyn massacre) ahead of Operation Barbarossa.[119] German planners had in November 1939 called for "the complete destruction of all Poles" and their fate as outlined in the genocidal Generalplan Ost.[120]


Pilots of the 303 Polish Fighter Squadron during the Battle of Britain, October 1940
Poland made the fourth-largest troop contribution in Europe,[121][122][123] and its troops served both the Polish Government in Exile in the west and Soviet leadership in the east. Polish troops played an important role in the Normandy, Italian and North African Campaigns and are particularly remembered for the Battle of Monte Cassino.[124][125] Polish intelligence operatives proved extremely valuable to the Allies, providing much of the intelligence from Europe and beyond,[126] and Polish code breakers were responsible for cracking the Enigma cipher. In the east, the Soviet-backed Polish 1st Army distinguished itself in the battles for Warsaw and Berlin.[127]

The wartime resistance movement, and the Armia Krajowa (Home Army), fought against German occupation. It was one of the three largest resistance movements of the entire war, and encompassed a range of clandestine activities, which functioned as an underground state complete with degree-awarding universities and a court system.[128] The resistance was loyal to the exiled government and generally resented the idea of a communist Poland; for this reason, in the summer of 1944 it initiated Operation Tempest, of which the Warsaw Uprising that began on 1 August 1944 is the best-known operation.[127][129]


Map of the Holocaust in German-occupied Poland with deportation routes and massacre sites. Major ghettos are marked with yellow stars. Nazi extermination camps are marked with white skulls in black squares. The border in 1941 between Nazi Germany and the Soviet Union is marked in red.
Nazi German forces under orders from Adolf Hitler set up six German extermination camps in occupied Poland, including Treblinka, Majdanek and Auschwitz. The Germans transported millions of Jews from across occupied Europe to be murdered in those camps.[130][131] Altogether, 3 million Polish Jews[132][133] – approximately 90% of Poland's pre-war Jewry – and between 1.8 and 2.8 million ethnic Poles[134][135][136] were killed during the German occupation of Poland, including between 50,000 and 100,000 members of the Polish intelligentsia – academics, doctors, lawyers, nobility and priesthood. During the Warsaw Uprising alone, over 150,000 Polish civilians were killed, most were murdered by the Germans during the Wola and Ochota massacres.[137][138] Around 150,000 Polish civilians were killed by Soviets between 1939 and 1941 during the Soviet Union's occupation of eastern Poland (Kresy), and another estimated 100,000 Poles were murdered by the Ukrainian Insurgent Army (UPA) between 1943 and 1944 in what became known as the Wołyń Massacres.[139][140] Of all the countries in the war, Poland lost the highest percentage of its citizens: around 6 million perished – more than one-sixth of Poland's pre-war population – half of them Polish Jews.[141][142][143] About 90% of deaths were non-military in nature.[144]

In 1945, Poland's borders were shifted westwards. Over two million Polish inhabitants of Kresy were expelled along the Curzon Line by Stalin.[145] The western border became the Oder-Neisse line. As a result, Poland's territory was reduced by 20%, or 77,500 square kilometres (29,900 sq mi). The shift forced the migration of millions of other people, most of whom were Poles, Germans, Ukrainians, and Jews.[146][147][148]

Post-war communism
Main articles: History of Poland (1945–1989), Polish People's Republic, History of Solidarity, and Polish Round Table Agreement

At High Noon, 4 June 1989 — political poster featuring Gary Cooper to encourage votes for the Solidarity party in the 1989 elections
At the insistence of Joseph Stalin, the Yalta Conference sanctioned the formation of a new provisional pro-Communist coalition government in Moscow, which ignored the Polish government-in-exile based in London. This action angered many Poles who considered it a betrayal by the Allies. In 1944, Stalin had made guarantees to Churchill and Roosevelt that he would maintain Poland's sovereignty and allow democratic elections to take place. However, upon achieving victory in 1945, the elections organised by the occupying Soviet authorities were falsified and were used to provide a veneer of legitimacy for Soviet hegemony over Polish affairs. The Soviet Union instituted a new communist government in Poland, analogous to much of the rest of the Eastern Bloc. As elsewhere in Communist Europe, the Soviet influence over Poland was met with armed resistance from the outset which continued into the 1950s.[149]

Despite widespread objections, the new Polish government accepted the Soviet annexation of the pre-war eastern regions of Poland[150] (in particular the cities of Wilno and Lwów) and agreed to the permanent garrisoning of Red Army units on Poland's territory. Military alignment within the Warsaw Pact throughout the Cold War came about as a direct result of this change in Poland's political culture. In the European scene, it came to characterise the full-fledged integration of Poland into the brotherhood of communist nations.[151]

The new communist government took control with the adoption of the Small Constitution on 19 February 1947. The Polish People's Republic (Polska Rzeczpospolita Ludowa) was officially proclaimed in 1952. In 1956, after the death of Bolesław Bierut, the régime of Władysław Gomułka became temporarily more liberal, freeing many people from prison and expanding some personal freedoms. Collectivization in the Polish People's Republic failed. A similar situation repeated itself in the 1970s under Edward Gierek, but most of the time persecution of anti-communist opposition groups persisted. Despite this, Poland was at the time considered to be one of the least oppressive states of the Eastern Bloc.[152]

Labour turmoil in 1980 led to the formation of the independent trade union "Solidarity" ("Solidarność"), which over time became a political force. Despite persecution and imposition of martial law in 1981 by General Wojciech Jaruzelski, it eroded the dominance of the Polish United Workers' Party and by 1989 had triumphed in Poland's first partially free and democratic parliamentary elections since the end of the Second World War. Lech Wałęsa, a Solidarity candidate, eventually won the presidency in 1990. The Solidarity movement heralded the collapse of communist regimes and parties across Europe.[153]

Third Polish Republic
Main article: History of Poland (1989–present)

Flowers in front of the Presidential Palace following the death of Poland's top government officials in a plane crash on 10 April 2010
A shock therapy program, initiated by Leszek Balcerowicz in the early 1990s, enabled the country to transform its socialist-style planned economy into a market economy.[154] As with other post-communist countries, Poland suffered temporary declines in social, economic, and living standards,[155] but it became the first post-communist country to reach its pre-1989 GDP levels as early as 1995, largely due to its booming economy.[156] Poland became a member of the Visegrád Group in 1991,[157] and joined NATO in 1999.[158] Poles then voted to join the European Union in a referendum in June 2003,[159] with Poland becoming a full member on 1 May 2004, following the consequent enlargement of the organisation.[160]

Poland joined the Schengen Area in 2007, as a result of which, the country's borders with other member states of the European Union have been dismantled, allowing for full freedom of movement within most of the European Union.[161] On 10 April 2010, the President of Poland Lech Kaczyński, along with 89 other high-ranking Polish officials died in a plane crash near Smolensk, Russia.[162]

In 2011, the ruling Civic Platform won parliamentary elections.[163] In 2014, the Prime Minister of Poland, Donald Tusk, was chosen to be President of the European Council, and resigned as prime minister.[164] The 2015 and 2019 elections were won by the conservative Law and Justice Party (PiS) led by Jarosław Kaczyński,[165][166] resulting in increased Euroscepticism and increased friction with the European Union.[167][168] In December 2017, Mateusz Morawiecki was sworn in as the new Prime Minister, succeeding Beata Szydlo, in office since 2015. President Andrzej Duda, supported by Law and Justice party, was narrowly re-elected in the 2020 presidential election.[169] Russia's invasion of Ukraine in 2022 led to 6.9 million Ukrainian refugees arriving in Poland.[170]

Geography
Main article: Geography of Poland

Topographic map of Poland
Poland covers an administrative area of 312,722 km2 (120,743 sq mi), and is the ninth-largest country in Europe. Approximately 311,895 km2 (120,423 sq mi) of the country's territory consists of land, 2,041 km2 (788 sq mi) comprises internal waters and 8,783 km2 (3,391 sq mi) is territorial sea.[171] Topographically, the landscape of Poland is characterised by diverse landforms, water bodies and ecosystems.[172] The central and northern region bordering the Baltic Sea lie within the flat Central European Plain, but its south is hilly and mountainous.[173] The average elevation above the sea level is estimated at 173 metres.[171]

The country has a coastline spanning 770 km (480 mi); extending from the shores of the Baltic Sea, along the Bay of Pomerania in the west to the Gulf of Gdańsk in the east.[171] The beach coastline is abundant in sand dune fields or coastal ridges and is indented by spits and lagoons, notably the Hel Peninsula and the Vistula Lagoon, which is shared with Russia.[174] The largest Polish island on the Baltic Sea is Wolin, located within Wolin National Park.[175] Poland also shares the Szczecin Lagoon and the Usedom island with Germany.[176]

The mountainous belt in the extreme south of Poland is divided into two major mountain ranges; the Sudetes in the west and the Carpathians in the east. The highest part of the Carpathian massif are the Tatra Mountains, extending along Poland's southern border.[177] Poland's highest point is Mount Rysy at 2,501 metres (8,205 ft) in elevation, located in the Tatras.[178] The highest summit of the Sudeten massif is Mount Śnieżka at 1,603.3 metres (5,260 ft), shared with the Czech Republic.[179] The lowest point in Poland is situated at Raczki Elbląskie in the Vistula Delta, which is 1.8 metres (5.9 ft) below sea level.[171]


Morskie Oko alpine lake in the Tatra Mountains. Poland has one of the highest densities of lakes in the world.
Poland's longest rivers are the Vistula, the Oder, the Warta, and the Bug.[171] The country also possesses one of the highest densities of lakes in the world, numbering around ten thousand and mostly concentrated in the north-eastern region of Masuria, within the Masurian Lake District.[180] The largest lakes, covering more than 100 square kilometres (39 sq mi), are Śniardwy and Mamry, and the deepest is Lake Hańcza at 108.5 metres (356 ft) in depth.[171]

Climate
Main article: Geography of Poland § Climate
The climate of Poland is temperate transitional, and varies from oceanic in the north-west to continental in the south-east.[181] The mountainous southern fringes are situated within an alpine climate.[181] Poland is characterised by warm summers, with a mean temperature of around 20 °C (68.0 °F) in July, and moderately cold winters averaging −1 °C (30.2 °F) in December.[182] The warmest and sunniest part of Poland is Lower Silesia in the southwest and the coldest region is the northeast corner, around Suwałki in Podlaskie province, where the climate is affected by cold fronts from Scandinavia and Siberia.[183] Precipitation is more frequent during the summer months, with highest rainfall recorded from June to September.[182]

There is a considerable fluctuation in day-to-day weather and the arrival of a particular season can differ each year.[181] Climate change and other factors have further contributed to interannual thermal anomalies and increased temperatures; the average annual air temperature between 2011 and 2020 was 9.33 °C (48.8 °F), around 1.11 °C higher than in the 2001–2010 period.[183] Winters are also becoming increasingly drier, with less sleet and snowfall.[181]

Biodiversity
Main article: Geography of Poland § Biodiversity

The wisent, one of Poland's national animals, is commonly found at the ancient and UNESCO-protected Białowieża Forest.
Phytogeographically, Poland belongs to the Central European province of the Circumboreal Region within the Boreal Kingdom. The country has four Palearctic ecoregions – Central, Northern, Western European temperate broadleaf and mixed forest, and the Carpathian montane conifer. Forests occupy 31% of Poland's land area, the largest of which is the Lower Silesian Wilderness.[184] The most common deciduous trees found across the country are oak, maple, and beech; the most common conifers are pine, spruce, and fir.[185] An estimated 69% of all forests are coniferous.[186]

The flora and fauna in Poland is that of Continental Europe, with the wisent, white stork and white-tailed eagle designated as national animals, and the red common poppy being the unofficial floral emblem.[187] Among the most protected species is the European bison, Europe's heaviest land animal, as well as the Eurasian beaver, the lynx, the gray wolf and the Tatra chamois.[171] The region was also home to the extinct aurochs, the last individual dying in Poland in 1627.[188] Game animals such as red deer, roe deer, and wild boar are found in most woodlands.[189] Poland is also a significant breeding ground for migratory birds and hosts around one quarter of the global population of white storks.[190]

Around 315,100 hectares (1,217 sq mi), equivalent to 1% of Poland's territory, is protected within 23 Polish national parks, two of which – Białowieża and Bieszczady – are UNESCO World Heritage Sites.[191] There are 123 areas designated as landscape parks, along with numerous nature reserves and other protected areas under the Natura 2000 network.[192]

Government and politics
Main article: Politics of Poland
Andrzej Sebastian Duda
Andrzej Duda
President
Mateusz Jakub Morawiecki
Mateusz Morawiecki
Prime Minister
Poland is a unitary parliamentary republic and a representative democracy, with a president as the head of state.[193] The executive power is exercised further by the Council of Ministers and the prime minister who acts as the head of government.[193] The council's individual members are selected by the prime minister, appointed by the president and approved by parliament.[193] The head of state is elected by popular vote for a five-year term.[194] The current president is Andrzej Duda and the prime minister is Mateusz Morawiecki.[195]

Poland's legislative assembly is a bicameral parliament consisting of a 460-member lower house (Sejm) and a 100-member upper house (Senate).[196] The Sejm is elected under proportional representation according to the d'Hondt method for vote-seat conversion.[197] The Senate is elected under the first-past-the-post electoral system, with one senator being returned from each of the one hundred constituencies.[198] The Senate has the right to amend or reject a statute passed by the Sejm, but the Sejm may override the Senate's decision with a majority vote.[199]


The Sejm is the lower house of the parliament of Poland.
With the exception of ethnic minority parties, only candidates of political parties receiving at least 5% of the total national vote can enter the Sejm.[198] Both the lower and upper houses of parliament in Poland are elected for a four-year term and each member of the Polish parliament is guaranteed parliamentary immunity.[200] Under current legislation, a person must be 21 years of age or over to assume the position of deputy, 30 or over to become senator and 35 to run in a presidential election.[200]

Members of the Sejm and Senate jointly form the National Assembly of the Republic of Poland.[201] The National Assembly, headed by the Sejm Marshal, is formed on three occasions – when a new president takes the oath of office; when an indictment against the president is brought to the State Tribunal; and in case a president's permanent incapacity to exercise his duties due to the state of his health is declared.[201]

Administrative divisions
Main article: Administrative divisions of Poland
Poland is divided into 16 provinces or states known as voivodeships.[202] As of 2022, the voivodeships are subdivided into 380 counties (powiats), which are further fragmented into 2,477 municipalities (gminas).[202] Major cities normally have the status of both gmina and powiat.[202] The provinces are largely founded on the borders of historic regions, or named for individual cities.[203] Administrative authority at the voivodeship level is shared between a government-appointed governor (voivode), an elected regional assembly (sejmik) and a voivodeship marshal, an executive elected by the assembly.[203]

Pomeranian Voivodeship
PomeranianWest Pomeranian Voivodeship
West
PomeranianWarmian-Masurian Voivodeship
Warmian-MasurianPodlaskie Voivodeship
PodlaskieMasovian Voivodeship
MasovianKuyavian-Pomeranian Voivodeship
Kuyavian-
PomeranianGreater Poland Voivodeship
Greater PolandLubusz Voivodeship
LubuszLower Silesian Voivodeship
Lower SilesianŁódź Voivodeship
ŁódźOpolskie Voivodeship
OpoleLublin Voivodeship
LublinLesser Poland Voivodeship
Lesser
PolandPodkarpackie Voivodeship
SubcarpathianŚwiętokrzyskie Voivodeship
Holy CrossSilesian Voivodeship
Silesian
Voivodeship	Capital city	Area	Population
in English	in Polish	km2[204]	2021[204]
Greater Poland	Wielkopolskie	Poznań	29,826	3,496,450
Kuyavian-Pomeranian	Kujawsko-Pomorskie	Bydgoszcz & Toruń	17,971	2,061,942
Lesser Poland	Małopolskie	Kraków	15,183	3,410,441
Łódź	Łódzkie	Łódź	18,219	2,437,970
Lower Silesian	Dolnośląskie	Wrocław	19,947	2,891,321
Lublin	Lubelskie	Lublin	25,123	2,095,258
Lubusz	Lubuskie	Gorzów Wielkopolski &
Zielona Góra	13,988	1,007,145
Masovian	Mazowieckie	Warsaw	35,559	5,425,028
Opole	Opolskie	Opole	9,412	976,774
Podlaskie	Podlaskie	Białystok	20,187	1,173,286
Pomeranian	Pomorskie	Gdańsk	18,323	2,346,671
Silesian	Śląskie	Katowice	12,333	4,492,330
Subcarpathian	Podkarpackie	Rzeszów	17,846	2,121,229
Holy Cross	Świętokrzyskie	Kielce	11,710	1,224,626
Warmian-Masurian	Warmińsko-Mazurskie	Olsztyn	24,173	1,416,495
West Pomeranian	Zachodniopomorskie	Szczecin	22,905	1,688,047
Law
Main article: Law of Poland

The Constitution of 3 May adopted in 1791 was the first modern constitution in Europe.
The Constitution of Poland is the enacted supreme law, and Polish judicature is based on the principle of civil rights, governed by the code of civil law.[205] The current democratic constitution was adopted by the National Assembly of Poland on 2 April 1997; it guarantees a multi-party state with freedoms of religion, speech and assembly, prohibits the practices of forced medical experimentation, torture or corporal punishment, and acknowledges the inviolability of the home, the right to form trade unions, and the right to strike.[206]

The judiciary in Poland is composed of the Supreme Court as the country's highest judicial organ, the Supreme Administrative Court for the judicial control of public administration, Common Courts (District, Regional, Appellate) and the Military Court.[207] The Constitutional and State Tribunals are separate judicial bodies, which rule the constitutional liability of people holding the highest offices of state and supervise the compliance of statutory law, thus protecting the Constitution.[208] Judges are nominated by the National Council of the Judiciary and are appointed for life by the president.[208] On the approval of the Senate, the Sejm appoints an ombudsman for a five-year term to guard the observance of social justice.[198]

Poland has a low homicide rate at 0.7 murders per 100,000 people, as of 2018.[209] Rape, assault and violent crime remain at a very low level.[210] The country has imposed strict regulations on abortion, which is permitted only in cases of rape, incest or when the woman's life is in danger; congenital disorder and stillbirth are not covered by the law, prompting some women to seek abortion abroad.[211]

Historically, the most significant Polish legal act is the Constitution of 3 May 1791. Instituted to redress long-standing political defects of the federative Polish–Lithuanian Commonwealth and its Golden Liberty, it was the first modern constitution in Europe and influenced many later democratic movements across the globe.[212][213][214] In 1918, the Second Polish Republic became one of the first countries to introduce universal women's suffrage.[215]

Foreign relations
Main articles: Foreign relations of Poland and List of diplomatic missions of Poland

The Ministry of Foreign Affairs, located in Warsaw
Poland is a middle power and is transitioning into a regional power in Europe.[216][217] It has a total of 52 representatives in the European Parliament as of 2022.[218] Warsaw serves as the headquarters for Frontex, the European Union's agency for external border security as well as ODIHR, one of the principal institutions of the OSCE.[219][220] Apart from the European Union, Poland has been a member of NATO, the United Nations, and the WTO.

In recent years, Poland significantly strengthened its relations with the United States, thus becoming one of its closest allies and strategic partners in Europe.[221] Historically, Poland maintained strong cultural and political ties to Hungary; this special relationship was recognised by the parliaments of both countries in 2007 with the joint declaration of 23 March as "The Day of Polish-Hungarian Friendship".[222]

Military
Main article: Polish Armed Forces

Polish Air Force F-16s, a single-engine multirole fighter aircraft
The Polish Armed Forces are composed of five branches – the Land Forces, the Navy, the Air Force, the Special Forces and the Territorial Defence Force.[223] The military is subordinate to the Ministry of National Defence of the Republic of Poland.[223] However, its commander-in-chief in peacetime is the president, who nominates officers, the Minister for National Defence and the chief of staff.[223] Polish military tradition is generally commemorated by the Armed Forces Day, celebrated annually on 15 August.[224] As of 2022, the Polish Armed Forces have a combined strength of 114,050 active soldiers, with a further 75,400 active in the gendarmerie and defence force.[225]

Poland is spending 2% of its GDP on defence, equivalent to approximately US$14.5 billion in 2022, with a slated increase to US$29 billion in 2023.[226][227] From 2022, Poland is set to spend 110 billion euros on the modernisation of its armed forces, in close cooperation with American, South Korean and local Polish defence manufacturers.[228] Also, the Polish military is set to increase its size to 250,000 enlisted and officers, and 50,000 defence force personnel.[229] According to SIPRI, the country exported €487 million worth of arms and armaments to foreign countries in 2020.[230]

Compulsory military service for men, who previously had to serve for nine months, was discontinued in 2008.[231] Polish military doctrine reflects the same defensive nature as that of its NATO partners and the country actively hosts NATO's military exercises.[225] Since 1953, the country has been a large contributor to various United Nations peacekeeping missions,[232] and currently maintains military presence in the Middle East, Africa, the Baltic states and southeastern Europe.[225]

Law enforcement and emergency services
Main articles: Law enforcement in Poland, Emergency medical services in Poland, and State Fire Service

A Mercedes-Benz Sprinter patrol van belonging to the Polish State Police Service (Policja)
Law enforcement in Poland is performed by several agencies which are subordinate to the Ministry of Interior and Administration – the State Police (Policja), assigned to investigate crimes or transgression; the Municipal City Guard, which maintains public order; and several specialised agencies, such as the Polish Border Guard.[233] Private security firms are also common, although they possess no legal authority to arrest or detain a suspect.[233][234] Municipal guards are primarily headed by provincial, regional or city councils; individual guards are not permitted to carry firearms unless instructed by the superior commanding officer.[235] Security service personnel conduct regular patrols in both large urban areas or smaller suburban localities.[236]

The Internal Security Agency (ABW, or ISA in English) is the chief counter-intelligence instrument safeguarding Poland's internal security, along with Agencja Wywiadu (AW) which identifies threats and collects secret information abroad.[237] The Central Investigation Bureau of Police (CBŚP) and the Central Anticorruption Bureau (CBA) are responsible for countering organised crime and corruption in state and private institutions.[238][239]

Emergency services in Poland consist of the emergency medical services, search and rescue units of the Polish Armed Forces and State Fire Service. Emergency medical services in Poland are operated by local and regional governments,[240] but are a part of the centralised national agency - the National Medical Emergency Service (Państwowe Ratownictwo Medyczne).[241]

Economy
Main article: Economy of Poland
Panorama siekierkowski.jpg
Economic indicators
GDP (PPP)	$1.599 trillion (2022)	[8]
Nominal GDP	$716 billion (2022)	[8]
Real GDP growth	4.5% (2019)	[242]
CPI inflation	2.2% (2019)	[243]
Employment-to-population ratio	55% (2019)	[244]
Unemployment	2.9% (2021)	[245]
Total public debt	$274 billion (2019)	[246]
As of 2023, Poland's economy and gross domestic product (GDP) is the sixth largest in the European Union by nominal standards and the fifth largest by purchasing power parity. It is also one of the fastest growing within the Union and reached a developed market status in 2018.[247] The unemployment rate published by Eurostat in 2021 amounted to 2.9%, which was the second-lowest in the EU.[245] Around 61% of the employed population works in the service sector, 31% in manufacturing, and 8% in the agricultural sector.[248] Although Poland is a member of EU's single market, the country has not adopted the Euro as legal tender and maintains its own currency – the Polish złoty (zł, PLN).

Poland is the regional economic leader in Central Europe, with nearly 40 per cent of the 500 biggest companies in the region (by revenues) as well as a high globalisation rate.[249] The country's largest firms compose the WIG20 and WIG30 indexes, which is traded on the Warsaw Stock Exchange. According to reports made by the National Bank of Poland, the value of Polish foreign direct investments reached almost 300 billion PLN at the end of 2014. The Central Statistical Office estimated that in 2014 there were 1,437 Polish corporations with interests in 3,194 foreign entities.[250]

Poland has the largest banking sector in Central Europe,[251] with 32.3 branches per 100,000 adults.[252] It was the only European economy to have avoided the recession of 2008.[253] The country is the 20th largest exporter of goods and services in the world.[254] Exports of goods and services are valued at approximately 56% of GDP, as of 2020.[255] In 2019, Poland passed a law that would exempt workers under the age of 26 from income tax.[256]

Tourism
Main articles: Tourism in Poland, List of World Heritage Sites of Poland, List of Historic Monuments (Poland), Seven Wonders of Poland, and Crown of Polish Mountains

The Old City of Zamość is a UNESCO World Heritage Site.
Poland experienced a significant increase in the number of tourists after joining the European Union in 2004.[257][258] With nearly 21 million international arrivals in 2019, tourism contributes considerably to the overall economy and makes up a relatively large proportion of the country's service market.[259]

Tourist attractions in Poland vary, from the mountains in the south to the sandy beaches in the north, with a trail of nearly every architectural style. The most visited city is Kraków, which was the former capital of Poland and serves as a relic of the Polish Golden Age and the Renaissance. Kraków also held royal coronations of most Polish kings and monarchs at Wawel, the nation's chief historical landmark. Among other notable sites in the country is Wrocław, one of the oldest cities in Poland which was a model for the founding of Kraków. Wrocław is famous for its dwarf statues, a large market square with two town halls, and the oldest Zoological Gardens with one of the world's largest number of animal species. The Polish capital Warsaw and its historical Old Town were entirely reconstructed after wartime destruction. Other cities attracting countless tourists include Gdańsk, Poznań, Lublin, Toruń as well as the site of the German Auschwitz concentration camp in Oświęcim. A notable highlight is the 13th-century Wieliczka Salt Mine with its labyrinthine tunnels, a subterranean lake and chapels carved by miners out of rock salt beneath the ground.[citation needed]

Other tourist destinations include the Baltic Sea coast in the north; the Masurian Lake District and Białowieża Forest in the east; on the south Karkonosze, the Table Mountains and the Tatra Mountains, where Rysy – the highest peak of Poland, and Eagle's Path mountain trail are located. The Pieniny and Bieszczady Mountains lie in the extreme south-east.[260] There are over 100 castles in the country, most in the Lower Silesian Voivodeship, and also on the Trail of the Eagles' Nests.[261] The largest castle in the world by land area is situated in Malbork, in north-central Poland.[262]

Transport and energy
Main articles: Transport in Poland and Energy in Poland

PKP Intercity Pendolino at the Wrocław railway station
Transport in Poland is provided by means of rail, road, marine shipping and air travel. The country is part of EU's Schengen Area and is an important transport hub along neighbouring Germany due to its strategic position in Central Europe.[263] Some of the longest European routes, including the E40, run through Poland.

The country has a good network of highways, composed of express roads and motorways. At the start of 2022, Poland had 4,623.3 km (2,872.8 mi) of highways in use.[264] In addition, all local and regional roads are monitored by the National Road Rebuilding Programme, which aims to improve the quality of travel in the countryside and suburban localities.[265]

In 2017, the nation had 18,513 kilometres (11,503 mi) of railway track, the third longest in European Union, after Germany and France.[266][better source needed] The Polish State Railways (PKP) is the dominant railway operator in the country. Poland has a number of international airports, the largest of which is Warsaw Chopin Airport, the primary global hub for LOT Polish Airlines.

Seaports exist all along Poland's Baltic coast, with most freight operations using Świnoujście, Police, Szczecin, Kołobrzeg, Gdynia, Gdańsk and Elbląg as their base. The Port of Gdańsk is the only port in the Baltic Sea adapted to receive oceanic vessels.

The electricity generation sector in Poland is largely fossil-fuel–based. Coal production in Poland is a major source of jobs and the largest source of the nation's greenhouse gas emissions.[267] Many power plants nationwide use Poland's position as a major European exporter of coal to their advantage by continuing to use coal as the primary raw material in the production of their energy. The three largest Polish coal mining firms (Węglokoks, Kompania Węglowa and JSW) extract around 100 million tonnes of coal annually.[268] After coal, Polish energy supply relies significantly on oil—the nation is the third-largest buyer of Russian oil exports to the EU.[269]

The new Energy Policy of Poland until 2040 (EPP2040) would reduce the share of coal and lignite in electricity generation by 25% from 2017 to 2030. The plan involves deploying new nuclear plants, increasing energy efficiency, and decarbonising the Polish transport system in order to reduce greenhouse gas emissions and prioritise long-term energy security.[267][270]

Science and technology
Main articles: Polish science and technology and Polish people § Science and technology

Physicist and chemist Maria Skłodowska-Curie was the first person to win two Nobel Prizes.[271]
Over the course of history, the Polish people have made considerable contributions in the fields of science, technology and mathematics.[272] Perhaps the most renowned Pole to support this theory was Nicolaus Copernicus (Mikołaj Kopernik), who triggered the Copernican Revolution by placing the Sun rather than the Earth at the center of the universe.[273] He also derived a quantity theory of money, which made him a pioneer of economics. Copernicus' achievements and discoveries are considered the basis of Polish culture and cultural identity.[274] Poland was ranked 40th in the Global Innovation Index in 2021, down from 39th in 2019.[275]


Nicolaus Copernicus, the 16th century Polish astronomer who formulated the heliocentric model of the solar system.
Poland's tertiary education institutions; traditional universities, as well as technical, medical, and economic institutions, employ around tens of thousands of researchers and staff members. There are hundreds of research and development institutes.[276] However, in the 19th and 20th centuries many Polish scientists worked abroad; one of the most important of these exiles was Maria Skłodowska-Curie, a physicist and chemist who lived much of her life in France. In 1925, she established Poland's Radium Institute.[271]

In the first half of the 20th century, Poland was a flourishing centre of mathematics. Outstanding Polish mathematicians formed the Lwów School of Mathematics (with Stefan Banach, Stanisław Mazur, Hugo Steinhaus, Stanisław Ulam) and Warsaw School of Mathematics (with Alfred Tarski, Kazimierz Kuratowski, Wacław Sierpiński and Antoni Zygmund). Numerous mathematicians, scientists, chemists or economists emigrated due to historic vicissitudes, among them Benoit Mandelbrot, Leonid Hurwicz, Alfred Tarski, Joseph Rotblat and Nobel Prize laureates Roald Hoffmann, Georges Charpak and Tadeusz Reichstein.

Demographics
Main articles: Demographics of Poland, List of cities and towns in Poland, Metropolitan areas in Poland, Polish people, and Polish diaspora
Poland has a population of approximately 38.2 million as of 2021, and is the ninth-most populous country in Europe, as well as the fifth-most populous member state of the European Union.[277] It has a population density of 122 inhabitants per square kilometre (320 inhabitants/sq mi).[278] The total fertility rate was estimated at 1.42 children born to a woman in 2019, which is among the world's lowest.[279] Furthermore, Poland's population is aging significantly, and the country has a median age of roughly 42.[280]


Population of Poland from 1900 to 2010 in millions of inhabitants
Around 60% of the country's population lives in urban areas or major cities and 40% in rural zones.[281] In 2020, 50.2% of Poles resided in detached dwellings and 44.3% in apartments.[282] The most populous administrative province or state is the Masovian Voivodeship and the most populous city is the capital, Warsaw, at 1.8 million inhabitants with a further 2–3 million people living in its metropolitan area.[283][284][285] The metropolitan area of Katowice is the largest urban conurbation with a population between 2.7 million[286] and 5.3 million residents.[287] Population density is higher in the south of Poland and mostly concentrated between the cities of Wrocław and Kraków.[288]

In the 2011 Polish census, 37,310,341 people reported Polish identity, 846,719 Silesian, 232,547 Kashubian and 147,814 German. Other identities were reported by 163,363 people (0.41%) and 521,470 people (1.35%) did not specify any nationality.[2] Official population statistics do not include migrant workers who do not possess a permanent residency permit or Karta Polaka.[289] More than 1.7 million Ukrainian citizens worked legally in Poland in 2017.[290] The number of migrants is rising steadily; the country approved 504,172 work permits for foreigners in 2021 alone.[291]
  
Largest cities or towns in Poland
Statistics Poland (GUS) 2021[292] and GUS BDL 2021[293]
Rank	Name	Voivodeship	Pop.	Rank	Name	Voivodeship	Pop.	
Warsaw
Warsaw
Kraków
Kraków	1	Warsaw	Masovian	1,860,281	11	Katowice	Silesian	285,711	Wrocław
Wrocław
Łódź
Łódź
2	Kraków	Lesser Poland	800,653	12	Gdynia	Pomeranian	245,222
3	Wrocław	Lower Silesian	672,929	13	Częstochowa	Silesian	213,107
4	Łódź	Łódź	670,642	14	Radom	Masovian	201,601
5	Poznań	Greater Poland	546,859	15	Toruń	Kuyavian-Pomeranian	198,273
6	Gdańsk	Pomeranian	486,022	16	Rzeszów	Subcarpathian	195,871
7	Szczecin	West Pomeranian	396,168	17	Sosnowiec	Silesian	193,660
8	Bydgoszcz	Kuyavian-Pomeranian	337,666	18	Kielce	Świętokrzyskie	186,894
9	Lublin	Lublin	334,681	19	Gliwice	Silesian	174,016
10	Białystok	Podlaskie	294,242	20	Olsztyn	Warmian-Masurian	170,225
Languages
Main articles: Polish language, Languages of Poland, and Bilingual communes in Poland

Dolina Jadwigi — a bilingual Polish-Kashubian road sign with the village name
Polish is the official and predominant spoken language in Poland, and is one of the official languages of the European Union.[294] It is also a second language in parts of neighbouring Lithuania, where it is taught in Polish-minority schools.[295][296] Contemporary Poland is a linguistically homogeneous nation, with 97% of respondents declaring Polish as their mother tongue.[297] There are currently 15 minority languages in Poland,[298] including one recognised regional language, Kashubian, which is spoken by approximately 100,000 people on a daily basis in the northern regions of Kashubia and Pomerania.[299] Poland also recognises secondary administrative languages or auxiliary languages in bilingual municipalities, where bilingual signs and placenames are commonplace.[300] According to the Centre for Public Opinion Research, around 32% of Polish citizens declared knowledge of the English language in 2015.[301]

Religion
Main article: Religion in Poland

John Paul II, born Karol Wojtyła, held the papacy between 1978–2005 and was the first Pole to become a Roman Catholic Pope.
According to the 2011 census, 87.6% of all Polish citizens adhere to the Roman Catholic Church, with 2.4% identifying as having no religion.[3] Poland is one of the most religious countries in Europe, where Roman Catholicism remains a criterion of national identity and Polish-born Pope John Paul II is widely revered.[302] In 2015, 61.6% of respondents outlined that religion is of high or very high importance.[303] Important pilgrimages to the Jasna Góra Monastery, a shrine dedicated to the Black Madonna, take place annually.[304] However, church attendance has decreased in recent years; only 38% of worshippers attended mass regularly on Sunday in 2018.[305]

Freedom of religion in Poland is guaranteed by the Constitution, and the concordat guarantees the teaching of religion in public schools.[306] Historically, the Polish state maintained a high degree of religious tolerance and provided asylum for refugees fleeing religious persecutions in other parts of Europe.[307] Poland also hosted Europe's largest Jewish diaspora and the country was a centre of Ashkenazi Jewish culture and traditional learning until the Holocaust.[308]

Contemporary religious minorities comprise Orthodox Christians, Protestants — including Lutherans of the Evangelical-Augsburg Church, Pentecostals in the Pentecostal Church in Poland, Adventists in the Seventh-day Adventist Church and other smaller Evangelical denominations — Jehovah's Witnesses, Eastern Catholics, Mariavites, Jews, Muslims (Tatars) and neopagans, some of whom are members of the Native Polish Church.[309]

Health
Main article: Health in Poland
Medical service providers and hospitals (szpitale) in Poland are subordinate to the Ministry of Health; it provides administrative oversight and scrutiny of general medical practice, and is obliged to maintain a high standard of hygiene and patient care. Poland has a universal healthcare system based on an all-inclusive insurance system; state subsidised healthcare is available to all citizens covered by the general health insurance program of the National Health Fund (NFZ). Private medical complexes exist nationwide; over 50% of the population uses both public and private sectors.[310][311][312]

According to the Human Development Report from 2020, the average life expectancy at birth is 79 years (around 75 years for an infant male and 83 years for an infant female);[313] the country has a low infant mortality rate (4 per 1,000 births).[314] In 2019, the principal cause of death was ischemic heart disease; diseases of the circulatory system accounted for 45% of all deaths.[315][316] In the same year, Poland was also the 15th-largest importer of medications and pharmaceutical products.[317]

Education
Main articles: Education in Poland and Universities in Poland

Jagiellonian University in Kraków
The Jagiellonian University founded in 1364 by Casimir III in Kraków was the first institution of higher learning established in Poland, and is one of the oldest universities still in continuous operation.[318] Poland's Commission of National Education (Komisja Edukacji Narodowej), established in 1773, was the world's first state ministry of education.[319][320]

The framework for primary, secondary and higher tertiary education are established by the Ministry of Education and Science. Kindergarten attendance is optional for children aged between three and five, with one year being compulsory for six-year-olds.[321][322] Primary education traditionally begins at the age of seven, although children aged six can attend at the request of their parents or guardians.[322] Elementary school spans eight grades and secondary schooling is dependent on student preference – a four-year high school (liceum), a five-year technical school (technikum) or various vocational studies (szkoła branżowa) can be pursued by each individual pupil.[322] A liceum or technikum is concluded with a maturity exit exam (matura), which must be passed in order to apply for a university or other institutions of higher learning.[323]

In Poland, there are over 500 university-level institutions,[324] with technical, medical, economic, agricultural, pedagogical, theological, musical, maritime and military faculties.[325] The University of Warsaw and Warsaw Polytechnic, the University of Wrocław, Adam Mickiewicz University in Poznań and the University of Technology in Gdańsk are among the most prominent.[326] There are three conventional academic degrees in Poland – licencjat or inżynier (first cycle qualification), magister (second cycle qualification) and doktor (third cycle qualification).[327] In 2018, the Programme for International Student Assessment, coordinated by the Organisation for Economic Co-operation and Development, ranked Poland's educational system higher than the OECD average; the study showed that students in Poland perform better academically than in most OECD countries.[328]

Culture
Main article: Culture of Poland

The Polish White Eagle is Poland's enduring national and cultural symbol
The culture of Poland is closely connected with its intricate 1,000-year history, and forms an important constituent in the Western civilisation.[329] The Poles take great pride in their national identity which is often associated with the colours white and red, and exuded by the expression biało-czerwoni ("whitereds").[330] National symbols, chiefly the crowned white-tailed eagle, are often visible on clothing, insignia and emblems.[331] The architectural monuments of great importance are protected by the National Heritage Board of Poland.[332] Over 100 of the country's most significant tangible wonders were enlisted onto the Historic Monuments Register,[333] with further 17 being recognised by UNESCO as World Heritage Sites.[334]

Holidays and traditions
See also: Christmas in Poland

All Saints' Day on 1 November is one of the most important public holidays in Poland.
There are 13 government-approved annual public holidays – New Year on 1 January, Three Kings' Day on 6 January, Easter Sunday and Easter Monday, Labour Day on 1 May, Constitution Day on 3 May, Pentecost, Corpus Christi, Feast of the Assumption on 15 August, All Saints' Day on 1 November, Independence Day on 11 November and Christmastide on 25 and 26 December.[335]

Particular traditions and superstitious customs observed in Poland are not found elsewhere in Europe. Though Christmas Eve (Wigilia) is not a public holiday, it remains the most memorable day of the entire year. Trees are decorated on 24 December, hay is placed under the tablecloth to resemble Jesus' manger, Christmas wafers (opłatek) are shared between gathered guests and a twelve-dish meatless supper is served that same evening when the first star appears.[336] An empty plate and seat are symbolically left at the table for an unexpected guest.[337] On occasion, carolers journey around smaller towns with a folk Turoń creature until the Lent period.[338]

A widely-popular doughnut and sweet pastry feast occurs on Fat Thursday, usually 52 days prior to Easter.[339] Eggs for Holy Sunday are painted and placed in decorated baskets that are previously blessed by clergymen in churches on Easter Saturday. Easter Monday is celebrated with pagan dyngus festivities, where the youth is engaged in water fights.[340][339] Cemeteries and graves of the deceased are annually visited by family members on All Saints' Day; tombstones are cleaned as a sign of respect and candles are lit to honour the dead on an unprecedented scale.[341]

Music
Main article: Music of Poland
Fryderyk Chopin
Fryderyk Chopin was a renowned classical composer and virtuoso pianist.
Artur Rubinstein
Artur Rubinstein was one of the greatest concert pianists of the 20th century.
Artists from Poland, including famous musicians such as Frédéric Chopin, Artur Rubinstein, Ignacy Jan Paderewski, Krzysztof Penderecki, Henryk Wieniawski, Karol Szymanowski, and traditional, regionalised folk composers create a lively and diverse music scene, which even recognises its own music genres, such as sung poetry and disco polo.[342]

The origins of Polish music can be traced to the 13th century; manuscripts have been found in Stary Sącz containing polyphonic compositions related to the Parisian Notre Dame School. Other early compositions, such as the melody of Bogurodzica and God Is Born (a coronation polonaise tune for Polish kings by an unknown composer), may also date back to this period, however, the first known notable composer, Nicholas of Radom, lived in the 15th century. Diomedes Cato, a native-born Italian who lived in Kraków, became a renowned lutenist at the court of Sigismund III; he not only imported some of the musical styles from southern Europe but blended them with native folk music.[343]

In the 17th and 18th centuries, Polish baroque composers wrote liturgical music and secular compositions such as concertos and sonatas for voices or instruments. At the end of the 18th century, Polish classical music evolved into national forms like the polonaise. Wojciech Bogusławski is accredited with composing the first Polish national opera, titled Krakowiacy i Górale, which premiered in 1794.[344]


Fryderyk Chopin
Mazurka no. 4 in a minor, op. 17
5:35
Mazurka (Polish: mazurek), stylised folk dance in triple meter (1832), commemorating the November Uprising
Poland today has an active music scene, with the jazz and metal genres being particularly popular among the contemporary populace. Polish jazz musicians such as Krzysztof Komeda created a unique style, which was most famous in the 1960s and 1970s and continues to be popular to this day. Poland has also become a major venue for large-scale music festivals, chief among which are the Open'er Festival, Opole Festival and Sopot Festival.[345]

Art
Main articles: Art in Poland and Young Poland
Further information: List of Polish artists
Jan Matejko
Jan Matejko, leading Polish history painter whose works depict Poland's heritage and key historical events.
Lady with an Ermine
Lady with an Ermine (1490) by Leonardo da Vinci is displayed in the Czartoryski Museum in Kraków.
Art in Poland has invariably reflected European trends, with Polish painting pivoted on folklore, Catholic themes, historicism and realism, but also on impressionism and romanticism. An important art movement was Young Poland, developed in the late 19th century for promoting decadence, symbolism and art nouveau. Since the 20th century Polish documentary art and photography has enjoyed worldwide fame, especially the Polish School of Posters.[346] One of the most distinguished paintings in Poland is Lady with an Ermine (1490) by Leonardo da Vinci.[347]

Internationally renowned Polish artists include Jan Matejko (historicism), Jacek Malczewski (symbolism), Stanisław Wyspiański (art nouveau), Henryk Siemiradzki (Roman academic art), Tamara de Lempicka (art deco), and Zdzisław Beksiński (dystopian surrealism).[348] Several Polish artists and sculptors were also acclaimed representatives of avant-garde, constructivist, minimalist and contemporary art movements, including Katarzyna Kobro, Władysław Strzemiński, Magdalena Abakanowicz, Alina Szapocznikow, Igor Mitoraj and Wilhelm Sasnal.

Notable art academies in Poland include the Kraków Academy of Fine Arts, Academy of Fine Arts in Warsaw, Art Academy of Szczecin, University of Fine Arts in Poznań and the Geppert Academy of Fine Arts in Wrocław. Contemporary works are exhibited at Zachęta, Ujazdów, and MOCAK art galleries.[349]

Architecture
Main article: Architecture of Poland
Saint Mary's Church in Kraków
St. Mary's Basilica on the Main Market Square in Kraków is an example of Brick Gothic architecture.
Poznań City Hall
The 16th-century City Hall of Poznań illustrates the Renaissance style.
The architecture of Poland reflects European architectural styles, with strong historical influences derived from Italy, Germany, and the Low Countries.[350] Settlements founded on Magdeburg Law evolved around central marketplaces (plac, rynek), encircled by a grid or concentric network of streets forming an old town (stare miasto).[351] Poland's traditional landscape is characterised by ornate churches, city tenements and town halls.[352] Cloth hall markets (sukiennice) were once an abundant feature of Polish urban architecture.[353] The mountainous south is known for its Zakopane chalet style, which originated in Poland.[354]

The earliest architectonic trend was Romanesque (c. 11th century), but its traces in the form of circular rotundas are scarce.[355] The arrival of brick Gothic (c. 13th century) defined Poland's most distinguishable medieval style, exuded by the castles of Malbork, Lidzbark, Gniew and Kwidzyn as well as the cathedrals of Gniezno, Gdańsk, Wrocław, Frombork and Kraków.[356] The Renaissance (16th century) gave rise to Italianate courtyards, defensive palazzos and mausoleums.[357] Decorative attics with pinnacles and arcade loggias are elements of Polish Mannerism, found in Poznań, Lublin and Zamość.[358][359] Foreign artisans often came at the expense of kings or nobles, whose palaces were built thereafter in the Baroque, Neoclassical and Revivalist styles (17th–19th century).[360]

Primary building materials comprising timber or red brick were extensively utilised in Polish folk architecture,[361] and the concept of a fortified church was commonplace.[362] Secular structures such as dworek manor houses, farmsteads, granaries, mills and country inns are still present in some regions or in open air museums (skansen).[363] However, traditional construction methods faded in the early-mid 20th century due to urbanisation and the construction of functionalist housing estates and residential areas.[364]

Literature
Main articles: Polish literature and History of philosophy in Poland
Adam Mickiewicz
Adam Mickiewicz, whose national epic poem Pan Tadeusz (1834) is considered a masterpiece of Polish literature.
Joseph Conrad-Korzeniowski
Joseph Conrad, author of popular books such as Heart of Darkness (1899) and Nostromo (1904).
The literary works of Poland have traditionally concentrated around the themes of patriotism, spirituality, social allegories and moral narratives.[365] The earliest examples of Polish literature, written in Latin, date to the 12th century.[366] The first Polish phrase Day ut ia pobrusa, a ti poziwai (officially translated as "Let me, I shall grind, and you take a rest") was documented in the Book of Henryków and reflected the use of a quern-stone.[367] It has been since included in UNESCO's Memory of World Register.[368] The oldest extant manuscripts of fine prose in Old Polish are the Holy Cross Sermons and the Bible of Queen Sophia,[369] and Calendarium cracoviense (1474) is Poland's oldest surviving print.[370]

The poets Jan Kochanowski and Nicholas Rey became the first Renaissance authors to write in Polish.[371] Prime literarians of the period included Dantiscus, Modrevius, Goslicius, Sarbievius and theologian John Laski. In the Baroque era, Jesuit philosophy and local culture greatly influenced the literary techniques of Jan Andrzej Morsztyn (Marinism) and Jan Chryzostom Pasek (sarmatian memoirs).[372] During the Enlightenment, playwright Ignacy Krasicki composed the first Polish-language novel.[373] Poland's leading 19th-century romantic poets were the Three Bards – Juliusz Słowacki, Zygmunt Krasiński and Adam Mickiewicz, whose epic poem Pan Tadeusz (1834) is a national classic.[374] In the 20th century, the English impressionist and early modernist writings of Joseph Conrad made him one of the most eminent novelists of all time.[375][376]

Contemporary Polish literature is versatile, with its fantasy genre having been particularly praised.[377] The philosophical sci-fi novel Solaris by Stanisław Lem and The Witcher series by Andrzej Sapkowski are celebrated works of world fiction.[378] Poland has six Nobel-Prize winning authors – Henryk Sienkiewicz (Quo Vadis; 1905), Władysław Reymont (The Peasants; 1924), Isaac Bashevis Singer (1978), Czesław Miłosz (1980), Wisława Szymborska (1996), and Olga Tokarczuk (2018).[379][380][381]

Cuisine
Main article: Polish cuisine

Selection of hearty traditional comfort food from Poland, including bigos, gołąbki, żurek, pierogi, placki ziemniaczane, and rye bread.
The cuisine of Poland is eclectic and shares similarities with other regional cuisines. Among the staple or regional dishes are pierogi (filled dumplings), kielbasa (sausage), bigos (hunter's stew), kotlet schabowy (breaded cutlet), gołąbki (cabbage rolls), barszcz (borscht), żurek (soured rye soup), oscypek (smoked cheese), and tomato soup.[382][383] Bagels, a type of bread roll, also originated in Poland.[384]

Traditional dishes are hearty and abundant in pork, potatoes, eggs, cream, mushrooms, regional herbs, and sauce.[385] Polish food is characteristic for its various kinds of kluski (soft dumplings), soups, cereals and a variety of breads and open sandwiches. Salads, including mizeria (cucumber salad), coleslaw, sauerkraut, carrot and seared beets, are common. Meals conclude with a dessert such as sernik (cheesecake), makowiec (poppy seed roll), or napoleonka cream pie.[386]

Traditional alcoholic beverages include honey mead, widespread since the 13th century, beer, wine and vodka.[387] The world's first written mention of vodka originates from Poland.[388] The most popular alcoholic drinks at present are beer and wine which took over from vodka more popular in the years 1980–1998.[389] Grodziskie, sometimes referred to as "Polish Champagne", is an example of a historical beer style from Poland.[390] Tea remains common in Polish society since the 19th century, whilst coffee is drunk widely since the 18th century.[391]

Fashion and design
Further information: Category:Polish fashion

Traditional polonaise dresses, 1780–1785.
Several Polish designers and stylists left a legacy of beauty inventions and cosmetics; including Helena Rubinstein and Maksymilian Faktorowicz, who created a line of cosmetics company in California known as Max Factor and formulated the term "make-up" which is now widely used as an alternative for describing cosmetics.[392] Faktorowicz is also credited with inventing modern eyelash extensions.[393][394] As of 2020, Poland possesses the fifth-largest cosmetic market in Europe.[395] Inglot Cosmetics is the country's largest beauty products manufacturer,[396] and the retail store Reserved is the country's most successful clothing store chain.[397]

Historically, fashion has been an important aspect of Poland's national consciousness or cultural manifestation, and the country developed its own style known as Sarmatism at the turn of the 17th century.[398] The national dress and etiquette of Poland also reached the court at Versailles, where French dresses inspired by Polish garments included robe à la polonaise and the witzchoura. The scope of influence also entailed furniture; rococo Polish beds with canopies became fashionable in French châteaus.[399] Sarmatism eventually faded in the wake of the 18th century.[398]

Cinema
Main article: Cinema of Poland

Andrzej Wajda, the recipient of an Honorary Oscar, the Palme d'Or, as well as Honorary Golden Lion and Golden Bear awards.
The cinema of Poland traces its origins to 1894, when inventor Kazimierz Prószyński patented the Pleograph and subsequently the Aeroscope, the first successful hand-held operated film camera.[400][401] In 1897, Jan Szczepanik constructed the Telectroscope, a prototype of television transmitting images and sounds.[400] They are both recognised as pioneers of cinematography.[400] Poland has also produced influential directors, film producers and actors, many of whom were active in Hollywood, chiefly Roman Polański, Andrzej Wajda, Pola Negri, Samuel Goldwyn, the Warner brothers, Max Fleischer, Agnieszka Holland, Krzysztof Zanussi and Krzysztof Kieślowski.[402]

The themes commonly explored in Polish cinema include history, drama, war, culture and black realism (film noir).[400][401] In the 21st-century, two Polish productions won the Academy Awards – The Pianist (2002) by Roman Polański and Ida (2013) by Paweł Pawlikowski.[401]

Media
Main articles: Television in Poland and Media of Poland
Further information: Category:Video gaming in Poland

Headquarters of the publicly funded national television network TVP in Warsaw
According to the Eurobarometer Report (2015), 78 percent of Poles watch the television daily.[403] In 2020, 79 percent of the population read the news more than once a day, placing it second behind Sweden.[404] Poland has a number of major domestic media outlets, chiefly the public broadcasting corporation TVP, free-to-air channels TVN and Polsat as well as 24-hour news channels TVP Info, TVN 24 and Polsat News.[405] Public television extends its operations to genre-specific programmes such as TVP Sport, TVP Historia, TVP Kultura, TVP Rozrywka, TVP Seriale and TVP Polonia, the latter a state-run channel dedicated to the transmission of Polish-language telecasts for the Polish diaspora. In 2020, the most popular types of newspapers were tabloids and socio-political news dailies.[403]

Poland is a major European hub for video game developers and among the most successful companies are CD Projekt, Techland, The Farm 51, CI Games and People Can Fly.[406] Some of the popular video games developed in Poland include The Witcher trilogy and Cyberpunk 2077.[406] The Polish city of Katowice also hosts Intel Extreme Masters, one of the biggest esports events in the world.[406]

Sports
Main article: Sport in Poland

The Stadion Narodowy in Warsaw, home of the national football team
Motorcycle Speedway, volleyball and association football are among the country's most popular sports, with a rich history of international competitions.[407][408] Track and field, basketball, handball, boxing, MMA, ski jumping, cross-country skiing, ice hockey, tennis, fencing, swimming, and weightlifting are other popular sports. The golden era of football in Poland occurred throughout the 1970s and went on until the early 1980s when the Polish national football team achieved their best results in any FIFA World Cup competitions finishing third place in the 1974 and the 1982 tournaments. The team won a gold medal in football at the 1972 Summer Olympics and two silver medals, in 1976 and in 1992. In 2012, Poland co-hosted the UEFA European Football Championship.[409]

As of January 2023, the Polish men's national volleyball team is ranked as first in the world.[410] The team won a gold medal at the 1976 Summer Olympics and the gold medal at the FIVB World Championship 1974, 2014 and 2018.[411][412] Mariusz Pudzianowski is a highly successful strongman competitor and has won more World's Strongest Man titles than any other competitor in the world, winning the event in 2008 for the fifth time.[413]

Poland has made a distinctive mark in motorcycle speedway racing. The top Ekstraliga division has one of the highest average attendances for any sport in Poland. The national speedway team of Poland is one of the major teams in international speedway. Individually, Poland has three Speedway Grand Prix World Champions, with the most successful being three-time World Champion Bartosz Zmarzlik who won back-to-back championships in 2019 and 2020, and his third in 2022. In 2021, Poland finished runners-up in the Speedway of Nations world championship final, held in Manchester, UK in 2021.[414]

In the 21st century, the country has seen a growth of popularity of tennis and produced a number of successful tennis players including World No. 1 Iga Świątek, winner of four Grand Slam singles titles; former World No. 2 Agnieszka Radwanska, winner of 20 WTA career singles titles including 2015 WTA Finals; Top 10 ATP player Hubert Hurkacz; and former World No. 1 doubles player Łukasz Kubot whose career highlights include winning two Grand Slam doubles titles – 2014 Australian Open and 2017 Wimbledon Championships. Poland also won the 2015 Hopman Cup with Agnieszka Radwańska and Jerzy Janowicz representing the country.[415][416]

Poles made significant achievements in mountaineering, in particular, in the Himalayas and the winter ascending of the eight-thousanders. Polish mountains are one of the tourist attractions of the country. Hiking, climbing, skiing and mountain biking and attract numerous tourists every year from all over the world.[260] Water sports are the most popular summer recreation activities, with ample locations for fishing, canoeing, kayaking, sailing and windsurfing especially in the northern regions of the country.[417]

See also
flag	Poland portal
map	Europe portal
List of Poles
Outline of Poland
Notes
 Polish: Polska [ˈpɔlska] (listen)
 Polish: Rzeczpospolita Polska [ʐɛt͡ʂpɔˈspɔlita ˈpɔlska] (listen)
 Poland borders the Kaliningrad Oblast, an exclave of Russia.
References
 Constitution of the Republic of Poland, Article 27.
 Struktura narodowo-etniczna, językowa i wyznaniowa ludności Polski. Narodowy Spis Powszechny Ludności i Mieszkań 2011 [National-ethnic, linguistic and religious structure of Poland. National Census of Population and Housing 2011] (PDF) (in Polish). Central Statistical Office. 2015. p. 36. ISBN 978-83-7027-597-6.
 Struktura narodowo-etniczna, językowa i wyznaniowa ludności Polski. Narodowy Spis Powszechny Ludności i Mieszkań 2011 [National-ethnic, linguistic and religious structure of Poland. National Census of Population and Housing 2011] (PDF) (in Polish). Central Statistical Office. 2015. p. 93. ISBN 978-83-7027-597-6.
 "The Act of December 29, 1989 amending the Constitution of the Polish People's Republic". Internetowy System Aktów Prawnych. Retrieved 18 October 2020. (in Polish)
 GUS. "Powierzchnia i ludność w przekroju terytorialnym w 2018 roku".
 "Surface water and surface water change". Organisation for Economic Co-operation and Development (OECD). Retrieved 11 October 2020.
 "Statistical Bulletin No 11/2022". Statistics Poland. Retrieved 23 December 2022.
 "World Economic Outlook Database, April 2023". IMF.org. International Monetary Fund. April 2023.
 "Gini coefficient of equivalised disposable income". Eurostat. Archived from the original on 9 October 2020. Retrieved 21 June 2022.
 Nations, United (8 September 2022). "Human Development Report 2021/2022" (PDF). United Nations Development Programme. Retrieved 11 September 2022.
 Thompson, Wayne C. (2021). Nordic, Central, and Southeastern Europe 2020-2022. Blue Ridge Summit: Rowman & Littlefield Publishers. p. 322. ISBN 9781475856262.
 Lukowski, Jerzy; Zawadzki, Hubert (2001). A Concise History of Poland. Cambridge: Cambridge University Press. p. 4. ISBN 0521551099.
 Lehr-Spławiński, Tadeusz (1978). Język polski. Pochodzenie, powstanie, rozwój (in Polish). Warszawa (Warsaw): Państwowe Wydawnictwo Naukowe. p. 64. OCLC 4307116.
 Potkański, Karol (2004) [1922]. Pisma pośmiertne. Granice plemienia Polan (in Polish). Vol. 1 & 2. Kraków: Polska Akademia Umiejętności. p. 423. ISBN 9788370634117.
 Everett-Heath, John (2019). "Poland (Polska)". The Concise Dictionary of World Place-Names. Oxford: University Press. ISBN 9780191905636.
 Harper, Douglas (n.d.). "Poland (n.)". Online Etymology Dictionary. Retrieved 1 August 2021.
 Harper, Douglas (n.d.). "Pole (n.)". Online Etymology Dictionary. Retrieved 1 August 2021.
 Buko, Andrzej (2014). Bodzia. A Late Viking-Age Elite Cemetery in Central Poland. Leiden: Brill. pp. 36, 62. ISBN 9789004281325.
 Hannan, Kevin (1994). Language and Identity in a West Slavic Borderland: The Case of Teschen Silesia. Austin: University of Texas. p. 127. OCLC 35825118.
 Dabrowski, Patrice M. (2014). Poland. The First Thousand Years. New York: Cornell University Press. ISBN 9781501757402.
 Kamusella, Tomasz (2022). Words in Space and Time: A Historical Atlas of Language Politics in Modern Central Europe. Budapest: Central European University Press. p. 9. ISBN 9789633864180.
 Małecki, Antoni (1907). Lechici w świetle historycznej krytyki (in Polish). Lwów (Lviv): Zakład Narodowy im. Ossolińskich. p. 37. ISBN 9788365746641.
 Andersson, Theodore Murdock; Morkinskinna, Ellen Gade (2000). The Earliest Icelandic Chronicle of the Norwegian Kings (1030-1157). Ithaca: Cornell University Press. p. 471. ISBN 9780801436949.
 Fabisiak, Wojciech (2002). Dzieje powiatu wrocławskiego (in Polish). Wrocław: Starostwo Powiatowe. p. 9. ISBN 978-83-913985-3-1.
 Jurek, Krzysztof (2019). Poznać przeszłość 1. Karty pracy ucznia. Poziom podstawowy (in Polish). Warszawa (Warsaw): Nowa Era. p. 93. ISBN 978-83-267-3653-7.
 Subbaraman, Nidhi (12 December 2012). "Art of cheese-making is 7,500 years old". Nature News. doi:10.1038/nature.2012.12020. S2CID 180646880.
 Attema, P. A. J.; Los-Weijns, Ma; Pers, N. D. Maring-Van der (December 2006). "Bronocice, Flintbek, Uruk, Jebel Aruda and Arslantepe: The Earliest Evidence Of Wheeled Vehicles In Europe And The Near East". Palaeohistoria. University of Groningen. 47/48: 10–28 (11).
 Harding, Anthony (2020). The Oxford Handbook of the European Bronze Age. Oxford: University Press. pp. 766–783. ISBN 9780198855071.
 Price, T. Douglas (2015). Ancient Scandinavia: an archaeological history from the first humans to the Vikings. New York: Oxford University Press. p. 212. ISBN 9780190231989.
 Ring, Trudy; Watson, Noelle; Schellinger, Paul (28 October 2013). Northern Europe: International Dictionary of Historic Places. Routledge. ISBN 978-1-136-63944-9. Retrieved 31 March 2019.
 Davies, Norman (2001). Heart of Europe. The Past in Poland's Present. Oxford: Oxford University Press. p. 247. ISBN 978-0-19-280126-5.
 Zdziebłowski, Szymon (9 May 2018). "Archaeologist: We have evidence of the presence of Roman legionaries in Poland". Science in Poland. Polish Ministry of Education and Science. Retrieved 8 August 2021.
 Mielnik-Sikorska, Marta; et al. (2013), "The History of Slavs Inferred from Complete Mitochondrial Genome Sequences", PLOS ONE, 8 (1): e54360, Bibcode:2013PLoSO...854360M, doi:10.1371/journal.pone.0054360, PMC 3544712, PMID 23342138
 Brather, Sebastian (2004). "The Archaeology of the Northwestern Slavs (Seventh To Ninth Centuries)". East Central Europe. 31 (1): 78–81. doi:10.1163/187633004x00116.
 McKenna, Amy (2013). Estonia, Latvia, Lithuania, and Poland. Britannica Educational Publishing. p. 132. ISBN 9781615309917.
 Dabrowski, Patrice (2014). Poland: The First Thousand Years. Ithaca: Cornell University Press. pp. 21–22. ISBN 9781501757402.
 Ramet, Sabrina (2017). The Catholic Church in Polish History. From 966 to the Present. New York: Palgrave Macmillan US. p. 15. ISBN 978-1-137-40281-3.
 Curta, Florin; Holt, Andrew (2016). Great Events in Religion. Santa Barbara: ABC-CLIO. pp. 468, 480–481. ISBN 9781610695664.
 Knoll, Paul W.; Schaer, Frank, eds. (2003), Gesta Principum Polonorum / The Deeds of the Princes of the Poles, Central European Medieval Texts, General Editors János M. Bak, Urszula Borkowska, Giles Constable & Gábor Klaniczay, Volume 3, Budapest/ New York: Central European University Press, pp. 87–211, ISBN 978-963-9241-40-4
 Ożóg, Krzysztof (2009). The Role of Poland in the Intellectual Development of Europe in the Middle Ages. Kraków: Societas Vistulana. p. 7. ISBN 978-83-61033-36-3.
 Urbańczyk, Przemysław (2017). Bolesław Chrobry – lew ryczący (in Polish). Toruń: Wydawnictwo Naukowe Uniwersytetu Mikołaja Kopernika. pp. 309–310. ISBN 978-8-323-13886-0.
 Davies, Norman (2005a). God's Playground: A History of Poland, Volume I (2nd ed.). Oxford: Oxford University Press. pp. 27–28. ISBN 978-0-231-12817-9.
 Kumor, Bolesław; Obertyński, Zdzisław (1974). Historia Kościoła w Polsce. Poznań: Pallottinum. p. 12. OCLC 174416485.
 Gerard Labuda (1992). Mieszko II król Polski: 1025–1034 : czasy przełomu w dziejach państwa polskiego. Secesja. p. 112. ISBN 978-83-85483-46-5. Retrieved 26 October 2014. ... w wersji Anonima Minoryty mówi się znowu, iż w Polsce "paliły się kościoły i klasztory", co koresponduje w przekazaną przez Anonima Galla wiadomością o zniszczeniu kościołów katedralnych w Gnieźnie...
 Krajewska, Monika (2010). Integracja i dezintegracja państwa Piastów w kronikach polskich Marcina Kromera oraz Marcina i Joachima Bielskich9 (in Polish). Warszawa (Warsaw): W. Neriton. p. 82. ISBN 978-83-909852-1-3.
 Anita J. Prazmowska (2011). A History of Poland. Palgrave Macmillan. pp. 34–35. ISBN 978-0-230-34537-9. Retrieved 26 October 2014.[permanent dead link]
 Melton, J. Gordon (2011). Religious Celebrations. An Encyclopedia of Holidays, Festivals, Solemn Observances, and Spiritual Commemorations. Santa Barbara: ABC-CLIO. p. 834. ISBN 978-1-59884-206-7.
 Hourihane, Colum (2012). The Grove encyclopedia of medieval art and architecture. Vol. 2. New York: Oxford University Press. p. 14. ISBN 9780195395365.
 Biber, Tomasz; Leszczyński, Maciej (2000). Encyklopedia Polska 2000. Poczet władców. Poznań: Podsiedlik-Raniowski. p. 47. ISBN 978-83-7212-307-7.
 Krasuski, Jerzy (2009). Polska-Niemcy. Stosunki polityczne od zarania po czasy najnowsze. Wrocław: Zakład Narodowy im. Ossolińskich. p. 53. ISBN 978-83-04-04985-7.
 Maroń, Jerzy (1996). Legnica 1241 (in Polish). Warszawa (Warsaw): Bellona. ISBN 978-83-11-11171-4.
 Davies, Norman (2010) [1996]. Europe: A History. New York: Oxford University Press. p. 366. ISBN 9780198201717.
 Dembkowski, Harry E. (1982). The union of Lublin, Polish federalism in the golden age. East European Monographs. p. 271. ISBN 978-0-88033-009-1.
 Kula, Marcin (2000). Zupełnie normalna historia, czyli, Dzieje Polski zanalizowane przez Marcina Kulę w krótkich słowach, subiektywnie, ku pożytkowi miejscowych i cudzoziemców. Warszawa (Warsaw): Więzi. pp. 58–59. ISBN 978-83-88032-27-1.
 Wróblewski, Bohdan (2006). Jaki znak twój? Orzeł Biały. Piekary Śląskie: ZP Grupa. p. 28. ISBN 978-83-922944-3-6.
 Stanley S. Sokol (1992). The Polish Biographical Dictionary: Profiles of Nearly 900 Poles who Have Made Lasting Contributions to World Civilization. Bolchazy-Carducci Publishers. p. 60. ISBN 978-0-86516-245-7.
 Britannica Educational Publishing (2013). Estonia, Latvia, Lithuania, and Poland. Britannica Educational Publishing. p. 139. ISBN 978-1-61530-991-7.
 Wróbel, Piotr (2004). "Poland". In Frucht, Richard C. (ed.). Eastern Europe: An Introduction to the People, Lands, and Culture. Vol. 1. ABC-CLIO. p. 10. ISBN 978-1-57607-800-6. Retrieved 8 April 2013. At the same time, when most of Europe was decimated by the Black Death, Poland developed quickly and reached the levels of the wealthiest countries of the West in its economy and culture.
 Magill, Frank N. (2012). The Middle Ages. Dictionary of World Biography. Vol. 2. Hoboken: Taylor & Francis. p. 210. ISBN 978-1-136-59313-0.
 Watson, Noelle (2013). Northern Europe. International Dictionary of Historic Places. New York: Routledge, Taylor & Francis. p. 388. ISBN 978-1-136-63944-9.
 Magill 2012, p. 64
 Davies 2001, p. 256
 Halecki, Oscar (1991). Jadwiga of Anjou and the Rise of East-Central Europe. Polish Institute of Arts and Sciences of America. pp. 116–117, 152. ISBN 978-0-88033-206-4.
 Griessler, Christina (2020). The Visegrad Four and the Western Balkans. Baden-Baden: Nomos. p. 173. ISBN 978-3-7489-0113-6.
 Jerzy Wyrozumski – Historia Polski do roku 1505 (History of Poland until 1505), Państwowe Wydawnictwo Naukowe (Polish Scientific Publishers PWN), Warszawa 1986, ISBN 978-83-01-03732-1
 Norman Davies (1996). Europe: a history. Oxford University Press. p. 428. ISBN 978-0-19-820171-7. By 1490 the Jagiellons controlled Poland–Lithuania, Bohemia, and Hungary, but not the Empire.
 Frost, Robert I. (2018). The Making of the Polish-Lithuanian Union 1385-1569. Vol. 1. Oxford: University Press. p. 242. ISBN 9780198800200.
 Graves, M. A. R. (2014). The Parliaments of Early Modern Europe. Hoboken: Taylor & Francis. p. 101. ISBN 978-1-317-88433-0.
 Graves 2014, pp. 101, 197
 Paul W. Knoll (2011). "Religious Toleration in Sixteenth-Century Poland. Political Realities and Social Constrains.". In Howard Louthan; Gary B. Cohen; Franz A.J. Szabo (eds.). Diversity and Dissent: Negotiating Religious Difference in Central Europe, 1500–1800. Berghahn Books. pp. 30–45. ISBN 978-0-85745-109-5.
 Houlden, J. L. (2015). Jesus in History, Legend, Scripture, and Tradition: A World Encyclopedia. Denver, Colorado: ABC-CLIO. pp. 577–578. ISBN 978-1-61069-804-7.
 Butterwick, Richard (2021). The Polish-Lithuanian Commonwealth, 1733-1795. Yale University Press. pp. 21, 14. ISBN 978-0-300-25220-0.
 Parker, Geoffrey (2017). Global Crisis. War, Climate Change and Catastrophe in the Seventeenth Century. New Haven: Yale University Press. p. 122. ISBN 978-0-300-21936-4.
 Parker 2017, p. 122
 Ward, Adolphus; Hume, Martin (2018). The Wars of Religion in Europe. Vachendorf: Perennial Press. ISBN 978-1-5312-6318-8.
 O'Connor, Kevin (2015). The History of the Baltic States. Vol. 2nd Edition. Westport: ABC-CLIO. pp. 37–38. ISBN 978-1-61069-916-7.
 Halina Lerski (30 January 1996). Historical Dictionary of Poland, 966-1945. ABC-CLIO. p. 678. ISBN 978-0-313-03456-5. Retrieved 2 July 2012.
 Szujski, Józef (1894). Dzieła Józefa Szujskiego. Dzieje Polski (in Polish). Vol. 3. Kraków: Szujski-Kluczycki. pp. 162–163. OCLC 717123162.
 Peterson, Gary Dean (2014). Warrior Kings of Sweden. The Rise of an Empire in the Sixteenth and Seventeenth Centuries. McFarland, Incorporated, Publishers. p. 107. ISBN 978-1-4766-0411-4.
 Dyer, Thomas Henry (1861). The History of Modern Europe. Vol. From the Fall of Constantinople, in 1453, to the War in the Crimea, in 1857. Volume 2. London: J. Murray. p. 504. ISBN 978-3-337-75029-9.
 Dzięgielewski, Jan (1994). Encyklopedia historii Polski: A-M (in Polish). Polska: Morex. p. 101. ISBN 978-83-902522-1-6.
 Kizwalter, Tomasz (1987). Kryzys Oświecenia a początki konserwatyzmu polskiego (in Polish). Warszawa (Warsaw): Uniwersytet Warszawski. p. 21. OCLC 23942204.
 Scott, H. M. (2015). The Oxford Handbook of Early Modern European History, 1350-1750. Vol. 2. Oxford: Oxford University Press. pp. 409–413. ISBN 978-0-19-102000-1.
 Czapliński, Władysław (1976). Władysław IV i jego czasy [Władysław IV and His Times] (in Polish). Warsaw: PW "Wiedza Poweszechna". pp. 170, 217–218.
 Scott 2015, p. 409
 Scott 2015, pp. 409–413
 Scott 2015, p. 411
 Scott 2015, pp. 409–412, 666
 Butterwick 2021, p. 88
 Butterwick 2021, pp. 83–88
 Butterwick 2021, pp. 89–91
 Butterwick 2021, pp. 108–109
 Butterwick 2021, pp. 108–116
 Józef Andrzej Gierowski – Historia Polski 1764–1864 [History of Poland 1764–1864], Państwowe Wydawnictwo Naukowe (Polish Scientific Publishers PWN), Warszawa 1986, ISBN 978-83-01-03732-1, pp. 1–74
 Ted Tapper; David Palfreyman (2005). Understanding Mass Higher Education: Comparative Perspectives On Access. RoutledgeFalmer. p. 140. ISBN 978-0-415-35491-2. Retrieved 17 March 2013.
 Butterwick 2021, p. 176
 Polska Akademia Nauk (1973). Nauka polska. Polska Akademia Nauk. p. 151. Retrieved 30 August 2021.
 Butterwick 2021, p. 260
 Butterwick 2021, p. 310
 Józef Andrzej Gierowski – Historia Polski 1764–1864 (History of Poland 1764–1864), pp. 74–101
 Bertholet, Auguste (2021). "Constant, Sismondi et la Pologne". Annales Benjamin Constant. 46: 65–85.
 Schulz-Forberg, Hagen (2005). Unravelling Civilisation: European Travel and Travel Writing. Peter Lang. p. 162. ISBN 9052012350.
 Storozynski, Alex (2009). The Peasant Prince: Thaddeus Kosciuszko and the Age of Revolution (Google Books). New York: St. Martin's Press, 352 pages. ISBN 978-1-4299-6607-8.
 Gardner, Monica Mary (1942). The Rising of Kościuszko (Chapter VII) (Project Gutenberg). Kościuszko: A Biography. G. Allen & Unwin., ltd, 136 pages.
 Nicholls, David (1999). Napoleon. Oxford: ABC-CLIO. p. 204. ISBN 978-0-87436-957-1.
 Lukowski, Jerzy; Zawadzki, W.H. (2001). A Concise History of Poland. Cambridge: Cambridge University Press. p. 313. ISBN 978-0-521-55917-1.
 Carolina Armenteros; Dawn Dodds; Isabel Divanna; Tim Blanning (2008). Historicising the French Revolution. Newcastle: Cambridge Scholars. p. 247. ISBN 978-1-4438-1157-6.
 Kappeler, Andreas (27 August 2014). The Russian Empire: A Multi-ethnic History. Routledge. ISBN 978-1-317-56810-0 – via Google Books.
 Lucassen, Leo; Feldman, David; Oltmer, Jochen (6 September 2006). Paths of Integration: Migrants in Western Europe (1880–2004). Amsterdam University Press. ISBN 978-90-5356-883-5 – via Google Books.
 Restivo, Sal (2005). Science, Technology, and Society: An Encyclopedia. New York: Oxford University Press. p. 613. ISBN 1280835133.
 Koryś, Piotr (2018). Poland From Partitions to EU Accession: A Modern Economic History, 1772–2004. Springer. ISBN 978-3-319-97126-1.
 According to Margaret MacMillan, "The rebirth of Poland was one of the great stories of the Paris Peace Conference." Margaret MacMillan, Paris 1919: Six Months that Changed the World (2001), p. 208.
 Glenn E. Curtis (1994). Poland: A Country Study. Vol. 550 (3 ed.). Federal Research Division of the Library of Congress. p. 29. ISBN 9780844408279.
 Piotr S. Wandycz (2009). "The Second Republic, 1921-1939". The Polish Review. University of Illinois Press. 54 (2): 159–171. JSTOR 25779809.
 Marjan Kukiel (1929). "The Polish-Soviet Campaign of 1920". The Slavonic and East European Review. Modern Humanities Research Association. 8 (22): 48–65. JSTOR 4202361.
 Bitter glory: Poland and its fate, 1918 to 1939; p. 179
 Robert Machray (November 1930). "Pilsudski, the Strong Man of Poland". Current History. University of California Press. 33 (2): 195–199. doi:10.1525/curh.1930.33.2.195. JSTOR 45333442.
 Brian Porter-Szücs (6 January 2014). Poland in the Modern World: Beyond Martyrdom. John Wiley & Sons. ISBN 9781118598085.
 "Russian parliament condemns Stalin for Katyn massacre". BBC News. 26 November 2010
 Michael Geyer (2009). Beyond Totalitarianism: Stalinism and Nazism Compared. Cambridge University Press. pp. 152–153. ISBN 978-0-521-89796-9.
 Steven J. Zaloga; Richard Hook (1982). The Polish Army 1939–45. Osprey Publishing. pp. 3–. ISBN 978-0-85045-417-8. Retrieved 6 March 2011 – via Google Books.[permanent dead link]
 Jerzy Jan Lerski (1996). Historical Dictionary of Poland, 966–1945. Greenwood Publishing Group. p. 18. ISBN 978-0-313-26007-0. Retrieved 6 March 2011 – via Google Books.
 E. Garrison Walters (1988). The other Europe: Eastern Europe to 1945. Syracuse University Press. pp. 276–. ISBN 978-0-8156-2440-0. Retrieved 6 March 2011 – via Google Books.
 At the siege of Tobruk
 including the capture of the monastery hill at the Battle of Monte Cassino
 Kochanski, Halik (2014). The Eagle Unbowed: Poland and the Poles in the Second World War. Harvard University Press. ISBN 978-0-674-06814-8.
 Jerzy Jan Lerski (1996). Historical Dictionary of Poland, 966–1945. Greenwood Publishing Group. p. 34. ISBN 978-0-313-26007-0 – via Google Books.
 Stanisław Salmonowicz, Polskie Państwo Podziemne, Wydawnictwa Szkolne i Pedagogiczne, Warszawa, 1994, ISBN 978-83-02-05500-3, p. 37
 The Warsaw Rising, polandinexile.com
 Browning, Christopher R.; Matthäus, Jürgen (2004). The origins of the Final Solution: the evolution of Nazi Jewish policy, September 1939 – March 1942. Comprehensive history of the Holocaust. Lincoln: University of Nebraska Press. ISBN 978-0-8032-1327-2.
 Snyder, Timothy (2015). Black earth: the Holocaust as history and warning (First ed.). New York: Tim Duggan Books. ISBN 978-1-101-90345-2.
 Materski & Szarota (2009) Quote: Liczba Żydów i Polaków żydowskiego pochodzenia, obywateli II Rzeczypospolitej, zamordowanych przez Niemców sięga 2,7- 2,9 mln osób. Translation: The number of Jewish victims is estimated at 2,9 million. This was about 90% of the 3.3 million Jews living in prewar Poland. Source: IPN.
 "Poland Historical Background".
 "Polish Victims". United States Holocaust Memorial Museum.
 Piotrowski, Tadeusz. "Poland World War II casualties (in thousands)".
 Materski & Szarota (2009) Quote: Łączne straty śmiertelne ludności polskiej pod okupacją niemiecką oblicza się obecnie na ok. 2 770 000. Translation: Current estimate is roughly 2,770,000 victims of German occupation. This was 11.3% of the 24.4 million ethnic Poles in prewar Poland.
 "Documenting Numbers of Victims of the Holocaust and Nazi Persecution". United States Holocaust Memorial Museum.
 Wardzyńska, Maria (2009). Był rok 1939. Operacja niemieckiej policji bezpieczeństwa w Polsce. Intelligenzaktion [The Year was 1939: Operation of German Security Police in Poland. Intelligenzaktion] (PDF) (in Polish). Institute of National Remembrance. ISBN 978-83-7629-063-8. Archived from the original (PDF) on 29 November 2014. Retrieved 4 January 2020. Oblicza się, że akcja „Inteligencja" pochłonęła ponad 100 tys. ofiar. Translation: It is estimated that Intelligenzaktion took the lives of 100,000 Poles.
 Grzegorz Motyka, Od rzezi wołyńskiej do akcji "Wisła". Konflikt polsko-ukraiński 1943–1947. Kraków 2011, p. 447. See also: Book review by Tomasz Stańczyk: "Grzegorz Motyka oblicza, że w latach 1943–1947 z polskich rąk zginęło 11–15 tys. Ukraińców. Polskie straty to 76–106 tys. zamordowanych, w znakomitej większości podczas rzezi wołyńskiej i galicyjskiej."
 "What were the Volhynian Massacres?". 1943 Wołyń Massacres Truth and Remembrance. Institute of National Remembrance. 2013.
 Materski & Szarota (2009)
 Holocaust: Five Million Forgotten: Non-Jewish Victims of the Shoah. Archived 25 January 2018 at the Wayback Machine Remember.org.
 "Polish experts lower nation's WWII death toll". Archived from the original on 18 August 2019.
 Bureau odszkodowan wojennych (BOW), Statement on war losses and damages of Poland in 1939–1945. Warsaw 1947
 Bogumiła Lisocka-Jaegermann (2006). "Post-War Migrations in Poland". In: Mirosława Czerny. Poland in the geographical centre of Europe. Hauppauge, New York: Nova Science Publishers. pp. 71–87. ISBN 978-1-59454-603-7. Google Books preview.
 Eberhardt, Piotr (2006). Political Migrations in Poland 1939–1948 (PDF). Warsaw: Didactica. ISBN 978-1-5361-1035-7. Archived from the original (PDF) on 26 June 2015.
 Eberhardt, Piotr (2011). Political Migrations On Polish Territories (1939–1950) (PDF). Warsaw: Polish Academy of Sciences. ISBN 978-83-61590-46-0.
 "European Refugee Movements After World War Two". BBC – History.
 "ARTICLE by Karol Nawrocki, Ph.D.: The soldiers of Polish freedom". Retrieved 6 March 2022.
 Arthur Bliss Lane I saw Poland betrayed: An American Ambassador Reports to the American People. Indianapolis: The Bobbs-Merrill Company, 1948.
 "Warsaw Pact: Definition, History, and Significance". Retrieved 6 March 2022.
 "Polska. Historia". PWN Encyklopedia (in Polish). Archived from the original on 1 October 2006. Retrieved 11 July 2005.
 "Solidarity Movement– or the Beginning of the End of Communism". September 2020. Archived from the original on 28 March 2022. Retrieved 6 March 2022.
 Hunter, Richard J. Jr.; Ryan, Leo V. (2006). "A RETROSPECTIVE ANALYSIS AND FUTURE PERSPECTIVE: "Why Was Poland's Transition So Difficult?"". The Polish Review. University of Illinois Press. 51 (2): 147–171. JSTOR 25779611.
 Kowalik, Tadeusz (2011). From Solidarity to Sell-Out: The Restoration of Capitalism in Poland. New York, NY: Monthly Review Press.
 Spieser, Catherine (April 2007). "Labour Market Policies in Post-communist Poland: Explaining the Peaceful Institutionalisation of Unemployment". Politique européenne. 21 (1): 97–132. doi:10.3917/poeu.021.0097.
 Poláčková, Hana (1994). "Regional Cooperation in Central Europe: Poland, Hungary, Czech Republic and Slovakia: from Visegrad to CEFTA". Perspectives. SAGE Publishers (3): 117–129. JSTOR 23615759.
 Sieradzka, Monika (3 November 2019). "After 20 years in NATO, Poland still eager to please". DW News. Deutsche Welle. Retrieved 26 March 2022. Poland's NATO accession in 1999 was meant to provide protection from Russia.
 Szczerbiak, Aleks (September 2004). "History Trumps Government Unpopularity: The June 2003 Polish EU Accession Referendum". West European Politics. 27 (4): 671–690. doi:10.1080/0140238042000249876. S2CID 153998856.
 Kundera, Jaroslaw (September 2014). "Poland in the European Union. The economic effects of ten years of membership". Rivista di Studi Politici Internazionali. 81 (3): 377–396. JSTOR 43580712.
 "Europe's border-free zone expands". BBC News. 21 December 2007. Retrieved 28 July 2011.
 Smith, Alex Duval (7 February 2016). "Will Poland ever uncover the truth about the plane crash that killed its president?". The Guardian. Warsaw. Retrieved 26 March 2022.
 Turkowski, Andrzej. "Ruling Civic Platform Wins Parliamentary Elections in Poland". Carnegie Endowment for International Peace.
 Lynch, Suzanne. "Donald Tusk named next president of European Council". The Irish Times.
 "Poland elections: Conservatives secure decisive win". BBC News. 25 October 2015.
 "Poland's populist Law and Justice party win second term in power". The Guardian. 14 October 2019.
 "Rule of Law: European Commission acts to defend judicial independence in Poland". European Commission. Retrieved 15 November 2020.
 Morijn, John (10 March 2020). "Commission v Poland: What Happened, What it Means, What it Will Take". Verfassungsblog: On Matters Constitutional. doi:10.17176/20200310-215105-0. Retrieved 15 November 2020.
 "Poland's Duda narrowly beats Trzaskowski in presidential vote". BBC News. 13 July 2020.
 "Number of people who crossed the Polish border from the war-stricken Ukraine as of July 2022, by date of report". Statista. 28 July 2022.
 Polish Ministry of Education and Science (2019). "Statistical Yearbook of the Republic of Poland" (PDF). Rocznik Statystyczny Rzeczypospolitej Polskiej. Warsaw: Statistics Poland (Główny Urząd Statystyczny GUS): 80–81, 84–85, 111. ISSN 1506-0632. OCLC 907771825. Retrieved 2 April 2022.
 "Cechy krajobrazów Polski – Notatki geografia".
 Grochowski, Mirosław (1997). "Poland Under Transition and Its New Geography". Canadian Slavonic Papers. Taylor & Francis. 39 (1/2): 1–26. doi:10.1080/00085006.1997.11092140. JSTOR 40869887.
 BACC Editorial Team (2015). Second Assessment of Climate Change for the Baltic Sea Basin. Cham: Springer. p. 385. ISBN 9783319160054.
 Tymon Zielinski; Iwona Sagan; Waldemar Surosz (2017). Interdisciplinary approaches for sustainable development goals. Cham: Springer. p. 79. ISBN 9783319717883.
 Shell, Marc (2014). Islandology: Geography, Rhetoric, Politics. Stanford: University Press. p. 89. ISBN 9780804789264.
 "Najwyższe szczyty w Tatrach Polskich i Słowackich". www.polskie-gory.pl. Archived from the original on 12 December 2021. Retrieved 4 December 2020.
 Siwicki, Michał (2020). "Nowe ustalenia dotyczące wysokości szczytów w Tatrach". geoforum.pl (in Polish). Archived from the original on 9 October 2021. Retrieved 9 October 2021.
 Czetwertynski-Sytnik, Lesław; Kozioł, Edward; R. Mazurski, Krzysztof (2000). "Settlement and sustainability in the Polish Sudetes". GeoJournal. Springer. 50 (2/3): 273–284. doi:10.1023/A:1007165901891. JSTOR 41147476. S2CID 150809158.
 Christine Zuchora-Walske (2013). "The Lakes Region". Poland. ABDO Publishing. p. 28. ISBN 978-1-61480-877-0. Insert: Poland is home to 9,300 lakes. Finland is the only European nation with a higher density of lakes than Poland.
 Korzeniewska, Ewa; Harnisz, Monika (2020). Polish River Basins and Lakes. Vol. I: Hydrology and Hydrochemistry. Cham: Springer International Publishing. pp. 4–5. ISBN 9783030121235.
 Azad, Abdul Kalam; Khan, Mohammad Masud Kamal (2021). Bioenergy Resources and Technologies. London: Elsevier. p. 6. ISBN 9780128225264.
 Zbigniew Ustrunul; Agnieszka Wypych; Ewa Jakusik; Dawid Biernacik; Danuta Czekierda; Anna Chodubska (2020). Climate of Poland (PDF) (Report). Institute of Meteorology and Water Management - National Research Institute (IMGW). p. 7. Retrieved 3 April 2022.
 "Forest area (% of land area) - Poland". World Bank. Retrieved 1 April 2021.
 Milewski, Wawrzyniec (2017). Forests in Poland 2017 (PDF). Warsaw (Warszawa): State Forests Information Centre. p. 8. ISBN 9788365659231.
 Frouz, Jan; Frouzova, Jaroslava (2022). Applied Ecology: How agriculture, forestry and fisheries shape our planet. Cham: Springer International Publishing. p. 245. ISBN 9783030832254.
 Aniskiewicz, Alena (2016). "That's Polish: Exploring the History of Poland's National Emblems". culture.pl. Adam Mickiewicz Institute. Retrieved 3 April 2022. "A white eagle [...], the profile of a shaggy bison in a field of grass. These are emblems of Poland". "Nation's (somewhat disputed) national flower – the corn poppy".
 Rokosz, M. (1995). "History of the Aurochs (Bos taurus primigenius) in Poland" (PDF). Animal Genetics Resources Information. 16: 5–12. doi:10.1017/S1014233900004582. Archived from the original (PDF) on 14 January 2013.
 Reidar Andersen; Marco Apollonio; Rory Putman; Piotr Wawrzyniak (2010). European Ungulates and Their Management in the 21st Century. Cambridge: University Press. pp. 223–231. ISBN 9780521760614.
 Kevin Hillstrom; Laurie Collier Hillstrom (2003). Europe: A Continental Overview of Environmental Issues, Volume 4. ABC-CLIO World geography. p. 34. ISBN 978-1-57607-686-6.
 Mayer, Marius (2019). Cross-Border Tourism in Protected Areas: Potentials, Pitfalls and Perspectives. Cham: Springer. p. 115. ISBN 9783030059606.
 Kowalczyk, Barbara; Mikowski, Rafał; Mikowski, Łukasz (2019). Environmental law in Poland. Alphen aan den Rijn: Kluwer Law International. ISBN 9789403509501.
 Serwis Rzeczypospolitej Polskiej (n.d.). "Civil Service; Basic information about Poland". www.gov.pl. Government of the Republic of Poland. Retrieved 8 March 2022.
 Stanisz, Piotr (2020). Religion and Law in Poland. Alphen aan den Rijn: Kluwer Law International. p. 13. ISBN 9789403529738.
 Central Intelligence Agency (2021). CIA World Factbook 2021-2022. New York: Skyhorse Publishing. ISBN 9781510763814.
 Foundations of Law: The Polish Perspective. Warszawa (Warsaw): Wolters Kluwer Polska. 2021. p. 127. ISBN 9788382231731.
 Gwiazda, Anna (2015). Democracy in Poland: Representation, participation, competition and accountability since 1989. Florence: Taylor and Francis. p. 67. ISBN 9781315680118.
 Granat, Mirosław; Granat, Katarzyna (2021). The Constitution of Poland: A Contextual Analysis. Oxford: Hart Publishing. pp. 51, 52, 221. ISBN 9781509913947.
 Piotr Machnikowski; Justyna Balcarczyk; Monika Drela (2017). "Political System (III)". Contract law in Poland. Alphen aan den Rijn: Kluwer Law International. ISBN 9789041189332. OCLC 1046634087.
 Jasiński, Wojciech; Kremens, Karolina (2019). "Political System and Administrative Structure (IV)". Criminal law in Poland. Alphen aan den Rijn: Kluwer Law International. ISBN 9789403513249.
 Bień-Kacała, Agnieszka; Młynarska-Sobaczewska, Anna (2021). "The Speaker, Presidium, and Convent of Seniors, Parliamentary Committees (II), s. 281". Constitutional law in Poland. Alphen aan den Rijn: Kluwer Law International. ISBN 9789403533001.
 "Liczba jednostek podziału terytorialnego kraju". TERYT (in Polish). Statistics Poland (Główny Urząd Statystyczny GUS). 2022. Retrieved 16 March 2022.
 Martí-Henneberg, Jordi (2021). European Regions, 1870-2020: A Geographic and Historical Insight into the Process of European Integration. Cham: Springer International Publishing. pp. 259–271. ISBN 9783030615376.
 Government of Poland (2021). "Powierzchnia i ludność w przekroju terytorialnym w 2021 roku". stat.gov.pl (in Polish). Statistics Poland (Główny Urząd Statystyczny GUS). Retrieved 23 March 2022.
 Kamarad, Ewa; Wysocka-Bar, Anna (2020). "General Introduction, s. 3". Private International Law in Poland. Alphen aan den Rijn: Kluwer Law International. ISBN 9789403529615.
 Sejm of the Republic of Poland. "Dziennik Ustaw nr 78: The Constitution of the Republic of Poland". sejm.gov.pl. National Assembly (Zgromadzenie Narodowe). Retrieved 9 March 2022.
 Kamarad, Ewa; Wysocka-Bar, Anna (2020). "General Introduction, s. 2". Private International Law in Poland. Alphen aan den Rijn: Kluwer Law International. ISBN 9789403529615.
 Jaremba, Urszula (2013). National Judges As EU Law Judges: The Polish Civil Law System. Boston: Martinus Nijhoff Publishers. pp. 126–129. ISBN 9781306070959.
 Nations, United (2020). "Human Development Indicators – Poland". Human Development Reports. United Nations Development Programme. Retrieved 16 December 2020.
 "Victims of intentional homicide 1990–2018 – Poland". Data UNODC. United Nations Office on Drugs and Crime. 2018. Retrieved 16 December 2020.
 Zsuzsa Csergo; Daina Stukuls Eglitis; Paula M Pickering (2021). Central and East European Politics: Changes and Challenges. Lanham, Maryland: Rowman & Littlefield. p. 168. ISBN 9781538142790.
 Davies, Norman (1996). Europe: A History. Oxford University Press. p. 699. ISBN 978-0-19-820171-7 – via Internet Archive.
 Norman Davies (1996). Europe: A History. Oxford University Press. p. 699. ISBN 978-0-19-820171-7.
 Gierowski, Józef Andrzej (1986). Historia Polski, 1505–1764 [History of Poland, 1505–1764] (in Polish). Państwowe Wydawnictwo Naukowe. p. 251. ISBN 978-83-01-03732-1. Retrieved 26 October 2014.
 Berglund, Sten (2006). The Making of the European Union: Foundations, Institutions and Future Trends. Cheltenham: Edward Elgar Publishing Press. p. 46. ISBN 9781845420253.
 Glazebrook, G. deT. (June 1947). "The Middle Powers in the United Nations System". International Organization. University of Wisconsin Press. 1 (2): 307–315. doi:10.1017/S0020818300006081. JSTOR 2703870. S2CID 154796013.
 Bindi, Federiga (2019). Europe and America: the end of the transatlantic relationship?. Washington, D.C.: Brookings Institution Press. p. 6. ISBN 9780815732815.
 "Poland in the EU". Website of the Republic of Poland. Government of Poland. 2022. Retrieved 19 March 2022.
 De Londras, Fiona; Doody, Josephine (2015). The impact, legitimacy and effectiveness of EU counter-terrorism. London: Routledge, Taylor & Francis Group. p. 58. ISBN 9781138097957.
 Weissbrodt, David S.; Vega, Connie (2010) [2007]. International Human Rights Law: An Introduction. Philadelphia: University of Pennsylvania Press. p. 324. ISBN 9780812221206.
 Deni, John R. (2021). Coalition of the unwilling and unable: European realignment and the future of American geopolitics. Michigan: University of Michigan Press. p. 148. ISBN 9780472128792.
 Suszycki, Andrzej Marcin (2021). Nationalism in Contemporary Europe: Concept, Boundaries and Forms. Zürich: LIT. p. 193. ISBN 9783643911025.
 Mihalčová, Bohuslava; Szaryszová, Petra; Štofová, Lenka; Pružinský, Michal; Gontkovičová, Barbora (2019) [2018]. Production Management and Business Development : Proceedings of the 6th Annual International Scientific Conference on Marketing Management, Trade, Financial and Social Aspects of Business. Boca Raton: CRC Press. pp. 174–175. ISBN 9780429468667.
 Zalewski, Jerzy (2002). Wojsko Polskie w przemianach ustrojowych 1989-2001 (in Polish). Warszawa (Warsaw): Elipsa. p. 131. ISBN 978-83-7151-494-4.
 International Institute for Strategic Studies (IISS) (2022). The Military Balance 2022. Milton: Routledge. pp. 134–137. ISBN 9781000619720.
 Onoszko, Maciej (20 August 2022). "Poland Will Double Military Spending as War in Ukraine Rages". Bloomberg. Retrieved 30 March 2022.
 Popescu, Ana-Roxana (2022). "Poland to increase defence spending to 3% of GDP from 2023". Janes. Montagu Private Equity. Retrieved 24 March 2022.
 Lepiarz, Jacek (27 August 2022). "Europa Środkowa i Wschodnia nie kupuje niemieckiej broni". MSN.com. Retrieved 28 August 2022.
 L., Wojciech (29 March 2022). "Quick and Bold: Poland's Plan To Modernize its Army". Overt Defense. Retrieved 28 August 2022.
 Government of Poland (2019). Eksport uzbrojenia i sprzętu wojskowego Polski (PDF) (Report). Warszawa (Warsaw): Ministerstwo Spraw Zagranicznych MSZ (Ministry of Foreign Affairs). p. 4. Retrieved 24 March 2022.
 Day, Matthew (5 August 2008). "Poland ends army conscription". Telegraph. London. Archived from the original on 10 January 2022. Retrieved 28 July 2011.
 Zięba, Ryszard (2020). Poland's Foreign and Security Policy: Problems of Compatibility with the Changing International Order. Cham: Springer International Publishing. pp. 226–229. ISBN 9783030306977.
 Narodowego, Biuro Bezpieczeństwa. "Potencjał ochronny". Biuro Bezpieczeństwa Narodowego. Archived from the original on 24 January 2022. Retrieved 2 December 2020.
 Rybak, Marcin (6 December 2018). "Klient kontra ochrona sklepu. Czy mogą nas zatrzymać, przeszukać, legitymować?". Gazeta Wrocławska.
 "Rozdział 3 - Uprawnienia i obowiązki strażników - Straże gminne. - Dz.U.2019.1795 t.j."
 "Policja o zwierzchnictwie nad Strażą Miejską w powiecie dzierżoniowskim". doba.pl.
 "Agencja Wywiadu". aw.gov.pl.
 Antykorupcyjne, Centralne Biuro. "Aktualności". Centralne Biuro Antykorupcyjne.
 Internet, J. S. K. "Status prawny". Centralne Biuro Śledcze Policji.
 "Projekt ustawy o krajowym systemie ratowniczym". orka.sejm.gov.pl.
 "Ustawa z dnia 25 lipca 2001 r. o Państwowym Ratownictwie Medycznym". isap.sejm.gov.pl. Retrieved 10 August 2021.
 "GDP growth (annual %) – Poland | Data". data.worldbank.org.
 "Inflation, consumer prices (annual %) – Poland | Data". data.worldbank.org.
 "Employment to population ratio, 15+, total (%) (modeled ILO estimate) – Poland | Data". data.worldbank.org.
 "Eurostat: Poland in second place with the lowest unemployment in the European Union". www.gov.pl.
 "Poland National Debt 2020". countryeconomy.com.
 "Poland promoted to developed market status by FTSE Russell". Emerging Europe. September 2018. Retrieved 1 January 2021.
 "Pracujący w rolnictwie, przemyśle i usługach | RynekPracy.org". Archived from the original on 25 April 2020. Retrieved 28 May 2020.
 "Polish economy seen as stable and competitive". Warsaw Business Journal. 9 September 2010. Archived from the original on 13 September 2010. Retrieved 28 July 2011.
 Dorota Ciesielska-Maciągowska (5 April 2016). "Hundreds of foreign companies taken over by Polish firms over the last decade". Central European Financial Observer. Archived from the original on 13 April 2016. Retrieved 17 June 2017.
 Thomas White International (September 2011), Prominent Banks in Poland. Emerging Market Spotlight. Banking Sector in Poland (Internet Archive). Retrieved 6 November 2014.
 Worldbank.org, Global Financial Development Report 2014. Appendix B. Key Aspects of Financial Inclusion (PDF file, direct download). Retrieved 6 November 2014.
 Schwab, Klaus. "The Global Competitiveness Report 2010–2011" (PDF). World Economic Forum. pp. 27 (41/516). Retrieved 25 April 2011.
 "Exports of goods and services (BoP, current US$) | Data". data.worldbank.org.
 "Exports of goods and services (% of GDP) | Data". data.worldbank.org. Retrieved 6 September 2021.
 Ivana Kottasová (30 July 2019). "Brain drain claimed 1.7 million youths. So this country is scrapping its income tax". CNN. Retrieved 30 July 2019.
 "Travel And Tourism in Poland". www.euromonitor.com. Archived from the original on 7 December 2010. Retrieved 12 October 2009.
 Stanisław Konopacki (12 March 2009). Polska pięć lat w Unii Europejskiej. WSMIP UŁ. ISBN 9788388679841.
 Press Release (5 November 2012). "International tourism strong despite uncertain economy". World Tourism Organization UNWTO. Archived from the original on 18 February 2013. Retrieved 6 February 2013.
 "UNTWO World Tourism Barometer, Vol.5 No.2" (PDF). www.tourismroi.com. Archived from the original (PDF) on 25 March 2009. Retrieved 12 October 2009.
 Neil Wilson; Tom Parkinson; Richard Watkins (2005). "The Eagles' Nests". Poland. Lonely Planet. ISBN 9781740595223.
 Pickup, Gilly (7 March 2019). The 50 Greatest Castles and Palaces of the World. Icon Books. ISBN 9781785784583.
 "PAIH | Transport". www.paih.gov.pl.
 "Autostrady :: Generalna Dyrekcja Dróg Krajowych i Autostrad – Serwis informacyjny". www.gddkia.gov.pl.
 "National Road Rebuilding Program (Polish)". Bip.mswia.gov.pl. 16 February 2006. Retrieved 28 July 2011.
 "Length of the rail network in Europe 2017, by country". Statista.
 International Energy Agency (20 May 2022). "Poland - Countries & Regions". Paris: IEA. Retrieved 24 May 2022.
 "Poland. Summary of Coal Industry" (PDF). Retrieved 5 March 2022.
 International Energy Agency (13 April 2022). "Frequently Asked Questions on Energy Security". Paris: IEA. Retrieved 27 April 2022.
 Ministry of Climate and Environment (2 February 2021). "Energy Policy of Poland until 2040 (EPP2040)". Ministry of Climate and Environment of Poland. Retrieved 24 May 2022.
 Richard Francis Mould (1993). A century of X-rays and radioactivity in medicine: with emphasis on photographic records of the early years. p. 19. ISBN 978-0-7503-0224-1 – via Google Books.
 Nodzyńska, Małgorzata; Cieśla, Paweł (2012). From alchemy to the present day – the choice of biographies of Polish scientists. Cracow: Pedagogical University of Kraków. ISBN 978-83-7271-768-9. Archived from the original on 3 March 2016. Retrieved 3 May 2018.
 "Nicolaus Copernicus Biography: Facts & Discoveries". Space.com. 20 March 2018. Retrieved 6 April 2018.
 Wolak, Arthur J. (12 March 2004). Forced Out: The Fate of Polish Jewry in Communist Poland. Arthur Wolak. ISBN 978-1-58736-291-0.
 "POLAND" (PDF). World Intellectual Property Organization. Geneva: United Nations. 2021. Retrieved 4 March 2022.
 Barcikowska, Renata (1 September 2016). "Research Institutes In Poland — Evaluation of Their Place and Role in Innovative Politics in Poland". Marketing of Scientific and Research Organizations. 21 (3): 141–154. doi:10.14611/minib.21.09.2016.12. S2CID 199470591. Archived from the original on 1 May 2020 – via content.sciendo.com.
 Statistics Poland (2021). Preliminary results of the National Population and Housing Census 2021. Główny Urząd Statystyczny GUS. p. 1.
 Statistics Poland (2021). Area and population in the territorial profile (in English and Polish). Główny Urząd Statystyczny GUS. p. 20.
 "Fertility rate, total (births per woman) - Poland". World Bank. Retrieved 12 March 2022.
 "Median age". CIA World Factbook. Central Intelligence Agency. Retrieved 12 March 2022.
 "Urban population (% of the population) - Poland". World Bank. Retrieved 13 March 2022.
 "Distribution of population by degree of urbanisation, dwelling type and income group - EU-SILC survey". European Statistical Office "Eurostat". European Commission. 2020. Retrieved 6 April 2022.
 Funkcje Metropolitalne Pięciu Stolic Województw Wschodnich Archived 27 March 2009 at the Wayback Machine - Markowski
 World Urbanization Prospects - United Nations - Department of Economic and Social Affairs / Population Division, The 2003 Revision (data of 2000)
 Eurostat, Urban Audit database Archived 6 April 2011 at the Wayback Machine, accessed on 12 March 2009. Data for 2004.
 Cox, Wendell (2013). "Major Metropolitan Areas in Europe". New Geography. Joel Kotkin and Praxis Strategy Group.
 European Spatial Planning Observation Network, Study on Urban Functions (Project 1.4.3) Archived 24 September 2015 at the Wayback Machine, Final Report, Chapter 3, (ESPON, 2007)
 Jażdżewska, Iwona (September 2017). "Changes in population density of the urban population in southern Poland in the period 1950-2011 against the background of political and economic transformation". Miscellanea Geographica. Sciendo. 21 (3): 107–113. doi:10.1515/mgrsd-2017-0017. ISSN 2084-6118. S2CID 134111630.
 Statistics Poland (n.d.). The Concept of the International Migration. Statistics System in Poland (PDF). Główny Urząd Statystyczny GUS. p. 5.
 "Filling Poland's labour gap". Poland Today. Archived from the original on 12 May 2022. Retrieved 24 March 2019.
 Departament Rynku Pracy MRPiPS (2021). "Zezwolenia na pracę cudzoziemców". psz.praca.gov.pl (in Polish).
 "Informacja o wynikach Narodowego Spisu Powszechnego Ludności i Mieszkań 2021 na poziomie województw, powiatów i gmin". stat.gov.pl. 2022. Archived from the original on 20 September 2022. Retrieved 21 September 2022.
 "GUS - Bank Danych Lokalnych". bdl.stat.gov.pl. 2022.
 Mori, Laura (2018). Observing eurolects corpus analysis of linguistic variation in EU law. Philadelphia: John Benjamins Publishing Company. p. 295. ISBN 9789027201706.
 "Framework Convention for the Protection of National Minorities". Treaty No. 157 of 1 February 1995. Council of Europe. Retrieved 15 September 2021.
 Lazdiņa, Sanita; Marten, Heiko F. (2018). Multilingualism in the Baltic States: Societal Discourses and Contact Phenomena. Springer. ISBN 9781137569141.
 Natalia Kucirkova; Catherine E Snow; Vibeke Grøver; Catherine McBride (2017). The Routledge international handbook of early literacy education. New York: Routledge. p. 139. ISBN 9781138787889.
 "Act of 6 January 2005 on national and ethnic minorities and on the regional languages" (PDF). GUGiK.gov.pl. Główny Urząd Geodezji i Kartografii (Head Office of Geodesy and Cartography). Archived from the original (PDF) on 6 March 2021. Retrieved 6 April 2020.
 Michna, Ewa; Warmińska, Katarzyna (2020). Identity Strategies of Stateless Ethnic Minority Groups in Contemporary Poland. Cham: Springer International Publishing. p. 16. ISBN 9783030415754.
 "Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 5 kwietnia 2017 r. w sprawie ogłoszenia jednolitego tekstu ustawy o mniejszościach narodowych i etnicznych oraz o języku regionalnym". isap.sejm.gov.pl.
 "O wyjazdach zagranicznych i znajomości języków obcych" (PDF). CBOS Komunikat z Badań (in Polish) (5): 13. 2016. ISSN 2353-5822. Retrieved 15 March 2022.
 Graf Strachwitz, Rupert (2020). Religious communities and civil society in Europe. Vol. II: Analyses and perspectives on a complex interplay. Berlin: De Gruyter Oldenburg. p. 177. ISBN 978-3110672992.
 "Infographic - Religiousness of Polish inhabitants". stat.gov.pl. Statistics Poland (Główny Urząd Statystyczny GUS). 2015. Retrieved 13 March 2022.
 Brabbs, Derry (2020). Great Pilgrimage Sites of Europe. London: Frances Lincoln. p. 116. ISBN 9780711245082.
 Silbermann, Michael; Berger, Ann M. (2022). Global Perspectives in Cancer Care: Religion, Spirituality, and Cultural Diversity in Health and Healing. Oxford: University Press. p. 197. ISBN 978-0197551356.
 Ramet, Sabrina P.; Borowik, Irena (26 October 2016). Religion, Politics, and Values in Poland: Continuity and Change Since 1989. New York: Palgrave Macmillan. p. 147. ISBN 9781137437518.
 Laursen, John Christian; Nederman, Cary J. (2011). Beyond the Persecuting Society: Religious Toleration Before the Enlightenment. Philadelphia: University of Pennsylvania Press. p. 103. ISBN 978-0812215670.
 Marcus, Joseph (2011). Social and Political History of the Jews in Poland 1919-1939. Boston: De Gruyter Mouton. p. 7. ISBN 9783110838688.
 "Concise Statistical Yearbook of Poland, 2008" (PDF). Central Statistical Office. 28 July 2008. Archived from the original (PDF) on 28 October 2008. Retrieved 12 August 2008.
 "Niecierpliwi". www.termedia.pl.
 "Prywatnie leczy się już ponad połowa Polaków".
 "Poland Guide: The Polish health care system, An introduction: Poland's health care is based on a general". Justlanded.com. Retrieved 28 July 2011.
 Nations, United (2020). "Poland – Human Development Indicators". Human Development Reports. United Nations Development Programme. Retrieved 16 December 2020.
 "Mortality rate, infant (per 1,000 live births) | Data". data.worldbank.org.
 "Poland: Country Health Profile 2019 | READ online". OECD iLibrary.
 "Prywatna opieka medyczna – czy warto? – Blog – Compensa". www.compensa.pl.
 "Imports of Drugs and Medicines by Country". World's Top Exports. 4 April 2020.
 "History – Jagiellonian University – Jagiellonian University". en.uj.edu.pl.
 Jan IJ. van der Meer (2002). Literary Activities and Attitudes in the Stanislavian Age in Poland (1764–1795): A Social System?. Rodopi. p. 233. ISBN 978-90-420-0933-2. Retrieved 26 April 2012.
 Norman Davies (2005). God's Playground: 1795 to the present. Columbia University Press. p. 167. ISBN 978-0-231-12819-3. OCLC 660185612.
 "Zmiany w wychowaniu przedszkolnym - Informacje - Wychowanie przedszkolne w Polsce - wiek, obowiązek, miejsce, opłaty - dlaprzedszkolaka.info". www.dlaprzedszkolaka.info. Archived from the original on 25 November 2020. Retrieved 3 December 2020.
 "Ustawa z dnia 14 grudnia 2016 r." (PDF). isap.sejm.gov.pl (in Polish). Retrieved 30 June 2022.
 "MATURA 2020 | wymagania na STUDIA | jak wygląda | terminy". otouczelnie.pl.
 Central Statistical Office: Studenci szkół wyższych (łącznie z cudzoziemcami) na dzień 30 XI 2008. Number of students at Poland's institutions of higher education, as of 30 November 2008. Retrieved 13 June 2012. Archived at Archive.org on 28 October 2008. (in Polish)
 "Study in Poland". studies.info. Retrieved 27 March 2019.
 "Ranking Uczelni Akademickich – Ranking Szkół Wyższych PERSPEKTYWY 2019". ranking.perspektywy.pl.
 OECD (2009). "The impact of the 1999 education reform in Poland". Retrieved 17 September 2010.
 "Programme for International Student Assessment (PISA) Results from PISA 2018" (PDF). OECD. 2019. Retrieved 30 June 2022.
 Adam Zamoyski, The Polish Way: A Thousand Year History of the Poles and Their Culture. Published 1993, Hippocrene Books, Poland, ISBN 978-0-7818-0200-0
 "Biało-Czerwoni – definicja, synonimy, przykłady użycia". sjp.pwn.pl.
 Jakubowska, Longina (1990). "Political Drama in Poland: The Use of National Symbols". Anthropology Today. Royal Anthropological Institute of Great Britain and Ireland. 6 (4): 10–13. doi:10.2307/3032734. JSTOR 3032734.
 "Zabytki nieruchome". www.nid.pl. Archived from the original on 7 July 2020. Retrieved 7 July 2020.
 "Album "100 pomników historii"". www.nid.pl. Archived from the original on 8 July 2020. Retrieved 7 July 2020.
 UNESCO World Heritage. "Poland". UNESCO World Heritage Centre. Retrieved 29 July 2021.
 "Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 19 grudnia 2014 r. w sprawie ogłoszenia jednolitego tekstu ustawy o dniach wolnych od pracy". isap.sejm.gov.pl.
 "Opłatek i pierwsza gwiazdka czyli wigilijne tradycje". wegorzewo.wm.pl.
 "Why Do Poles Leave One Chair Empty on Christmas Eve?". Culture.pl.
 "turoń – słownik języka polskiego i poradnia językowa – Dobry słownik". DobrySłownik.pl.
 Borodo, Michał (22 February 2020). English Translations of Korczak's Children's Fiction: A Linguistic Perspective. Springer Nature. ISBN 978-3-030-38117-2 – via Google Books.
 "Śmigus-Dyngus: Poland's National Water Fight Day". Culture.pl.
 "Summer in Warsaw | Things You Can Do Only in Summer". 21 October 2018.
 Individuals and Their Social Context. Poland: Institute of Political Studies Polish Academy of Sciences. 31 December 2018. p. 160. ISBN 978-83-65972-34-7.
 "The Music Courts of the Polish Vasas" (PDF). www.semper.pl. p. 244. Archived from the original (PDF) on 29 May 2009. Retrieved 13 May 2009.
 Wolff, Larry (9 January 2012). The Idea of Galicia; History and Fantasy in Habsburg Political Culture. Stanford University Press. p. 57. ISBN 978-0-8047-7429-1.
 Guillain, Charlotte (2012). Poland. Raintree. p. 29. ISBN 978-1-4062-2826-7.
 Ministry of Foreign Affairs of Poland, 2002–2007, An Overview of Polish Culture Archived 2 April 2009 at the Wayback Machine Access date 13 December 2007.
 "Lady with an Ermine – by Leonardo Da Vinci". LeonardoDaVinci.net.
 Cross, Mary (31 August 2017). Madonna: A Biography. Greenwood Publishing Group. p. 47. ISBN 978-0-313-33811-3. Retrieved 31 August 2017 – via Google Books.
 Sarzyński, Piotr (12 February 2013). "Ranking polskich galerii ze współczesną sztuką". www.polityka.pl (in Polish). Retrieved 4 May 2021.
 Facca, Danilo; Lepri, Valentina (2013). Polish culture in the Renaissance: studies in the arts, humanism and political thought. Firenze: University Press. pp. 14–16. ISBN 9788866554899.
 Magocsi, Paul Robert (2018). Historical Atlas of Central Europe. Vol. 3rd Edition. Toronto: University Press. p. 37. ISBN 9781487523312.
 Karczmarzyk, Włodzimierz (1990). Views of Polish towns. Warsaw (Warszawa): Interpress. p. 30. ISBN 8322323921.
 Szolginia, Witold (1992). Architektura. Warsaw: Sigma NOT. p. 152. ISBN 978-83-85001-89-8.
 Brockington, Grace (2009). Internationalism and the Arts in Britain and Europe at the Fin de Siècle. Bern: Peter Lang. p. 116. ISBN 9783039111282.
 Marcinek, Roman (2002). Poland. Kraków: Kluszczyński. pp. 16, 158, 170. ISBN 9788388080425.
 Kujawińska-Courtney, Krystyna; Williams, Evan (2011). European Culture in Diversity. Newcastle: Cambridge Scholars. pp. 115–116. ISBN 9781443832953.
 Roszkowski, Wojciech (2015). Cultural Heritage of East Central Europe: A Historical Outline. Warsaw (Warszawa): Instytut Studiów Politycznych PAN. pp. 44–46. ISBN 9788364091551.
 Miłobędzki, Adam (1994). The architecture of Poland : a chapter of the European heritage (in Polish). Poland: International Cultural Centre-Międzynarodowe Centrum Kultury w Krakowie. pp. 52–56. ISBN 978-83-85739-14-2.
 Many designs imitated the arcaded courtyard and arched loggias of the Wawel palace. Michael J. Mikoś. "Renaissance Cultural Background". www.staropolska.pl. p. 9. Retrieved 23 April 2009.
 Stanley, John (2004). "Reviewed Work: Literary Activities and Attitudes in the Stanislavian Age in Poland (1764–1795): A Social System? by Jan I.J. van der Meer". Canadian Slavonic Papers. 46 (1/2): 226–229. JSTOR 40870954.
 Rączka, Jan Władysław (2001). Walka o polski styl narodowy w architekturze (in Polish). Poland: Politechnika Krakowska. ISBN 978-83-7242-153-1.
 Dmochowski, Zbigniew (1956). The Architecture of Poland: An Historical Survey. London: Polish Research Centre. p. 241. OCLC 636790894.
 Kosmaczewska, Joanna; Poczta, Walenty (2021). Tourism and Socio-Economic Transformation of Rural Areas: Evidence from Poland. Milton: Taylor & Francis. pp. 4–30. ISBN 9781000377385.
 Centroni, Alessandra (3 January 2016). Restauro e ricostruzione. Italy: Gangemi Editore. p. 121. ISBN 978-88-492-9191-9.
 Dyczewski, Leon (29 July 2002). Values in the Polish Cultural Tradition. CRVP. ISBN 978-1-56518-142-7 – via Google Books.
 Koca, B. (2006). "Polish Literature – The Middle Ages (Religious writings)" (in Polish). Archived from the original on 8 November 2006. Retrieved 10 December 2006.
 www.ideo.pl, Ideo Sp. z o.o. -. "The manuscript with the first ever sentence in Polish has be [sic] digitalized – News – Science & Scholarship in Poland". scienceinpoland.pap.pl. Archived from the original on 21 August 2017. Retrieved 24 May 2017.
 "The first sentence in Polish in the UNESCO register". #Poland. Retrieved 24 May 2017.
 "Polish Libraries – Wiesław Wydra: The Oldest Extant Prose Text in the Polish language. The Phenomenon of the Holy Cross Sermons". polishlibraries.pl. Retrieved 24 May 2017.
 Carter, F.W. (2006). Trade and Urban Development in Poland: An Economic Geography of Cracow, from Its Origins to 1795. Cambridge University Press. p. 364. ISBN 978-0-521-02438-9.
 "Dwujęzyczność w twórczości Jana Kochanowskiego". fp.amu.edu.pl.
 Evonne Levy (April 2004). Propaganda and the Jesuit Baroque. University of California Press. ISBN 978-0-520-23357-7. Retrieved 24 May 2017.
 Peter Melville Logan, ed. (2014). The Encyclopedia of the Novel. Associate editors:Olakunle George, Susan Hegeman, EfraÃn Kristal. John Wiley & Sons. ISBN 978-1-118-77907-1. Retrieved 24 May 2017 – via Google Books.
 Eunice L. Blavascunas (2008). The Peasant and Communist Past in the Making of an Ecological Region: Podlasie, Poland. p. 98. ISBN 978-0-549-65633-3.[permanent dead link]
 "The Joseph Conrad Society (UK) Official Website". josephconradsociety.org. Retrieved 10 February 2016.
 "The Joseph Conrad Society of America". josephconrad.org. Retrieved 10 February 2016.
 Booker, M. Keith (2020). Historical Dictionary of Science Fiction Cinema. Rowman & Littlefield Publishers. p. 261. ISBN 978-1-5381-3010-0.
 "O Wiedźminie i Wiedźmince". Rynek książki.
 "Facts on the Nobel Prize in Literature". Nobelprize.org. 5 October 2009. Retrieved 28 July 2011.
 Adam Gopnik (5 June 2007). "Szymborska's 'View': Small Truths Sharply Etched". npr.org. Retrieved 12 December 2010.
 "Tokarczuk and Handke win Nobel Literature Prizes". BBC News. 10 October 2019.
 "Always home-made, tomato soup is one of the first things a Polish cook learns to prepare." [in:] Marc E. Heine. Poland. 1987
 "Tu się w lasy schroniły wygnane ze zbytkowych stołów, narodowe potrawy, Barszcz, Bigos, Zrazy, Pirogi i Pieczeń" [in:] Jan N. de Bobrowicz. Maxymilian arcyksiąże Austryacki obrany Król polski. 1848. s. 74; "barszcz, rosół, sztuka mięsa, pieczenie huzarskie, bigos, pierogi, kiełbasa z kapustą, przede wszystkim zaś rozmaite kasze" Zbigniew Kuchowicz Obyczaje staropolskie XVII-XVIII wieku. 1975; "pieczeń cielęca pieczona (panierowana), pieczeń cielęca zapiekana w sosie beszamelowym, pieczeń huzarska (=pieczeń wołowa przekładana farszem), pieczeń rzymska (klops), pieczeń rzymska (klops z cielęciny) w sosie śmietanowym, pieczeń rzymska z królika " [in:] Stanisław Berger. Kuchnia polska. 1974.; Polish Holiday Cookery by Robert Strybel. Strybel, Robert (2003). Polish Holiday Cookery. ISBN 978-0-7818-0994-8 – via Google Books.
 Amanda Fiegl (17 December 2008). "A Brief History of the Bagel". smithsonianmag.com. Retrieved 6 May 2023.
 Byrd Hollar, Melanie; Dunn, John P. (2020). Cooking through history: a worldwide encyclopedia of food with menus and recipes. Santa Barbara: Greenwood. pp. 431–432. ISBN 9781610694568.
 Steves, Rick; Hewitt, Cameron (15 August 2017). Rick Steves Snapshot Kraków, Warsaw & Gdańsk. Avalon Publishing. ISBN 978-1-63121-624-4.
 "gorzała – Słownik języka polskiego PWN". sjp.pwn.pl.
 "History of vodka production, at the official page of Polish Spirit Industry Association (KRPS), 2007". Archived from the original on 30 September 2007.
 "EJPAU 2004. Kowalczuk I. CONDITIONS OF ALCOHOLIC BEVERAGES CONSUMPTION AMONG POLISH CONSUMERS". www.ejpau.media.pl.
 Jim Hughes (4 February 2013). "Forgotten Beer Styles: Grodziskie". badassdigest.com. Archived from the original on 17 February 2015. Retrieved 10 May 2023.
 Strybel, Robert; Strybel, Maria (31 March 2019). Polish Heritage Cookery. Hippocrene Books. ISBN 978-0-7818-1124-8. Retrieved 31 March 2019 – via Google Books.
 "Maks Faktorowicz: Polak, który stworzył kosmetyczne imperium" [Maks Faktorowicz: A Pole who created a cosmetic empire]. Interia Kobieta (in Polish). Retrieved 24 May 2017.
 "Maksymilian Faktorowicz – człowiek, który dał nam sztuczne rzęsy" [Maksymilian Faktorowicz – a man who gave us false eyelashes]. Polskie Radio (in Polish). Retrieved 24 May 2017.
 Stella Rose Saint Clair (12 February 2014). "Makeup Masters: The History of Max Factor". Beautylish. Retrieved 24 May 2017.
 Lepan, Alen (22 May 2019). "Poland: An ambitious player making a name in the cosmetics industry". Daily Sabah.
 Norbert Ziętal (13 July 2013). "Przemyski Inglot ma już 400 sklepów na świecie" [Przemysl Inglot already has 400 stores in the world]. Strefa Biznesu (in Polish).
 Butler, Sarah (2 September 2016). "Reserved! Polish fashion chain moves into BHS flagship store". The Guardian. Retrieved 12 March 2022.
 Biedrońska-Słota, Beata (2005). Crossroads of Costume and Textiles in Poland. Kraków: National Museum (Muzeum Narodowe). p. 20. ISBN 9788389424464. OCLC 607873644.
 "The Wrightsman Collection. Vols. 1 and 2, Furniture, Gilt Bronze and Mounted Porcelain, Carpets". Metropolitan Museum of Art – via Google Books.
 Ford, Charles; Hammond, Robert M. (2009). Polish Film: A Twentieth Century History. London: Eurospan. pp. 12–14, 118. ISBN 9781476608037.
 Haltof, Marek (2015). Historical Dictionary of Polish Cinema. Lanham: Rowman & Littlefield Publishers. pp. 195, 25, 5, 91. ISBN 978-1322889191.
 Tzvetkova, Juliana (12 October 2017). Pop Culture in Central Europe. ABC-CLIO. p. 188. ISBN 978-1-4408-4466-9.
 Agnieszka Stępińska; Artur Lipiński; Dorota Piontek; Agnieszka Hess (2020). Populist Political Communication in Poland. Berlin: Logos Verlag. pp. 110, 114. ISBN 9783832586140.
 Cabrera, Isabel (2020). "World Reading Habits in 2020 [Infographic]". geediting.com. Global English Editing. Retrieved 29 September 2021.
 The International Encyclopedia of Media Effects, 4 Volume Set. Wiley. 6 March 2017. p. 1160. ISBN 978-1-118-78404-4.
 Marszałkowski, Jakub; Biedermann, Sławomir; Rutkowski, Eryk (2021). The Game Industry of Poland (PDF). Warsaw (Warszawa): Polish Agency for Enterprise Development. ISBN 9788376334516.
 "FIFA World Cup Statistics-Poland". FIFA. Archived from the original on 6 December 2007. Retrieved 12 December 2010.
 "FIFA Statistics – Poland". Archived from the original on 6 December 2007. Retrieved 12 December 2010.
 "Poland hosts Euro 2012!". warsaw-life.com. Retrieved 12 December 2010.
 "FIVB Senior World Ranking – Men". Retrieved 30 May 2021.
 "FIVB Volleyball Men's World Championship Poland 2014". Retrieved 1 January 2017.
 "Finals". Retrieved 13 October 2018.
 Fedor, Dariusz; Ramlau, Łukasz (2009). Polska, to tu się zaczęło (in Polish). Poland: Agora. p. 153. ISBN 978-83-7552-707-0.
 "Speedway World Cup: Poland win 2010 Speedway World Cup". worldspeedway.com. Archived from the original on 10 May 2011. Retrieved 18 December 2010.
 Blanka Konopka (10 June 2022). "Tennis fever hits Poland as clubs across the country report surge in interest". thefirstnews.com. Retrieved 24 April 2023.
 "Poland wins Hopman Cup as Agnieszka Radwanska and Jerzy Janowicz combine to beat Serena Williams and John Isner in Perth". abc.net.au. 10 January 2015. Retrieved 24 April 2023.
 Summer Sports in Poland at Poland For Visitors Online. Retrieved 2 November 2014.
Works cited
Materski, Wojciech; Szarota, Tomasz (2009). Poland 1939–1945. Casualties and the victims of repressions under the Nazi and the Soviet occupations [Polska 1939–1945. Straty osobowe i ofiary represji pod dwiema okupacjami]. (excerpts online). Institute of National Remembrance (IPN). Hardcover, 353 pages. ISBN 978-83-7629-067-6. With a Foreword by Janusz Kurtyka (IPN); and expert contributions by Waldemar Grabowski, Franciszek Piper, and Andrzej Krzysztof Kunert. Archived from the original on 31 March 2012.
External links
Poland
at Wikipedia's sister projects
Definitions from Wiktionary
Media from Commons
News from Wikinews
Quotations from Wikiquote
Texts from Wikisource
Textbooks from Wikibooks
Resources from Wikiversity
Travel information from Wikivoyage
Poland.gov.en – Polish national portal Archived 3 December 2014 at the Wayback Machine
Poland. The World Factbook. Central Intelligence Agency.
"Poland" . Encyclopædia Britannica. Vol. 21 (11th ed.). 1911.
"Poland" . Encyclopædia Britannica. Vol. 32 (12th ed.). 1922.
Poland at Curlie
 Wikimedia Atlas of Poland
 Geographic data related to Poland at OpenStreetMap
vte
Poland articles
Links to related articles
Authority control Edit this at Wikidata
Categories: PolandCountries in EuropeMember states of NATOMember states of the European UnionMember states of the Union for the MediterraneanMember states of the United NationsMember states of the Three Seas InitiativeRepublicsStates and territories established in 1918OECD members
This page was last edited on 27 June 2023, at 23:45 (UTC).
Text is available under the Creative Commons Attribution-ShareAlike License 4.0; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.
Privacy policyAbout WikipediaDisclaimersContact WikipediaCode of ConductMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWikiToggle limited content width



Functional Protein Structure Annotation Using a
Deep Convolutional Generative Adversarial Network
Ethan Moyer1*, Jeff Winchell2,4, Isamu Isozaki2
, Yigit Alparslan2
, Mali Halac3
, Edward Kim2
1School of Biomedical Engineering, Drexel University, PA
2College of Computing & Informatics, Drexel University, PA
3College of Engineering, Drexel University, PA
4College of Arts & Sciences, Drexel University, PA
Email: { ejm374, jmw479, imi25, ya332, mh3636, ek826 }@drexel.edu
Abstract—Identifying novel functional protein structures is
at the heart of molecular engineering and molecular biology,
requiring an often computationally exhaustive search. We introduce the use of a Deep Convolutional Generative Adversarial
Network (DCGAN) to classify protein structures based on their
functionality by encoding each sample in a grid object structure
using three features in each object: the generic atom type, the
position atom type, and its occupancy relative to a given atom. We
train DCGAN on 3-dimensional (3D) decoy and native protein
structures in order to generate and discriminate 3D protein
structures. At the end of our training, loss converges to a local
minimum and our DCGAN can annotate functional proteins
robustly against adversarial protein samples. In the future we
hope to extend the novel structures we found from the generator
in our DCGAN with more samples to explore more granular
functionality with varying functions. We hope that our effort
will advance the field of protein structure prediction.
Index Terms—Generative Adversarial Network, Protein Structure Prediction, Functional Protein Generation, Machine Learning, Bioinformatics
I. INTRODUCTION
One of the goals of metagenomics is to identify the functions
of proteins present in a given sample. Two commonly used
methods to determine the protein functions are 1. to compare
the amino acid sequence of a protein with the functionally
annotated sequences present in protein sequence databases, 2.
to compare the 3-D structure of a protein against those of the
protein structure databases [1]. Thanks to the recent advances
in computational tools and techniques especially applications
of machine learning in the field of metagenomics, there is a
growing number of annotations of proteins available.
The inverse problem, determining the 3-D structure of a protein for a given function, is a young field which has attracted
the interest of researchers as engineering of proteins with
certain functions has promising applications in biotechnology
and medicine [2]. Design of such proteins may lead to novel
therapeutic agents such as custom designed signaling proteins
that will allow us to give specific instructions to cells [3].
* Corresponding author
All source code is open-sourced at GitHub.
To address this issue, we propose an implementation of
a Deep Convolutional Generative Adversarial Network using
a protein data set obtained from Protein Data Bank (PDB)
database.
This paper is organized such that section II discusses related
work, section III discusses the implemented search algorithms,
section V reports the experiments and results, section IV
concludes the paper by going over the important findings and
discusses future work.
II. RELATED WORK
Functionality of a protein and its structure are tightly coupled.
Understanding the 3-D structure of a protein can give us
knowledge regarding its functionality.
A. Protein Structure Prediction
In the literature, we see that X-ray crystallography and
Nuclear Magnetic Resonance (NMR) are used to determine
the 3-D structure of a protein [4]. By emitting X-ray onto
protein and measuring the diffractions and scatters, one can
measure the density of molecules in a protein. NMR technique
is faster compared to X-ray crystallography, but it is only used
on proteins that have less than 150 amino acids [5]. Therefore,
developing computational models that would predict protein
structure is a crucial need [6].
For this reason, identifying the native three-dimensional (3-
D) structure of a protein is a common problem in bioinformatics and has applications in drug design, protein engineering,
and protein annotation. Previous methods of 3-D structure
prediction have focused on energy minimization to find thermodynamically favored structures and the results are assessed
in comparison to the free energy of the native structure [7].
A few works in energy prediction have successfully used
Convolution Neural Networks (CNN) to predict the energy
between each of the bonds in a structure [8]. Moreover, some
have attempted to quantify the relative energy deviation of
a decoy structure from its native, or most optimally folded,
structure [9]. This latter method is displayed in Figure 1a
where the red to blue gradient corresponds to a measurement
of energy deviation from a decoy structure to a native structure.
arXiv:2104.08969v1 [q-bio.BM] 18 Apr 2021
B. Functional Protein Annotation
The function of a protein is closely tied to its structure.
A similar sequence of amino acids between two proteins can
imply an identical or similar function. However there are cases
of even a single amino acid change entirely changing the
function of a protein [10]. As such, additional criteria beyond
protein structure is needed to predict the function of a protein.
To simplify this task, there is a large body of work that focuses
on identifying ”structural motifs,” or certain protein structures
and amino acid sequences which are found in many proteins
with a specific function. It should be noted that the presence of
a structural motif in that protein does not necessarily indicate
that protein has a certain function.
A more general question is whether a protein is functional
or non-functional. Since functionality is more or less indicative
of native folding, one would suspect that a search of functional
proteins to computationally expensive. To put it in perspective,
the protein structure search space of an n-lengthed amino acid
sequence has 4
n permutations. Each individual amino acid
sequence may have a range of unique structures in which
the protein can function relatively well and a select few in
which it functions most optimally. An exhaustive search is
therefore unrealistic and effort should be put into recognizing
relationships between functionally annotated structures that are
already identified using X-ray crystallography and NMR.
C. Generative Adversarial Network
Generative Adversarial Networks (GANs) are first
introduced by Ian Goodfellow and have seen wide adaptations
[11]. Even though noise cancellation was the first purpose of
GANs, the field expanded onto developing conditional GANs
and has seen wide adaptations in style transfer [12], image
generation [13], audio generation [14] [15].
A Generative Adversarial Network (GAN) can be thought
of as a zero-sum game between two networks: 1) One to
discriminate between real and fake data samples and 2) one
to generate data samples that fool this discriminator. This
dynamic is illistrated in Figure 1d. In mathematical terms, this
corresponds to the minimax game:
min
G
max
D
V (D, G) =Ex∼pdata(x)
[log D(x)]
+ Ez∼pz(z)
[log(1 − D(G(z))]
where x is a vector of real data samples, z is a latent
representation of a fake data sample, G is the generative
network, and D is the discriminative network[11]. Often, the
generator uses random noise in order to create seemingly novel
samples that are increasingly indistinguishable real samples.
In training both of these models simultaneously, they are
able to both become more accurate with discrimination and
generation.
D. Deep Convolutional GAN (DCGAN)
DCGANs merge the areas of convolutional neural networks
and the GAN architecture described in C. It extends the
standard GAN architecture by replacing the fully-connected
generator and discriminator networks with deep convolutional
neural networks.
Convolutional Neural Networks (CNNs) are useful for classifying images, especially over their non-convolutional counterparts because the convolution operation preserves spatial
properties of images by working with 2D representations.
In contrast, non-convolutional networks require 1D representations and the image is ”flattened” (the rows/columns of
the image are concatenated). [16] and [17] provide more indepth discussions of how CNNs are used for image classification/recognition.
The use and deployment of a GAN or DCGAN is highly
dependent on the problem at hand. In one case, this model
could be used in order to discriminate between otherwise
indistinguishable samples, such as. In another case, a model
may be deployed for the generation of unique samples. Our
work focuses on the latter.
III. METHODOLOGY
A. Protein Data Set
In the Protein Data Bank (PDB) database, every molecular
structure can be uniquely identified using a four letter noncase sensitive accession number, also called a PDB ID. These
molecular accessions are standardized in such a way that the
first character is numeric and the last three characters are
alphanumeric. An example of such a code is 1crn, identifying
a specific hydrophobic protein structure of crambin [18].
Our data set is composed of 1000 proteins segments identified by PDB IDs. Each segment is exactly 11 amino acids
long and has more than 80% alpha helix composition.
B. Protein Representation
Protein structures are commonly encoded using a contact
map or distance matrix, which is an nxn matrix of pairwise
distances between n atoms in a given structure [19]. These
structures can be easily used to reconstruct a protein using
methods known as multidimensional scaling [20]. Although
this representation captures the distances between each atom,
it ignores the atom types which are responsible for forming
specific bonds in different levels of protein structure. For
instance, in alpha helix secondary structures hydrogen atoms
are responsible for holding the helical spiral together. Additionally, sulfur atoms are known to form disulfide brides in the
tertiary structure of a protein. Therefore, this work substitutes
a contact map for a convolutional network design which has
known to be successful in image recognition. Our hope is
that convolution can be used in place of contact maps as it
uses filter maps to learn the positional relationship amongst
features. In addition our use of convolution, in each atom we
store three additional features. These features include a onehot encoded vector for the generic atom type (carbon, nitrogen,
sulfur, etc), a one-hot encoded vector for the positional atom
type (beta-carbon, alpha-carbon, etc.), and the atomic occu-
Native
70x70x70 Å grid
Discriminator
z Generator
Latent random noise
Fake
70x70x70 Å grid
Decoy
or
Native
Loss
ptn
70x70x70 Å grid
1x1x1 Å Cubes
a
d
b
1x1x1 Å Cube
One-hot encoded vector for generic atom type
One-hot encoded vector for positional atom type
Continuous occupancy value using Van-der Waals radius
Energy
decoy decoy
native c
Fig. 1: a) A measurement of deviation of energy of decoy structures relative a respective native structure. b) The features stored
in each 1x1x1 angstrom object, representing the space allocated for a single atom. c) The structure of each protein encoded
sample. In order to decrease the computational load of the machine learning model, these structures were trimmed down to
the smallest non-zero rectangular prism. d) The Generative Adversarial Network architecture in the scope of our work.
pancy value corresponding to the nearest atom given by the
following formula:
n(ra) = 1 − e
−(
rvdw
ra
)
12
where n(ra) is the single atom occupancy of atom a with
radius ra, and rvdw is the Van der Waals attractive force radius
for atom a.
Each protein sample is represented with 70x70x70
Angstrom (A) grid where each 1x1x1 ˚ A cube contains these ˚
three features about a single atom in the structure as displayed
in Figure 1b and Figure 1c, respectively.
C. Network Architecture & Training
Layer type Output Shape Param #
Conv3D (19, 13, 16, 64) 65728
LeakyReLU (19, 13, 16, 64) 0
Conv3D (10, 7, 8, 128) 221312
LeakyReLU (10, 7, 8, 128) 0
Global Max Pooling 3D (128) 0
Dense (1) 129
TABLE I: Model Architecture for discriminator. Discriminator
has a total of 287,169 parameters, of which 287,169 is
trainable and 0 is non-trainable params
As it can be seen in figure Figure 2, we have trained our
DCGAN over 50 epochs with an early stopping. The training
stopped on epoch around 17 and resulted in a final loss
of 2.962 for the generator and 0.642 for the discriminator.
Generator has a total of 46,302,126 parameters, all of which
are trainable. Discriminator has a total of 287,169 parameters,
all of which is trainable. Loss in generator means that the
structure prediction is improving over time and the discriminator is trying to discriminate between the decoy and the nondecoy structure generation. Functional annotation generation
is robust enough against adversarial attacks.
Layer type Output Shape Param #
Dense (1169792) 45621888
LeakyReLU (1169792) 0
Reshape (37, 26, 32, 38) 0
Conv3DTranspose (37, 26, 32, 38) 92454
LeakyReLU (37, 26, 32, 38) 0
Conv3DTranspose (37, 26, 32, 38) 92454
LeakyReLU (37, 26, 32, 38) 495330
TABLE II: Model Architecture for generator. Generator has
a total of 46,302,126 parameters, of which 46,302,126 is
trainable and 0 is non-trainable.
IV. CONCLUSION AND FUTURE WORK
Fig. 2: DCGAN training cycle.
Two optimization steps were included in order to alleviate
the computational load of the DCGAN. First, the feature
space was trimmed from the 70x70x70 A window down to ˚
the smallest possible rectangular prism grid without removing
non-zero occupancy entries. Second, this grid-like formatted
data was fed into the DCGAN using a generator function and
a batch size of ten.
V. EXPERIMENT RESULTS & OBSERVATIONS
In this work, we limited our scope to simply discriminating between functional and non-functional protein structures.
Although our results provide insight to the difficulty of the
problem at hand, a more focused future development would
be to create a DCGAN on subsets of protein structure with
highly specific functions, such as ligand binding and RNA
degradation. Furthermore, adding features such as torsion
(Ramachandran) angles between outer bonds of the proteins
would increase the representational fidelity of new generated
data. Such future work would allow for the possible discovery
of novel protein structures that are related to real samples by
function.
ACKNOWLEDGMENT
We would like to acknowledge Drexel Society of Artificial
Intelligence for its contributions and support for this research.
REFERENCES
[1] Guorui Li, Jinguang Huang, Jun Yang, Dan He, Chao
Wang, Xiaoxuan Qi, Ian A. Taylor, Junfeng Liu, YouLiang Peng, Structure based function-annotation of hypothetical protein mgg˙01005 from magnaporthe oryzae
reveals it is the dynein light chain orthologue of
dynlt1/3, 2018.
[2] Kuhlman, B., Bradley, P., “Advances in protein structure
prediction and design,” Nat Rev Mol Cell Biol 20,
pp. 681–697, 2019.
[3] E. V. Gurevich and V. V. Gurevich, “Therapeutic potential of small molecules and engineered proteins,” in
Arrestins - Pharmacology and Therapeutic Potential,
V. V. Gurevich, Ed. Berlin, Heidelberg: Springer Berlin
Heidelberg, 2014, pp. 1–12, ISBN: 978-3-642-41199-
1. DOI: 10 . 1007 / 978 - 3 - 642 - 41199 - 1 1. [Online].
Available: https://doi.org/10.1007/978- 3- 642- 41199-
1 1.
[4] A. Ilari and C. Savino, “Protein structure determination
by x-ray crystallography,” Bioinformatics, pp. 63–87,
2008.
[5] J. L. Goodman, M. D. Pagel, and M. J. Stone, “Relationships between protein structure and dynamics from
a database of nmr-derived backbone order parameters,”
Journal of molecular biology, vol. 295, no. 4, pp. 963–
978, 2000.
[6] E. J. Moyer and A. Das, Machine learning applications
to dna subsequence and restriction site analysis, 2020.
arXiv: 2011.03544 [eess.SP].
[7] K. A. Dill, S. B. Ozkan, M. S. Shell, and T. R. Weikl,
“The protein folding problem,” Annu. Rev. Biophys.,
vol. 37, pp. 289–316, 2008.
[8] K. Yao, J. E. Herr, S. N. Brown, and J. Parkhill, “Intrinsic bond energies from a bonds-in-molecules neural
network,” The journal of physical chemistry letters,
vol. 8, no. 12, pp. 2689–2694, 2017.
[9] E. J. Moyer and A. Sacan, Measuring protein structure
deviation using machine learning, 2020.
[10] C. Schaefer and B. Rost, “Predict impact of single
amino acid change upon protein structure,” in BMC
genomics, BioMed Central, vol. 13, 2012, pp. 1–10.
[11] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu,
D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio,
Generative adversarial networks, 2014. arXiv: 1406 .
2661 [stat.ML].
[12] P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros, Imageto-image translation with conditional adversarial networks, 2018. arXiv: 1611.07004 [cs.CV].
[13] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros,
Unpaired image-to-image translation using cycleconsistent adversarial networks, 2020. arXiv: 1703 .
10593 [cs.CV].
[14] K. Alparslan, Y. Alparslan, and M. Burlick, Adversarial
attacks against neural networks in audio domain: Exploiting principal components, 2021. arXiv: 2007.07001
[cs.LG].
[15] Y. Alparslan, E. J. Moyer, and E. Kim, Evaluating
online and offline accuracy traversal algorithms for
k-complete neural network architectures, 2021. arXiv:
2101.06518 [cs.LG].
[16] F. Sultana, A. Sufian, and P. Dutta, “Advancements
in image classification using convolutional neural network,” CoRR, vol. abs/1905.03288, 2019. arXiv: 1905.
03288.
[17] N. Sharma, V. Jain, and A. Mishra, “An analysis of
convolutional neural networks for image classification,”
Procedia Computer Science, vol. 132, pp. 377–384,
2018, International Conference on Computational Intelligence and Data Science, ISSN: 1877-0509.
[18] M. M. Teeter, “Water structure of a hydrophobic protein
at atomic resolution: Pentagon rings of water molecules
in crystals of crambin,” Proceedings of the National
Academy of Sciences, vol. 81, no. 19, pp. 6014–6018,
1984.
[19] P. Baldi and G. Pollastri, “The principled design of
large-scale recursive neural network architectures–dagrnns and the protein structure prediction problem,”
The Journal of Machine Learning Research, vol. 4,
pp. 575–602, 2003.
[20] J. B. Kruskal, “Multidimensional scaling by optimizing
goodness of fit to a nonmetric hypothesis,” Psychometrika, vol. 29, no. 1, pp. 1–27, 1964.

%% 
%% Copyright 2007-2020 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references

%\documentclass[preprint,12pt,authoryear]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times,authoryear]{elsarticle}
%% \documentclass[final,1p,times,twocolumn,authoryear]{elsarticle}
%% \documentclass[final,3p,times,authoryear]{elsarticle}
%% \documentclass[final,3p,times,twocolumn,authoryear]{elsarticle}
%% \documentclass[final,5p,times,authoryear]{elsarticle}
 \documentclass[final,5p,times,twocolumn,authoryear]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
\usepackage{lipsum}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

%% You might want to define your own abbreviated commands for common used terms, e.g.:
\newcommand{\kms}{km\,s$^{-1}$}

\journal{Nuclear Physics B}


\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \affiliation for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%            addressline={}, 
%%            city={},
%%            postcode={}, 
%%            state={},
%%            country={}}
%% \fntext[label3]{}

\title{Title of paper}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \affiliation[label1]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%%
%% \affiliation[label2]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}

\author[first]{Author name}
\affiliation[first]{organization={University of the Moon},%Department and Organization
            addressline={}, 
            city={Earth},
            postcode={}, 
            state={},
            country={}}

\begin{abstract}
%% Text of abstract
Example abstract for the Nuclear Physics B journal. Here you provide a brief summary of the research and the results.
\end{abstract}

%%Graphical abstract
%\begin{graphicalabstract}
%\includegraphics{grabs}
%\end{graphicalabstract}

%%Research highlights
%\begin{highlights}
%\item Research highlight 1
%\item Research highlight 2
%\end{highlights}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword, up to a maximum of 6 keywords
keyword 1 \sep keyword 2 \sep keyword 3 \sep keyword 4

%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}


\end{frontmatter}

%\tableofcontents

%% \linenumbers

%% main text

\section{Introduction}
\label{introduction}

Here is where you provide an introduction to work and some background. For example building on previous work of image enhancment in optical astronomy \citep{vojtekova2021learning}, \cite{sweere2022deep} developed a method to improve the resolution of X-ray images from XMM-Newton to provide similar spatial resolution to Chandra.

\section{Title 2}
%%\label{}
\lipsum[1]

\subsection{Subsection title}

\begin{figure}
	\centering 
	\includegraphics[width=0.4\textwidth, angle=-90]{Nuclear_Physics_B_cover_image.pdf}	
	\caption{Nuclear Physics B journal cover} 
	\label{fig_mom0}%
\end{figure}

A random equation, the Toomre stability criterion:

\begin{equation}
    Q = \frac{\sigma_v \times \kappa}{\pi \times G \times \Sigma}
\end{equation}

\section{Title 3}
%%\label{}
\lipsum[2]

\subsection{Subsection title}
\lipsum[3]

\begin{table}
\begin{tabular}{l c c c} 
 \hline
 Source & RA (J2000) & DEC (J2000) & $V_{\rm sys}$ \\ 
        & [h,m,s]    & [o,','']    & \kms          \\
 \hline
 NGC\,253 & 	00:47:33.120 & -25:17:17.59 & $235 \pm 1$ \\ 
 M\,82 & 09:55:52.725, & +69:40:45.78 & $269 \pm 2$ 	 \\ 
 \hline
\end{tabular}
\caption{Random table with galaxies coordinates and velocities, Number the tables consecutively in
accordance with their appearance in the text and place any table notes below the table body. Please avoid using vertical rules and shading in table cells.
}
\label{Table1}
\end{table}


\section{Discussion}
%%\label{}
\lipsum[4]

\section{Summary and conclusions}
%%\label{}
\lipsum[1-4]


\section*{Acknowledgements}
Thanks to ...

%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
\appendix

\section{Appendix title 1}
%% \label{}

\section{Appendix title 2}
%% \label{}

%% If you have bibdatabase file and want bibtex to generate the
%% bibitems, please use
%%
\bibliographystyle{elsarticle-harv} 
\bibliography{example}

%% else use the following coding to input the bibitems directly in the
%% TeX file.

%%\begin{thebibliography}{00}

%% \bibitem[Author(year)]{label}
%% For example:

%% \bibitem[Aladro et al.(2015)]{Aladro15} Aladro, R., Martín, S., Riquelme, D., et al. 2015, \aas, 579, A101


%%\end{thebibliography}

\end{document}

\endinput
%%
%% End of file `elsarticle-template-harv.tex'.